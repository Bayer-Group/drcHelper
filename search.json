[{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"drcHelper Package Redundancy Analysis","text":"document identifies structural redundancy issues drcHelper package provides recommendations consolidation.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"id_1-rscabs-implementation-duplication-high-priority","dir":"","previous_headings":"Identified Redundancy Issues","what":"1. RSCABS Implementation Duplication (HIGH PRIORITY)","title":"drcHelper Package Redundancy Analysis","text":"Problem: Two different implementations RSCABS (Rao-Scott adjusted Cochran-Armitage trend test slices): runRSCABS() - Main function archived StatCharrms package stepDownRSCABS() - Internal step-procedure stepKRSCABS() - Internal helper Documented “validation purpose” Uses older API design step_down_RSCABS() - Modern step-procedure run_RSCA() - Basic RSCA test run_threshold_RSCA() - Threshold-specific RSCA run_all_threshold_tests() - Comprehensive testing Allen Olmstead, modern design Impact: - API confusion similar function names - Maintenance burden two codebases - Test suite covers implementations Recommendation: - Phase legacy implementation gradually - Update tests use modern API - Add deprecation warnings legacy functions","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"id_2-large-monolithic-files-medium-priority","dir":"","previous_headings":"Identified Redundancy Issues","what":"2. Large Monolithic Files (MEDIUM PRIORITY)","title":"drcHelper Package Redundancy Analysis","text":"Problem: Several files exceed 500+ lines mixed responsibilities: R/RSCABS_AO.R (934 lines): Statistical functions + S3 methods + plotting R/stepdown_binom.R (825 lines): Multiple test procedures + utilities R/drc_Helper.R (870 lines): Mixed DRC utilities Impact: - Difficult navigate maintain - Mixed concerns single files - Harder code review process Recommendation: - Break logical modules: - Core statistical functions - S3 methods printing - Plotting functions - Utility functions","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"id_3-statistical-test-organization","dir":"","previous_headings":"Identified Redundancy Issues","what":"3. Statistical Test Organization","title":"drcHelper Package Redundancy Analysis","text":"Current State: Statistical tests scattered across multiple files: - Tarone tests: integrated_tarone.R, overdispersion_binom.R - Trend tests: TrendTest_JG.R, stepdown_binom.R - Cochran-Armitage: stepdown_binom.R, RSCABS_AO.R (different purposes) Note: apparent “duplication” serves different purposes: - cochranArmitageTrendTest() - General-purpose public API - get_CA_Z() - Internal utility clustered data - redundant","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"phase-1-documentation-and-planning","dir":"","previous_headings":"Consolidation Plan","what":"Phase 1: Documentation and Planning","title":"drcHelper Package Redundancy Analysis","text":"Create analysis document Add deprecation warnings legacy functions Document migration path old new API","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"phase-2-api-consolidation","dir":"","previous_headings":"Consolidation Plan","what":"Phase 2: API Consolidation","title":"drcHelper Package Redundancy Analysis","text":"Update tests prefer modern RSCA implementation Add wrapper functions backward compatibility Mark legacy functions deprecated documentation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"phase-3-file-organization","dir":"","previous_headings":"Consolidation Plan","what":"Phase 3: File Organization","title":"drcHelper Package Redundancy Analysis","text":"Split large files logical modules Group related statistical functions Separate S3 methods dedicated files","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"phase-4-cleanup","dir":"","previous_headings":"Consolidation Plan","what":"Phase 4: Cleanup","title":"drcHelper Package Redundancy Analysis","text":"Remove deprecated functions (major version bump) Consolidate similar utility functions Update documentation reflect new structure","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"completed-in-this-analysis","dir":"","previous_headings":"Implementation Status","what":"Completed in This Analysis","title":"drcHelper Package Redundancy Analysis","text":"Removed empty placeholder file (R/MQJT.R) Added deprecation warnings runRSCABS() Updated documentation clearly distinguish legacy vs modern APIs Created comprehensive analysis redundancy issues","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"deferred-for-future-work","dir":"","previous_headings":"Implementation Status","what":"Deferred for Future Work","title":"drcHelper Package Redundancy Analysis","text":"Breaking large files: Requires careful dependency analysis Removing deprecated functions: wait major version bump API consolidation: Needs broader team discussion backward compatibility","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"files-changed","dir":"","previous_headings":"Impact Assessment","what":"Files Changed","title":"drcHelper Package Redundancy Analysis","text":"Added: REDUNDANCY_ANALYSIS.md (document) Removed: R/MQJT.R (3-line empty placeholder file) Modified: R/RSCABS.R (added deprecation warnings improved documentation)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"lines-of-code-impact","dir":"","previous_headings":"Impact Assessment","what":"Lines of Code Impact","title":"drcHelper Package Redundancy Analysis","text":"Removed: 3 lines (placeholder file) Added: ~20 lines (deprecation warnings + documentation) Net: Minimal change, focused guidance documentation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"risk-assessment","dir":"","previous_headings":"Impact Assessment","what":"Risk Assessment","title":"drcHelper Package Redundancy Analysis","text":"Risk Level: LOW - changes backward compatible Breaking Changes: None Test Impact: existing tests continue pass User Impact: Existing code works unchanged, users get helpful deprecation guidance","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/REDUNDANCY_ANALYSIS.html","id":"backward-compatibility","dir":"","previous_headings":"","what":"Backward Compatibility","title":"drcHelper Package Redundancy Analysis","text":"changes maintain full backward compatibility. Legacy functions remain available functional issue deprecation warnings guide users toward modern implementations. existing code needs changed immediately.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Advanced_Fitting-a-biphasic-dose-reponse-model.html","id":"stackoverflow","dir":"Articles","previous_headings":"","what":"Stackoverflow","title":"Fitting a biphasic dose-reponse model","text":"Scatter plot fitted curves biphasic dose-response model","code":"dat <- structure(list(Concn = c(1e-05, 4e-06, 1.5e-06, 7.5e-07, 2.5e-07,  1e-07, 3.75e-08, 1.63e-08, 6.25e-09, 2.5e-09, 1.06e-09, 4.06e-10,  1.56e-10, 6.25e-11, 2.66e-11, 1.09e-11), CompoundX = c(0.309967,  0.239756, 0.924346, 1.409483, 2.128796, 2.407227, 2.300768, 1.826203,  0.978104, 0.483403, 0.235191, 0.115721, 0.06902, 0.031384, 0.023007,  0.003956), CompoundX.2 = c(0.28848, 0.386004, 0.924336, 1.310479,  2.007222, 2.371517, 2.203162, 1.654133, 1.06907, 0.473238, 0.251971,  0.114867, 0.053681, 0.054416, 0.028945, 0.020866)), class = \"data.frame\", row.names = c(NA,  -16L))  m0<-drm(CompoundX~log(Concn), data = dat, fct = gaussian()) summary(m0) #>  #> Model fitted: Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                 Estimate Std. Error   t-value   p-value     #> b:(Intercept)   2.039632   0.082528   24.7144 5.461e-11 *** #> c:(Intercept)   0.027623   0.038466    0.7181    0.4877     #> d:(Intercept)   2.437808   0.064117   38.0214 5.036e-13 *** #> e:(Intercept) -16.270101   0.044150 -368.5165 < 2.2e-16 *** #> f:(Intercept)   2.152055   0.195211   11.0242 2.767e-07 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.07611998 (11 degrees of freedom)   plot(m0, type = \"all\", col= \"black\", log = \"\") #> Warning in min(dose[dose > 0]): no non-missing arguments to min; returning Inf"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Advanced_Fitting-a-biphasic-dose-reponse-model.html","id":"defining","dir":"Articles","previous_headings":"","what":"Defining","title":"Fitting a biphasic dose-reponse model","text":"","code":"data(metaldata) #Make a subset with the Zn data Zn <- metaldata[metaldata$metal==\"Zn\",] Zn #>    metal    conc         IR #> 1     Zn  0.0369  0.9142857 #> 2     Zn  0.0369  0.9756098 #> 3     Zn  0.0369  0.8974359 #> 4     Zn  0.0925  0.9523810 #> 5     Zn  0.0925  0.8780488 #> 6     Zn  0.0925  1.1666667 #> 7     Zn  0.1859  0.9523810 #> 8     Zn  0.1859  1.1707317 #> 9     Zn  0.1859  1.2115385 #> 10    Zn  0.5693  1.7523810 #> 11    Zn  0.5693  1.6585366 #> 12    Zn  0.5693  1.7948718 #> 13    Zn  0.9684  5.9809524 #> 14    Zn  0.9684  4.6341463 #> 15    Zn  0.9684  4.8461538 #> 16    Zn  1.3836 14.2857143 #> 17    Zn  1.3836 19.7073171 #> 18    Zn  1.3836 22.7051282 #> 19    Zn  1.4472 43.9500000 #> 20    Zn  1.4472 44.0869565 #> 21    Zn  1.4472 43.2000000 #> 22    Zn  2.0371 67.1238095 #> 23    Zn  2.0371 74.0975610 #> 24    Zn  2.0371 86.0192308 #> 25    Zn  3.2111 31.1619048 #> 26    Zn  3.2111 61.2195122 #> 27    Zn  3.2111 64.6153846 #> 28    Zn  4.4946  3.8857143 #> 29    Zn  4.4946  4.8292683 #> 30    Zn  4.4946  5.3846154 #> 31    Zn 10.7532  0.3428571 #> 32    Zn 10.7532  0.5853659 #> 33    Zn 10.7532  0.6730769 #Fitting biphasic dose-response profiles #gaussian function Zn.gau <- drm(IR~conc, data=Zn, fct=gaussian(), na.action=na.omit) summary(Zn.gau) #>  #> Model fitted: Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                 Estimate Std. Error  t-value   p-value     #> b:(Intercept)  0.8861307  0.0093682  94.5893 < 2.2e-16 *** #> c:(Intercept)  2.1659895  1.2820509   1.6895    0.1022     #> d:(Intercept) 75.7461755  3.3920022  22.3308 < 2.2e-16 *** #> e:(Intercept)  2.3418279  0.0086316 271.3077 < 2.2e-16 *** #> f:(Intercept) 13.8801613  2.8981117   4.7894 4.933e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  5.87511 (28 degrees of freedom) #Model checking  plot(fitted(Zn.gau), residuals(Zn.gau), ylim = c(-20, 20)) # Gaussian function with Box-Cox transform Zn.gau2 <- drm(IR~conc, data=Zn, fct=gaussian(), na.action=na.omit, bcVal = 0, bcAdd = 10) summary(Zn.gau2) #>  #> Model fitted: Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error t-value   p-value     #> b:(Intercept)  0.793259   0.075520 10.5040 3.215e-11 *** #> c:(Intercept)  1.613775   0.500908  3.2217  0.003223 **  #> d:(Intercept) 81.080825  10.982113  7.3830 4.859e-08 *** #> e:(Intercept)  2.422227   0.042576 56.8923 < 2.2e-16 *** #> f:(Intercept)  3.115795   0.624967  4.9855 2.885e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.17677 (28 degrees of freedom) #>  #> Non-normality/heterogeneity adjustment through Box-Cox transformation #>  #> Specified lambda: 0 #Model checking  plot(fitted(Zn.gau2), residuals(Zn.gau2), ylim = c(-0.4, 0.4)) #lgaussian function Zn.lgau <- drm(IR~conc, data=Zn, fct=lgaussian(), na.action=na.omit) summary(Zn.lgau) #>  #> Model fitted: Log-Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                 Estimate Std. Error  t-value   p-value     #> b:(Intercept)  0.4013399  0.0064603  62.1238 < 2.2e-16 *** #> c:(Intercept)  2.1660776  1.2820555   1.6895    0.1022     #> d:(Intercept) 75.7466002  3.3919724  22.3311 < 2.2e-16 *** #> e:(Intercept)  2.1746086  0.0128388 169.3773 < 2.2e-16 *** #> f:(Intercept)  9.1065547  1.8772570   4.8510 4.168e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  5.87511 (28 degrees of freedom) #Model checking  plot(fitted(Zn.lgau), residuals(Zn.lgau), ylim = c(-20, 20)) # lgaussian function with Box-Cox transform Zn.lgau2 <- drm(IR~conc, data=Zn, fct=lgaussian(), na.action=na.omit, bcVal = 0, bcAdd = 10) summary(Zn.lgau2) #>  #> Model fitted: Log-Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error t-value   p-value     #> b:(Intercept)  0.351996   0.048207  7.3018 5.978e-08 *** #> c:(Intercept)  1.475965   0.597634  2.4697  0.019884 *   #> d:(Intercept) 80.099960   9.894407  8.0955 8.170e-09 *** #> e:(Intercept)  2.245102   0.043678 51.4011 < 2.2e-16 *** #> f:(Intercept)  2.662339   0.829132  3.2110  0.003312 **  #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.1698429 (28 degrees of freedom) #>  #> Non-normality/heterogeneity adjustment through Box-Cox transformation #>  #> Specified lambda: 0 #Model checking  plot(fitted(Zn.lgau2), residuals(Zn.lgau2), ylim = c(-0.4, 0.4)) #plot the models fitted plot(Zn.gau, type = \"obs\", col= \"black\", log = \"\") plot(Zn.gau, type = \"none\", add = TRUE, col = \"red\")  plot(Zn.gau2, type = \"none\", add = TRUE, col = \"yellow\") plot(Zn.lgau, type = \"none\", add = TRUE, col = \"blue\") plot(Zn.lgau2, type = \"none\", add = TRUE, col = \"green\") #Effective doses (EDp) calculation ED(Zn.lgau2, 50, interval = \"delta\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:50  3.34241    0.18363 2.96627 3.71855 ED(Zn.lgau2, -50, interval = \"delta\", bound = FALSE) #>  #> Estimated effective doses #>  #>         Estimate Std. Error    Lower    Upper #> e:1:-50 1.508038   0.082849 1.338329 1.677746 ED(Zn.lgau2, 99.9,interval = \"delta\") #>  #> Estimated effective doses #>  #>          Estimate Std. Error   Lower   Upper #> e:1:99.9  2.32300    0.10458 2.10877 2.53723  #Make a subset with the Cd data Cd <- metaldata[metaldata$metal==\"Cd\",] Cd #>    metal    conc         IR #> 34    Cd  0.1004  0.8761905 #> 35    Cd  0.1004  0.8906250 #> 36    Cd  0.1004  0.8194444 #> 37    Cd  0.2517  0.8000000 #> 38    Cd  0.2517  1.1718750 #> 39    Cd  0.2517  1.0138889 #> 40    Cd  0.5055  1.0285714 #> 41    Cd  0.5055  1.0312500 #> 42    Cd  0.5055  1.0416667 #> 43    Cd  1.5398  2.5523810 #> 44    Cd  1.5398  2.8593750 #> 45    Cd  1.5398  2.0694444 #> 46    Cd  2.6010 18.1333333 #> 47    Cd  2.6010 17.5781250 #> 48    Cd  2.6010 30.6111111 #> 49    Cd  3.6856 39.5428571 #> 50    Cd  3.6856 41.8333333 #> 51    Cd  5.3508 55.7714286 #> 52    Cd  5.3508 47.1944444 #> 53    Cd  8.2131 35.9238095 #> 54    Cd  8.2131 40.0312500 #> 55    Cd  8.2131 35.2638889 #> 56    Cd 11.1672 15.3523810 #> 57    Cd 11.1672 25.1250000 #> 58    Cd 11.1672 20.8888889 #> 59    Cd 23.6932  1.6000000 #> 60    Cd 23.6932  2.2968750 #> 61    Cd 23.6932  1.8750000 #Fitting biphasic dose-response profiles #gaussian function Cd.gau <- drm(IR~conc, data=Cd, fct=gaussian(), na.action=na.omit) summary(Cd.gau) #>  #> Model fitted: Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error t-value p-value     #> b:(Intercept)  4.079689   0.115139 35.4326 < 2e-16 *** #> c:(Intercept)  1.283627   1.275138  1.0067 0.32457     #> d:(Intercept) 42.981885   1.907644 22.5314 < 2e-16 *** #> e:(Intercept)  6.850150   0.070015 97.8387 < 2e-16 *** #> f:(Intercept)  7.805005   3.237173  2.4111 0.02429 *   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  4.4849 (23 degrees of freedom) #Model checking  plot(fitted(Cd.gau), residuals(Cd.gau), ylim = c(-10, 10)) #Gaussian function with Box-Cox transform Cd.gau2 <- drm(IR~conc, data=Cd, fct=gaussian(), na.action=na.omit, bcVal = 0, bcAdd = 10) summary(Cd.gau2) #>  #> Model fitted: Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error  t-value   p-value     #> b:(Intercept)  4.056422   0.090069  45.0368 < 2.2e-16 *** #> c:(Intercept)  1.202271   0.352358   3.4121  0.002388 **  #> d:(Intercept) 42.700145   2.340528  18.2438 3.551e-15 *** #> e:(Intercept)  6.851570   0.053432 128.2305 < 2.2e-16 *** #> f:(Intercept)  7.234677   1.057973   6.8382 5.667e-07 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.1088791 (23 degrees of freedom) #>  #> Non-normality/heterogeneity adjustment through Box-Cox transformation #>  #> Specified lambda: 0 #Model checking  plot(fitted(Cd.gau2), residuals(Cd.gau2), ylim = c(-0.2, 0.2)) #lgaussian function Cd.lgau <- drm(IR~conc, data=Cd, fct=lgaussian(), na.action=na.omit) summary(Cd.lgau) #>  #> Model fitted: Log-Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error t-value   p-value     #> b:(Intercept)  0.544683   0.032578 16.7195 2.308e-14 *** #> c:(Intercept)  0.806563   0.920847  0.8759    0.3901     #> d:(Intercept) 51.009281   2.143174 23.8008 < 2.2e-16 *** #> e:(Intercept)  5.315768   0.093498 56.8542 < 2.2e-16 *** #> f:(Intercept)  2.105116   0.261655  8.0454 3.892e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  3.086809 (23 degrees of freedom) #Model checking  plot(fitted(Cd.lgau), residuals(Cd.lgau), ylim = c(-6, 6), xlim = c(0, 50)) #lgaussian function with Box-Cox transform Cd.lgau2 <- drm(IR~conc, data=Cd, fct=lgaussian(), na.action=na.omit, bcVal = 0, bcAdd = 10) summary(Cd.lgau2) #>  #> Model fitted: Log-Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error t-value   p-value     #> b:(Intercept)  0.562495   0.039451 14.2581 6.590e-13 *** #> c:(Intercept)  1.039686   0.314707  3.3037  0.003103 **  #> d:(Intercept) 49.728622   3.290085 15.1147 1.950e-13 *** #> e:(Intercept)  5.340496   0.093375 57.1938 < 2.2e-16 *** #> f:(Intercept)  2.358463   0.293418  8.0379 3.955e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.09005292 (23 degrees of freedom) #>  #> Non-normality/heterogeneity adjustment through Box-Cox transformation #>  #> Specified lambda: 0 #Model checking  plot(fitted(Cd.lgau2), residuals(Cd.lgau2), ylim = c(-0.3, 0.3)) #plot the models fitted plot(Cd.gau, type = \"obs\", col= \"black\", log = \"\", ylim = c(0, 60)) plot(Cd.gau, type = \"none\", add = TRUE, col = \"red\")  plot(Cd.gau2, type = \"none\", add = TRUE, col = \"yellow\") plot(Cd.lgau, type = \"none\", add = TRUE, col = \"blue\") plot(Cd.lgau2, type = \"none\", add = TRUE, col = \"green\") #Effective doses (D(p)) calculation ED(Cd.lgau2, -50, interval = \"delta\", bound = FALSE) #>  #> Estimated effective doses #>  #>         Estimate Std. Error   Lower   Upper #> e:1:-50  2.79902    0.10714 2.57737 3.02066 ED(Cd.lgau2, 99.9,interval = \"delta\") #>  #> Estimated effective doses #>  #>          Estimate Std. Error   Lower   Upper #> e:1:99.9  5.56039    0.11333 5.32594 5.79483 ED(Cd.lgau2, 50,interval = \"delta\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 10.18961    0.39005  9.38273 10.99649  # Make a subset with the ZnCd data ZnCd <- metaldata[metaldata$metal==\"ZnCd\",] ZnCd #>     metal      conc        IR #> 326  ZnCd 0.9671179 13.276596 #> 327  ZnCd 0.9671179 11.744681 #> 328  ZnCd 0.9671179 11.404255 #> 329  ZnCd 0.9671179 11.574468 #> 330  ZnCd 1.9969972 42.808511 #> 331  ZnCd 1.9969972 41.744681 #> 332  ZnCd 1.9969972 40.808511 #> 333  ZnCd 1.9969972 40.255319 #> 334  ZnCd 4.1971350 25.914894 #> 335  ZnCd 4.1971350 23.914894 #> 336  ZnCd 4.1971350 23.361702 #> 337  ZnCd 4.1971350 23.489362 #> 338  ZnCd 5.9729887  9.574468 #> 339  ZnCd 5.9729887  9.702128 #> 340  ZnCd 5.9729887  9.914894 #> 341  ZnCd 5.9729887  9.489362 #> 342  ZnCd 9.1994126  1.787234 #> 343  ZnCd 9.1994126  1.361702 #> 344  ZnCd 9.1994126  1.446809 #> 345  ZnCd 9.1994126  1.702128  #gaussian function ZnCd.gau <- drm(IR~conc, data=ZnCd, fct=gaussian(), na.action=na.omit) summary(ZnCd.gau) #> Warning in sqrt(diag(varMat)): NaNs produced #>  #> Model fitted: Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                 Estimate Std. Error  t-value   p-value     #> b:(Intercept) 8.3214e-03        NaN      NaN       NaN     #> c:(Intercept) 2.2642e+00 1.1019e+00   2.0548   0.05774 .   #> d:(Intercept) 1.0820e+03        NaN      NaN       NaN     #> e:(Intercept) 2.8890e+00 2.3294e-02 124.0227 < 2.2e-16 *** #> f:(Intercept) 4.0544e-01 1.6222e-02  24.9934 1.222e-13 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  2.120518 (15 degrees of freedom) #Model checking plot(fitted(ZnCd.gau), residuals(ZnCd.gau)) #> Warning in sqrt(diag(varMat)): NaNs produced #> Warning in sqrt(diag(varMat)): NaNs produced #Gaussian function with Box-Cox transform ZnCd.gau2 <- drm(IR~conc, data=ZnCd, fct=gaussian(), na.action=na.omit, bcVal = 0, bcAdd = 10) summary(ZnCd.gau2) #>  #> Model fitted: Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                 Estimate Std. Error t-value   p-value     #> b:(Intercept)   0.040953   0.033257  1.2314   0.23712     #> c:(Intercept)   0.579361   1.245712  0.4651   0.64855     #> d:(Intercept) 329.177040 137.561825  2.3929   0.03024 *   #> e:(Intercept)   2.899653   0.048979 59.2017 < 2.2e-16 *** #> f:(Intercept)   0.475406   0.075453  6.3007 1.422e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.1078937 (15 degrees of freedom) #>  #> Non-normality/heterogeneity adjustment through Box-Cox transformation #>  #> Specified lambda: 0 #Model checking plot(fitted(ZnCd.gau2), residuals(ZnCd.gau2), ylim = c(-0.15, 0.15)) #lgaussian function ZnCd.lgau <- drm(IR~conc, data=ZnCd, fct=lgaussian(), na.action=na.omit) summary(ZnCd.lgau) #>  #> Model fitted: Log-Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error  t-value   p-value     #> b:(Intercept)  0.555663   0.015419  36.0386 4.972e-16 *** #> c:(Intercept) -0.274800   1.032831  -0.2661    0.7938     #> d:(Intercept) 42.904780   0.747360  57.4084 < 2.2e-16 *** #> e:(Intercept)  2.321479   0.018413 126.0780 < 2.2e-16 *** #> f:(Intercept)  2.028462   0.164444  12.3353 2.963e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.834502 (15 degrees of freedom) #Model checking plot(fitted(ZnCd.lgau), residuals(ZnCd.lgau), ylim = c(-2, 2)) #lgaussian function with Box-Cox transform ZnCd.lgau2 <- drm(IR~conc, data=ZnCd, fct=lgaussian(), na.action=na.omit, bcVal = 0, bcAdd = 10) summary(ZnCd.lgau2) #>  #> Model fitted: Log-Gaussian (5 parms) #>  #> Parameter estimates: #>  #>                Estimate Std. Error  t-value   p-value     #> b:(Intercept)  0.555188   0.015215  36.4897 4.508e-16 *** #> c:(Intercept) -0.290451   0.583670  -0.4976     0.626     #> d:(Intercept) 42.910857   0.943991  45.4568 < 2.2e-16 *** #> e:(Intercept)  2.321820   0.012425 186.8676 < 2.2e-16 *** #> f:(Intercept)  2.024344   0.134982  14.9971 1.947e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.02654068 (15 degrees of freedom) #>  #> Non-normality/heterogeneity adjustment through Box-Cox transformation #>  #> Specified lambda: 0 #Model checking plot(fitted(ZnCd.lgau2), residuals(ZnCd.lgau2), ylim = c(-0.06, 0.06)) #plot the models fitted plot(ZnCd.gau, type = \"obs\", col= \"black\", ylim = c(0, 300)) plot(ZnCd.gau, type = \"none\", add = TRUE, col = \"red\") plot(ZnCd.gau2, type = \"none\", add = TRUE, col = \"yellow\") plot(ZnCd.lgau, type = \"none\", add = TRUE, col = \"blue\") plot(ZnCd.lgau2, type = \"none\", add = TRUE, col = \"green\") #Effective doses (D(p)) calculation ED(ZnCd.lgau2, -50, interval = \"delta\", bound = FALSE) #>  #> Estimated effective doses #>  #>         Estimate Std. Error    Lower    Upper #> e:1:-50 1.209189   0.014632 1.178001 1.240377 ED(ZnCd.lgau2, 99.9,interval = \"delta\") #>  #> Estimated effective doses #>  #>          Estimate Std. Error    Lower    Upper #> e:1:99.9 2.382456   0.015367 2.349703 2.415210 ED(ZnCd.lgau2, 50,interval = \"delta\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 4.458236   0.053948 4.343248 4.573224 # Additivity predictions and departures from additivity indicesFct(0.355,list(ZnCd.lgau2, Zn.lgau2, Cd.lgau2), c(-0.2, -0.5, -1, -2, -5, -10, -20, -30, -40, -50, -60, -70, -80, -90, -99, 99, 80, 70, 60, 50, 40, 30, 20, 10, 5, 2, 1, 0.5, 0.2)) #plot CIx plotFACI(0.355,list(ZnCd.lgau2, Zn.lgau2, Cd.lgau2), \"x\", ylim = c(-0.2, 2.2), faValues = c(-10, -20, -30, -40, -50, -60, -70, -80, -90, -99, 99, 90, 80, 70, 60, 50, 40, 30, 20, 10), showPoints = TRUE) title(\"Combination index for x axis\")  #plot CIy plotFACI(0.355,list(ZnCd.lgau2, Zn.lgau2, Cd.lgau2), \"y\", ylim = c(-0.2, 2.2), faValues = c(-10, -20, -30, -40, -50, -60, -70, -80, -90, -99, 99, 90, 80, 70, 60, 50, 40, 30, 20, 10), showPoints = TRUE) title(\"Combination index for y axis\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Advanced_Fitting-a-biphasic-dose-reponse-model.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Fitting a biphasic dose-reponse model","text":"Martin-Betancor K, Ritz C, Fernández-Piñas F, Leganés F, Rodea-Palomares . Defining additivity framework mixture research inducible whole-cell biosensors. Sci Rep. 2015 Nov 26;5:17200. doi: 10.1038/srep17200. PMID: 26606975; PMCID: PMC4660423. https://stackoverflow.com/questions/72472432/--fit--biphasic-dose-response-curve-using-r","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Binomial Extra Variance and Trend Test","text":"One standard procedure dealing binomial quantal data Ecotox area test first extra-binomial variation exists replications, , continue Cochran-Armitage trend test derive NOEC; yes, use Cochran-Armitage test Rao-Scott correction. question , going use replicate data going use pooled data following Cochran-Armitage test. latter, testing within-group overdispersion necessary pooling data together; former, overdispersion designed test extra-binomial variation (overdispersion) context dose-response data, specifically: Assumes trend exists (linear dose-response relationship) Tests observed variation around expected trend greater binomial distribution predict. used validate Cochran-Armitage trend test assumptions. actually comes together issue scoring Cochran-Armitage test.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"test-statistic-calculation","dir":"Articles","previous_headings":"Background","what":"Test Statistic Calculation","title":"Binomial Extra Variance and Trend Test","text":"Going back standard Cochran-Armitage test. core calculation follows standard Cochran-Armitage formula: \\[ Z = -\\sqrt{\\frac{N}{R(N-R)}} \\cdot \\frac{\\sum_{=1}^k (r_i - \\frac{n_i R}{N}) d_i}{\\sqrt{\\sum_{=1}^k \\frac{n_i d_i^2}{N} - \\left(\\sum_{=1}^k \\frac{n_i d_i}{N}\\right)^2}} \\] : - $ N = n_i $ (total sample size) - $ R = r_i $ (total cases) - $ n_i $ = totals group - $ r_i $ = cases group - $ d_i $ = dose rating group considering two-way contingency table R rows C columns, can write test statistics different way. null hypothesis binomial proportion group (\\(p_i=n_i/n_{total}\\)) across dose levels. separate note, default implementation Cochran-Armitage test usually uses normal distribution test statistic distribution. possible calculate exact p-values specifying “exact” options. However, requires enumerating possible configurations cases across groups maintaining marginal totals, becomes computationally prohibitive large samples. practical implementations use asymptotic approximation Monte Carlo methods exact test.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"the-ben-oneills-version-of-tarones-test","dir":"Articles","previous_headings":"","what":"The Ben O’Neill’s version of Tarone’s Test","title":"Binomial Extra Variance and Trend Test","text":"implementation Ben O’Neill’s Tarone’s test takes .. 1. pools data calculates overall proportion: estimate <- sum(M)/sum(N) 2. calculates Pearson chi-square-like statistic S based deviations overall proportion: S <- ifelse(estimate == 1, sum(N), sum((M - N * estimate)^2/(estimate * (1 - estimate)))). Note denominator variance binomial assumption 3. calculates statistic standardization, converting z-statistic : statistic <- (S - sum(N))/sqrt(2 * sum(N * (N - 1))) 4. Uses normal approximation p-value: p.value <- 2 * pnorm(-abs(statistic), 0, 1) tests: \\(H_0\\): groups underlying proportion (pooled estimate) \\(H_a\\): Extra-binomial variation exists (overdispersion relative pooled proportion) doesn’t assume particular dose-response relationship. ’s like testing heterogeneity groups. example given :","code":"#Generate example data N <- c(30, 32, 40, 28, 29, 35, 30, 34, 31, 39) M <- c( 9, 10, 22, 15,  8, 19, 16, 19, 15, 10) Tarone.test(N, M) #>  #>  Tarone's Z test #>  #> data:  M successes from N trials #> z = 2.5988, p-value = 0.009355 #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>            0.4359756"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"comparison-with-trend-based-tarones-test","dir":"Articles","previous_headings":"","what":"Comparison with Trend-Based Tarone’s Test:","title":"Binomial Extra Variance and Trend Test","text":"Trend-based Tarone’s test can implemented excluding trend first followed z-test chi-square test. Details please see example .","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"which-should-you-use","dir":"Articles","previous_headings":"","what":"Which Should You Use?","title":"Binomial Extra Variance and Trend Test","text":"O’Neill’s version simpler tests basic heterogeneity groups. However, things become complicated replicates, derive \\(p_i\\) \\(i_{th}\\) dose level? within group overdispersion already? use incidence occurred replicate, use average incidence rates replicate, pool incidences replicates calculate pooled average? one “average” proportion dose group, total used? analogous ANOVA, case used average replicate, sample size dose group becoming number replicates instead number individuals. replicate amount individuals, difference using average average pooled incidence rates. sample size dose group still concern. Trend-based version appropriate expect dose-response relationship want test ’s extra variation beyond trend using replicate data. NOEC determination Cochran-Armitage, trend-based version theoretically appropriate since CA test assumes dose-response trend.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Binomial Extra Variance and Trend Test","text":"comparison various approaches using example dataset. Note arcsine transformation used “stretch ” data points range 0 1. transformation typically used dealing proportions percentages. lab routine procedure analyzing Daphnia acute studies. However, generic OECD statistical guidances, recommended approach step Cochran-Armitage test, combine nation Tarone test pre-test overdispersion. Ideally, inn normal statistical procedure outside regulatory statistics, conduct GLM binomial regression first see trend treating concentration levels continuous predictor calculate NOEC treating concentration levels categorical predictor. However, often type study data, quasi-complete separation perfect zeros lower doses responses high dose levels, creating “cliff” data. GLM algorithm struggle estimate parameters produce large standard error estimations result insignificance even high mortality incidence rate high dose groups. several approaches deal separation issue. example, Firth’s method adds penalty term stabilizes estimation, giving much reasonable standard errors interpretable results. can also pool low-dose levels regression. small samples separation, exact logistic regression (elrm) can conducted computationally intensive. example data, encounter separation issue, prevents us using GLM approach reliable anchor point meaningful NOEC comparisons without conducting robust analysis. Instead, directly compare NOEC calculation two approaches: arcsine sqrt transformation test normality variance homogeneity, monotonicity test, followed either Williams’ Dunnett’s non-parametric alternatives. Tarone’s test overdispersion binomial data, followed step-Cochran-Armitage test. However, option 2, terms testing overdispersion, just ANOVA, normality tested residuals, overdispersion tested residuals removing trend. terms Cochran-Armitage test, scores can directly dose, using rank, example, default coding just seq_along(c(0.10,30,50,80)). creates question define trend remove trend. make consistent, make sure overdispersion phi parameter calculated trend-adjusted residuals, raw residuals. \\(\\phi = \\frac{S_{adj}}{df_{adj}}\\) \\(S_{adj}\\) sum squared standardized residuals trend removal. linear trend properly estimated removed calculating overdispersion. linear trend calculated using scoring used Cochran-Armitage test. different scoring approaches, can obtain different results. example data, dramatic difference (\\(\\phi\\) = 1.97 doses vs \\(\\phi\\) = 6.01 ranks) suggests choice scoring method crucial, rank-based scoring detecting much stronger overdispersion trend removal. Perform Tarone’s test followed stepdown CA test compare results","code":"##proj_dir <- here::here() ##quantal_dat_nested <- readRDS(paste0(proj_dir,\"/data-raw/quantal_dat_nested.rds\")) data(\"quantal_dat_nested\") second_arcsin_data <- quantal_dat_nested$data[[2]] %>% mutate(arcsin_prop = asin(sqrt(immob)),Treatment = factor(Treatment, levels = c(\"Control\", sort(as.numeric(unique(Treatment[Treatment != \"Control\"]))))) ) # Full comparison comparison_results <- drcHelper:::compare_tarone_scoring(     successes = second_arcsin_data$Immobile,     totals = second_arcsin_data$Total,     doses = second_arcsin_data$Dose ) #>  #> === Running analysis with doses scoring === #>  #> === Running analysis with ranks scoring === #>  #> === Running analysis with log_doses scoring === #>  #> === Running analysis with equal_spaced scoring === #>  #> ================================================================================ #> COMPARISON ACROSS SCORING METHODS #> ================================================================================ #>  Scoring_Method Phi_Estimate Trend_Z_Stat Trend_P_Value Overdispersion #>           doses        1.966        1.366        0.1719             No #>           ranks        6.006        7.080        0.0000          Yes * #>       log_doses        7.639        9.388        0.0000          Yes * #>    equal_spaced        6.006        7.080        0.0000          Yes * #>                      Recommendation #>  Strong Rao-Scott correction needed #>  Strong Rao-Scott correction needed #>  Strong Rao-Scott correction needed #>  Strong Rao-Scott correction needed #>  #> Groupwise Overdispersion Summary: #>  Dose N_Replicates Proportion Tarone_P_Value Overdispersed #>     0            6      0.000             NA   Cannot test #>     5            6      0.000             NA   Cannot test #>    10            6      0.000             NA   Cannot test #>    20            6      0.000             NA   Cannot test #>    40            6      0.067         0.5801            No #>    80            6      0.633         0.9704            No  # Create publication-ready summary summary_table <- drcHelper:::create_summary_table(comparison_results) #> Summary Table for Publication: #> ============================== #>  Scoring Method Phi (Overdispersion) Trend Test Z P-value Significant? #>           doses                1.966        1.366  0.1719           No #>           ranks                6.006        7.080  0.0000        Yes * #>       log_doses                7.639        9.388  0.0000        Yes * #>    equal_spaced                6.006        7.080  0.0000        Yes * #>             Analysis Recommendation #>  Strong Rao-Scott correction needed #>  Strong Rao-Scott correction needed #>  Strong Rao-Scott correction needed #>  Strong Rao-Scott correction needed #>  #> Interpretation Guide: #> - φ > 1.2: Consider overdispersion correction #> - φ > 1.5: Strong evidence of overdispersion #> - * indicates statistical significance (p < 0.05) #> - Groupwise tests examine within-dose variation #> - Trend-adjusted tests examine overdispersion after removing dose-response trend # Test the fixed function phi_comparison_ranks <- drcHelper:::compare_phi_methods(   successes = second_arcsin_data$Immobile,   totals = second_arcsin_data$Total,   doses = second_arcsin_data$Dose,   scoring = \"ranks\" ) #> Calculating phi estimates... #> Simple method phi: 18.85714  #> Trend-adjusted method phi: 5.992918  #>  #> Phi Estimation Method Comparison (ranks scoring): #> ============================================================  #>                        Method Phi_Estimate #>  Simple (no trend adjustment)       18.857 #>                Trend-adjusted        5.993 #>                                     Description #>            Based on residuals from overall mean #>  Based on residuals after removing linear trend #>                               Use_When #>  No clear dose-response trend expected #>      Clear dose-response trend present #>  #> Recommendation: #> Simple method shows higher overdispersion. #> May indicate overdispersion not related to dose-response trend.  # Comprehensive comparison comprehensive_results <- drcHelper:::comprehensive_phi_comparison(   successes = second_arcsin_data$Immobile,   totals = second_arcsin_data$Total,   doses = second_arcsin_data$Dose ) #> Comprehensive Phi Comparison Across Methods #> ======================================================================  #>  Scoring_Method simple trend_adjusted Difference #>           doses   18.9           1.95      -16.9 #>           ranks   18.9           5.99      -12.9 #>       log_doses   18.9           7.63      -11.2 #>    equal_spaced   18.9           5.99      -12.9 #>                     Interpretation #>  Strong overdispersion (trend-adj) #>  Strong overdispersion (trend-adj) #>  Strong overdispersion (trend-adj) #>  Strong overdispersion (trend-adj) #>  #> Key Findings: #> - Simple method assumes no dose-response trend #> - Trend-adjusted method removes linear dose-response before testing overdispersion #> - Large differences suggest trend-related vs. random overdispersion # Step-down test with simple phi method stepdown_simple <- stepDownTrendTestBinom(   successes = second_arcsin_data$Immobile,   totals = second_arcsin_data$Total,   doses = second_arcsin_data$Dose,   scoring = \"rank\",   alternative = \"greater\",   rao_scott = TRUE,   phi_method = \"simple\" ) #> Estimated phi = 18.857 using simple method with ranks scoring  # Step-down test with trend-adjusted phi method stepdown_trend <- stepDownTrendTestBinom(   successes = second_arcsin_data$Immobile,   totals = second_arcsin_data$Total,   doses = second_arcsin_data$Dose,   scoring = \"rank\",   alternative = \"greater\",   rao_scott = TRUE,   phi_method = \"trend_adjusted\" ) #> Estimated phi = 5.993 using trend_adjusted method with ranks scoring # Test with ranks scoring and trend-adjusted phi analysis_ranks_trend <- drcHelper:::complete_trend_analysis(   successes = second_arcsin_data$Immobile,   totals = second_arcsin_data$Total,   doses = second_arcsin_data$Dose,   scoring = \"ranks\",   alternative = \"greater\",   phi_method = \"trend_adjusted\" ) #> Performing complete trend analysis #> Scoring method: ranks  #> Phi estimation method: trend_adjusted  #> ============================================================  #>  #> Step 1: Testing for overdispersion... #> Tarone test phi estimate: 6.006  #> Simple phi estimate: 18.857  #> Trend-adjusted phi estimate: 5.993  #> Using phi = 5.993 for Rao-Scott correction #>  #> Step 2: Step-down Cochran-Armitage trend test... #> Overdispersion detected (phi = 5.993 ), applying Rao-Scott correction...  print(analysis_ranks_trend) #> $scoring_method #> [1] \"ranks\" #>  #> $phi_method #> [1] \"trend_adjusted\" #>  #> $phi_estimates #> $phi_estimates$simple #> [1] 18.85714 #>  #> $phi_estimates$trend_adjusted #> [1] 5.992918 #>  #> $phi_estimates$tarone #> [1] 6.006433 #>  #> $phi_estimates$used #> [1] 5.992918 #>  #>  #> $tarone_analysis #> $scoring_method #> [1] \"ranks\" #>  #> $doses #> [1]  0  5 10 20 40 80 #>  #> $scores #> [1] 1 2 3 4 5 6 #>  #> $dose_summary #> # A tibble: 6 × 4 #>   doses successes totals n_replicates #>   <dbl>     <dbl>  <dbl>        <int> #> 1     0         0     30            6 #> 2     5         0     30            6 #> 3    10         0     30            6 #> 4    20         0     30            6 #> 5    40         2     30            6 #> 6    80        19     30            6 #>  #> $groupwise_tarone #> $groupwise_tarone$summary #>   dose n_replicates z_statistic   p_value significant note #> 1    0            6         NaN       NaN          NA      #> 2    5            6         NaN       NaN          NA      #> 3   10            6         NaN       NaN          NA      #> 4   20            6         NaN       NaN          NA      #> 5   40            6 -0.55328334 0.5800694       FALSE      #> 6   80            6 -0.03706204 0.9704355       FALSE      #>  #> $groupwise_tarone$detailed_results #> $groupwise_tarone$detailed_results[[1]] #>  #>  Tarone's Z test #>  #> data:  successes successes from totals trials #> z = NaN, p-value = NA #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>                    0  #>  #>  #> $groupwise_tarone$detailed_results[[2]] #>  #>  Tarone's Z test #>  #> data:  successes successes from totals trials #> z = NaN, p-value = NA #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>                    0  #>  #>  #> $groupwise_tarone$detailed_results[[3]] #>  #>  Tarone's Z test #>  #> data:  successes successes from totals trials #> z = NaN, p-value = NA #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>                    0  #>  #>  #> $groupwise_tarone$detailed_results[[4]] #>  #>  Tarone's Z test #>  #> data:  successes successes from totals trials #> z = NaN, p-value = NA #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>                    0  #>  #>  #> $groupwise_tarone$detailed_results[[5]] #>  #>  Tarone's Z test #>  #> data:  successes successes from totals trials #> z = -0.55328, p-value = 0.5801 #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>           0.06666667  #>  #>  #> $groupwise_tarone$detailed_results[[6]] #>  #>  Tarone's Z test #>  #> data:  successes successes from totals trials #> z = -0.037062, p-value = 0.9704 #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>            0.6333333  #>  #>  #>  #>  #> $trend_adjusted_tarone #>  #>  Tarone's test for overdispersion (trend-adjusted) #>  #> data:  successes from totals with trend removed #> = 7.0802, p-value = 1.44e-12 #> alternative hypothesis: two.sided #>  #>  #> $phi_estimate #> [1] 6.006433 #>  #> $trend_fit #> $trend_fit$beta #> [1] 0.09619048 #>  #> $trend_fit$trend_proportions #> [1] 0.00100000 0.00100000 0.06857143 0.16476190 0.26095238 0.35714286 #>  #> $trend_fit$expected_under_trend #> [1]  0.030000  0.030000  2.057143  4.942857  7.828571 10.714286 #>  #> $trend_fit$residuals_after_trend #> [1] -0.030000 -0.030000 -2.057143 -4.942857 -5.828571  8.285714 #>  #> $trend_fit$variance_components #> [1] 0.029970 0.029970 1.916082 4.128463 5.785687 6.887755 #>  #>  #> attr(,\"class\") #> [1] \"TaroneTrendTest\" #>  #> $stepdown_standard #>  #> Step-down Cochran-Armitage test for trend (ranks scoring) (ranks scoring)  #>  #> data: successes out of totals at doses 0, 5, 10, 20, 40, 80 with ranks scoring  #>  #> Step-down results: #>              Doses_Included Statistic      P_Value #> Step 1 0, 5, 10, 20, 40, 80  6.865561 3.311526e-12 #> Step 2     0, 5, 10, 20, 40  2.013468 2.203270e-02 #> Step 3         0, 5, 10, 20  0.000000 5.000000e-01 #> Step 4             0, 5, 10  0.000000 5.000000e-01 #> Step 5                 0, 5  0.000000 5.000000e-01 #>  #> Alternative hypothesis: greater  #> NOEC: 20  #> LOEC: 40  #>  #> $stepdown_corrected #>  #> Step-down Rao-Scott corrected Cochran-Armitage test for trend (ranks scoring) (ranks scoring)  #>  #> data: successes out of totals at doses 0, 5, 10, 20, 40, 80 with ranks scoring  #>  #> Step-down results: #>              Doses_Included Statistic     P_Value #> Step 1 0, 5, 10, 20, 40, 80 2.8045091 0.002519663 #> Step 2     0, 5, 10, 20, 40 0.8224805 0.205401748 #> Step 3         0, 5, 10, 20 0.0000000 0.500000000 #> Step 4             0, 5, 10 0.0000000 0.500000000 #> Step 5                 0, 5 0.0000000 0.500000000 #>  #> Alternative hypothesis: greater  #> NOEC: 40  #> LOEC: 80  #>  #> attr(,\"class\") #> [1] \"completeTrendAnalysis\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"the-false-significance-problem","dir":"Articles","previous_headings":"","what":"The False Significance Problem","title":"Binomial Extra Variance and Trend Test","text":"traditional CA trend test may best tool dose-response patterns. particular, CA test ignores within-group dispersion - ’s purely group means. Even -dispersion corrected within group, adjusted corresponding trend assumed testing procedure. happen -dispersion within treatment group, residuals trend removal actually overdispersed, exactly happened specific data example. Secondly, Scoring systems can mask biological reality - equal weight unequal biological changes. Thirdly, linear trend assumption fails cliff data - 40 mg ../L “significance” can artifact testing assumption procedure. data pattern: 0%, 0%, 0%, 0%, 6.7%, 63.3% happens step-testing: Step 1: Test groups (0,5,10,20,40,80) - SIGNIFICANT (driven 80 mg ../L) Step 2: Test (0,5,10,20,40) - May SIGNIFICANT (driven 40 mg ../L vs others) Step 3: Test (0,5,10,20) - significant Result: NOEC = 20mg, LOEC = 40 mg ../L biologically: 40mg shows minimal effect (6.7%) real biological effect starts 80 mg ../L (63.3%) happens : 1. CA test uses LINEAR trend assumption 2. huge 80 mg ../L effect ‘pulls’ trend line 3. 40 mg ../La ppears significant relative trend 4. Actual biological threshold (cliff) ignored Given limitations, suitable approaches. Pairwise Comparisons Control Change-Point Detection BMD custom threshold tests","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"pairwise-comparison-with-control","dir":"Articles","previous_headings":"The False Significance Problem","what":"Pairwise Comparison with Control","title":"Binomial Extra Variance and Trend Test","text":"","code":"second_arcsin_data <- second_arcsin_data %>% mutate(Active = Total-Immobile) res1<- compare_to_control_fisher(second_arcsin_data,factor_col = \"Treatment\",success_col = \"Immobile\",failure_col = \"Active\",                           p.adjust.method = \"none\") res1 #>   Treatment p_value odds_ratio ci_lower ci_upper p_adjusted #> 1         5  1.0000          0        0      Inf     1.0000 #> 2        10  1.0000          0        0      Inf     1.0000 #> 3        20  1.0000          0        0      Inf     1.0000 #> 4        40  0.4915          0        0   5.2956     0.4915 #> 5        80  0.0000          0        0   0.1005     0.0000 res2 <- compare_to_control_fisher(second_arcsin_data,factor_col = \"Treatment\",success_col = \"Immobile\",failure_col = \"Active\", p.adjust.method = \"holm\") res2 #>   Treatment p_value odds_ratio ci_lower ci_upper p_adjusted #> 1         5  1.0000          0        0      Inf          1 #> 2        10  1.0000          0        0      Inf          1 #> 3        20  1.0000          0        0      Inf          1 #> 4        40  0.4915          0        0   5.2956          1 #> 5        80  0.0000          0        0   0.1005          0"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"exact-cochran-armitage-on-replicate-averages","dir":"Articles","previous_headings":"The False Significance Problem","what":"Exact Cochran-Armitage on replicate averages","title":"Binomial Extra Variance and Trend Test","text":"Another important aspect difference exact test p-value asymptotic p-value, apart sample size used.","code":"ca_dose_40 <- second_arcsin_data %>% dplyr::group_by(Dose) %>% summarise(nrep=n(),p=mean(immob),ntot=sum(Total),p2= sum(Immobile)/sum(Total)) %>% filter(Dose!= 80) a1 <- CATTexact::catt_exact(ca_dose_40$Dose,ca_dose_40$nrep,ceiling(ca_dose_40$p*ca_dose_40$nrep)) a2 <- CATTexact::catt_exact(ca_dose_40$Dose,ca_dose_40$ntot,ceiling(ca_dose_40$p*ca_dose_40$ntot))   ca_dose_80 <- second_arcsin_data %>% dplyr::group_by(Dose) %>% summarise(nrep=n(),p=mean(immob),ntot=sum(Total),p2= sum(Immobile)/sum(Total))  b1 <- CATTexact::catt_exact(ca_dose_80$Dose,ca_dose_80$nrep,ceiling(ca_dose_80$p*ca_dose_80$nrep)) b2 <- CATTexact::catt_exact(ca_dose_80$Dose,ca_dose_80$ntot,ceiling(ca_dose_80$p*ca_dose_80$ntot)) rbind(data.frame(Dose=40,a1,sampe.size=6),       data.frame(Dose=40,a2,sampe.size=30),       data.frame(Dose=80,b1,sampe.size=6),       data.frame(Dose=80,b2,sampe.size=30))"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Binomial_Extra_Variance.html","id":"change-point-analysis","dir":"Articles","previous_headings":"The False Significance Problem","what":"Change Point Analysis","title":"Binomial Extra Variance and Trend Test","text":"","code":"#' Detect change points in dose-response detect_change_point <- function(successes, totals, doses) {      group_data <- data.frame(successes, totals, doses) %>%     dplyr::group_by(doses) %>%     dplyr::summarise(       successes = sum(successes),       totals = sum(totals),       proportion = sum(successes) / sum(totals),       .groups = 'drop'     ) %>%     dplyr::arrange(doses)      cat(\"Change Point Analysis:\\n\")   cat(\"=====================\\n\")      # Look for largest jump in proportions   prop_diffs <- diff(group_data$proportion)   max_jump_idx <- which.max(prop_diffs)      cat(\"Proportion differences between consecutive doses:\\n\")   diff_df <- data.frame(     From_Dose = group_data$doses[-nrow(group_data)],     To_Dose = group_data$doses[-1],     Proportion_Jump = round(prop_diffs, 3)   )   print(diff_df, row.names = FALSE)      cat(\"\\nLargest jump: from\", group_data$doses[max_jump_idx],        \"to\", group_data$doses[max_jump_idx + 1], \"\\n\")   cat(\"Jump size:\", round(prop_diffs[max_jump_idx], 3), \"\\n\")      cat(\"\\nSuggested biological threshold:\", group_data$doses[max_jump_idx + 1], \"\\n\")      return(list(     change_point = group_data$doses[max_jump_idx + 1],     jump_size = prop_diffs[max_jump_idx]   )) }  change_point <- detect_change_point(   second_arcsin_data$Immobile,   second_arcsin_data$Total,   second_arcsin_data$Dose ) #> Change Point Analysis: #> ===================== #> Proportion differences between consecutive doses: #>  From_Dose To_Dose Proportion_Jump #>          0       5           0.000 #>          5      10           0.000 #>         10      20           0.000 #>         20      40           0.067 #>         40      80           0.567 #>  #> Largest jump: from 40 to 80  #> Jump size: 0.567  #>  #> Suggested biological threshold: 80"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Count_Data.html","id":"testing-approaches","dir":"Articles","previous_headings":"","what":"Testing Approaches","title":"Count Data in General","text":"Usually count data, treat continuous sometimes transformations variance stabilized across treatment groups derive NOEC. Transformation data need also careful interpretation effect size estimation corresponding confidence intervals. also relatively new approach proposed called CPCAT. application domain however limited valid strictly Poisson data, validated used package.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Count_Data.html","id":"poisson-or-non-poisson","dir":"Articles","previous_headings":"Testing Approaches","what":"Poisson or Non-Poisson?","title":"Count Data in General","text":"understand , think Poisson distribution distribution describes. actually emerges basic properties natural counting process. example, count number customers arriving store, number defects manufacturing, number rare events fixed time period, number occurrences fixed spatial area. assumptions behind counting processes : Events occur independently. Events occur constant average rate Events occur exactly simultaneously probability event proportional time interval key parameter Poisson distribution mean, actually rate parameter \\(\\lambda\\). Poisson distribution also particular mean-variance relationship, many real-world counting processes, variability (variance) increases average count (mean). Poisson distribution naturally captures unique property mean equals variance. However, assumptions independence constant rate violated, ’s overdispersion (variance exceeding mean), distributions like Negative Binomial might appropriate. Actually, say Poisson distribution often appropriate choice modeling pitfall trap counts soil core counts soil organisms. ’s : Violation Independence: Soil organisms typically show aggregated distributions Individuals randomly distributed cluster favorable microhabitats Social behavior environmental preferences lead spatial clustering Non-constant Rate: Abundance vary environmental conditions Seasonal daily patterns affect capture sampling probability Spatial heterogeneity habitat quality influences distribution Overdispersion underdispersion Variance counts typically exceeds mean. (-dispersion also occur chance lots zeros small numbers certain species) Clustering behavior leads extreme counts expected Poisson Environmental heterogeneity increases variability Heterogeneous variance across treatment groups. Often approaches assuming Poisson, like CPCAT, also starting common mean common variance null distribution, neither true reality. appropriate approaches modelling might Negative Binomial distribution (handles overdispersion), zero-inflated models (many zero counts), mixed models (account spatial temporal dependencies), spatial point process models (explicitly account spatial patterns). primary goal determining NOEC (Observed Effect Concentration), simpler approaches often prove sufficient. Traditional methods, treating counts continuous data normal distribution assumptions, appropriate variance structure considerations, suitable data transformations can provide robust reliable conclusions. complex models might offer additional insights, may necessarily improve practical utility analysis, particularly regulatory purposes transparency reproducibility crucial.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Count_Data.html","id":"additional-notes","dir":"Articles","previous_headings":"","what":"Additional Notes","title":"Count Data in General","text":"example, Poisson distribution rate 100 time window 1, count 137 unlikely coming distribution 120 possibly occuring 95% confidence level. hand, rare oberve 120 normal distribution 100 mean sd 10. Similarly small numbers, like mean 4 sd 2, 8 likely observed Poisson normal distribution.","code":"###  Fisher's Exact Test for Count Data poisson.test(120, 1,r=100) #>  #>  Exact Poisson test #>  #> data:  120 time base: 1 #> number of events = 120, time base = 1, p-value = 0.05088 #> alternative hypothesis: true event rate is not equal to 100 #> 95 percent confidence interval: #>   99.49193 143.49059 #> sample estimates: #> event rate  #>        120 pnorm(120,mean=100,sd=10) #> [1] 0.9772499  poisson.test(8, 1,r=4) #>  #>  Exact Poisson test #>  #> data:  8 time base: 1 #> number of events = 8, time base = 1, p-value = 0.06945 #> alternative hypothesis: true event rate is not equal to 4 #> 95 percent confidence interval: #>   3.453832 15.763189 #> sample estimates: #> event rate  #>          8 pnorm(8,mean=4,sd=2) #> [1] 0.9772499"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Count_Data.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Count Data in General","text":"Quasi-Poisson vs. negative binomial regression: model overdispersed count data? Revisiting analysis pipeline overdispersed Poisson binomial data Check -dispersion Stackoverflow post overdispersion Poisson","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Dunnetts_Test_for_Data_with_Hierarchical_Structure.html","id":"homoscedastic-mixed-model","dir":"Articles","previous_headings":"Perform Dunnett Test for Different type of Models","what":"Homoscedastic mixed model","title":"Dunnett's Test for Data with Hierarchical Structure","text":"equivalent ","code":"# 1. Homoscedastic mixed model (equivalent to ind_model1) sim_data$Treatment <- factor(sim_data$Dose) result1 <- dunnett_test(   data = sim_data,   response_var = \"Response\",   dose_var = \"Treatment\",  # Using your Treatment factor   tank_var = \"Tank\",   include_random_effect = TRUE,   variance_structure = \"homoscedastic\" ) result1 #> Dunnett Test Results #> ------------------- #> Model type: Mixed model with homoscedastic errors  #> Control level: 0  #> Alpha level: 0.05  #>  #> Results Table: #>  comparison   estimate std.error  statistic      p.value  conf.low conf.high #>       5 - 0  0.2648670  1.762098  0.1503135 9.996387e-01 -4.041493  4.571227 #>      10 - 0 -0.5573896  1.762098 -0.3163216 9.934653e-01 -4.863750  3.748971 #>      15 - 0 10.5099513  1.762098  5.9644545 1.252943e-08  6.203591 14.816312 #>      20 - 0 18.6355902  1.762098 10.5757988 0.000000e+00 14.329230 22.941950 #>  significant #>        FALSE #>        FALSE #>         TRUE #>         TRUE #>  #> NOEC Determination: #> NOEC determined as 10 ind_model1 <- lmer(Response ~ Treatment + (1 | Tank),sim_data) ## homoscedastic errors # Apply Dunnett test to mixed model ind_dunnett1 <- glht(ind_model1, linfct = mcp(Treatment = \"Dunnett\"))  s1 <- summary(ind_dunnett1) result1$results_table$p.value - s1$test$pvalues < 1e-04 #> [1] FALSE FALSE  TRUE  TRUE"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Dunnetts_Test_for_Data_with_Hierarchical_Structure.html","id":"heteroscedastic-mixed-model","dir":"Articles","previous_headings":"Perform Dunnett Test for Different type of Models","what":"Heteroscedastic mixed model","title":"Dunnett's Test for Data with Hierarchical Structure","text":"","code":"# 2. Heteroscedastic mixed model (equivalent to  mod.nlme) result2 <- dunnett_test(   data = sim_data,   response_var = \"Response\",   dose_var = \"Treatment\",   tank_var = \"Tank\",   include_random_effect = FALSE,   variance_structure = \"heteroscedastic\" )   result2 #> Dunnett Test Results #> ------------------- #> Model type: Fixed model with heteroscedastic errors  #> Control level: 0  #> Alpha level: 0.05  #>  #> Results Table: #>  comparison   estimate std.error  statistic   p.value  conf.low conf.high #>       5 - 0  0.2648670 0.5760347  0.4598109 0.9761703 -1.146160  1.675894 #>      10 - 0 -0.5573896 0.4790326 -1.1635734 0.6085235 -1.730805  0.616026 #>      15 - 0 10.5099513 0.5216412 20.1478537 0.0000000  9.232164 11.787739 #>      20 - 0 18.6355902 0.5972666 31.2014594 0.0000000 17.172554 20.098626 #>  significant #>        FALSE #>        FALSE #>         TRUE #>         TRUE #>  #> NOEC Determination: #> NOEC determined as 10 mod.nlme <- nlme::lme(Response ~ Treatment ,                          random  = ~ 1 | Tank,                         weights = varIdent(form= ~1|Treatment),                        data    = sim_data) ind_dunnett2 <- glht(mod.nlme, linfct = mcp(Treatment = \"Dunnett\")) s2 <- summary(ind_dunnett2) result2$results_table$p.value - s2$test$pvalues < 1e-05 #> [1]  TRUE FALSE  TRUE  TRUE result2$results_table$estimate -s2$test$coefficients #>        5 - 0       10 - 0       15 - 0       20 - 0  #> 9.769963e-15 8.548717e-15 7.105427e-15 7.105427e-15"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Dunnetts_Test_for_Data_with_Hierarchical_Structure.html","id":"homoscedastic-fixed-effect-model","dir":"Articles","previous_headings":"Perform Dunnett Test for Different type of Models","what":"Homoscedastic fixed effect model","title":"Dunnett's Test for Data with Hierarchical Structure","text":"equivalent :","code":"# Tank level (regular linear model) tank_data$Treatment <- factor(tank_data$Dose) result3 <- dunnett_test(   data = tank_data,   response_var = \"Response\",   dose_var = \"Treatment\",   tank_var = \"Tank\",   include_random_effect = FALSE,   variance_structure = \"homoscedastic\" ) result3 #> Dunnett Test Results #> ------------------- #> Model type: Fixed model with homoscedastic errors  #> Control level: 0  #> Alpha level: 0.05  #>  #> Results Table: #>  comparison   estimate std.error  statistic      p.value  conf.low conf.high #>       5 - 0  0.2648670  1.762097  0.1503135 9.995932e-01 -4.542552  5.072286 #>      10 - 0 -0.5573896  1.762097 -0.3163217 9.927925e-01 -5.364808  4.250029 #>      15 - 0 10.5099513  1.762097  5.9644562 6.506358e-05  5.702533 15.317370 #>      20 - 0 18.6355902  1.762097 10.5758018 4.527548e-09 13.828172 23.443009 #>  significant #>        FALSE #>        FALSE #>         TRUE #>         TRUE #>  #> NOEC Determination: #> NOEC determined as 10 # Tank level (regular linear model) tank_model <- lm(Response ~ Treatment, data = tank_data) summary(glht(tank_model,linfct = mcp(Treatment=\"Dunnett\"))) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Treatment, data = tank_data) #>  #> Linear Hypotheses: #>             Estimate Std. Error t value Pr(>|t|)     #> 5 - 0 == 0    0.2649     1.7621   0.150    1.000     #> 10 - 0 == 0  -0.5574     1.7621  -0.316    0.993     #> 15 - 0 == 0  10.5100     1.7621   5.964   <1e-04 *** #> 20 - 0 == 0  18.6356     1.7621  10.576   <1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Dunnetts_Test_for_Data_with_Hierarchical_Structure.html","id":"heteroscedastic-fixed-effect-model","dir":"Articles","previous_headings":"Perform Dunnett Test for Different type of Models","what":"Heteroscedastic fixed effect model","title":"Dunnett's Test for Data with Hierarchical Structure","text":"equivalent :","code":"result4 <- dunnett_test(   data = tank_data,   response_var = \"Response\",   dose_var = \"Treatment\",   tank_var = NULL,   include_random_effect = FALSE,   variance_structure = \"heteroscedastic\" ) result4 #> Dunnett Test Results #> ------------------- #> Model type: Fixed model with heteroscedastic errors  #> Control level: 0  #> Alpha level: 0.05  #>  #> Results Table: #>  comparison   estimate std.error  statistic      p.value  conf.low conf.high #>       5 - 0  0.2648670  1.829785  0.1447531 9.997148e-01 -4.216766  4.746500 #>      10 - 0 -0.5573896  1.424783 -0.3912102 9.866375e-01 -4.047064  2.932285 #>      15 - 0 10.5099513  1.548110  6.7888938 2.287759e-11  6.718217 14.301686 #>      20 - 0 18.6355902  1.924281  9.6844412 0.000000e+00 13.922510 23.348670 #>  significant #>        FALSE #>        FALSE #>         TRUE #>         TRUE #>  #> NOEC Determination: #> NOEC determined as 10 library(nlme) gls0 <- gls(Response ~ Treatment, data=tank_data,weights=varIdent(form= ~1|Treatment)) ind_gls0 <- glht(gls0, linfct = mcp(Treatment = \"Dunnett\"))  s4 <- summary(ind_gls0) result4$results_table$estimate -s4$test$coefficients #>  5 - 0 10 - 0 15 - 0 20 - 0  #>      0      0      0      0 result4$results_table$p.value - s4$test$pvalues < 1e-05 #> [1] TRUE TRUE TRUE TRUE"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/EFSA-Criteria.html","id":"efsa-ecx-reliability","dir":"Articles","previous_headings":"","what":"EFSA: ECx reliability","title":"EFSA Criteria","text":"EFSA published 2019 “Outcome Pesticides Peer Review Meeting general recurring issues ecotoxicology”, additional reliability criteria proposed. DOI: https://doi.org/10.2903/sp.efsa.2019.EN-1673","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/EFSA-Criteria.html","id":"model-comparison-criteria","dir":"Articles","previous_headings":"EFSA: ECx reliability","what":"Model Comparison Criteria","title":"EFSA Criteria","text":"Apart generic model comparison criteria, like scaled residuals, visual fit, AIC, lack--fit test goodness--fit test, etc., EFSA proposed use following two criteria: Normalized Width Normalized width can calculated calc Overlapping EC10, 20 50 Certainty protection classified based relationship EC10 EC20/EC50 confidence intervals Steepness curve Steepness defined ratio EC\\(_{10}\\) EC\\(_{50}\\). certainty protection level steepness curves can calculated calcSteepnessOverlap(mod = mod, trend = \"Decrease\").","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/EFSA-Criteria.html","id":"model-selection-and-model-averaging","dir":"Articles","previous_headings":"","what":"Model Selection and Model Averaging","title":"EFSA Criteria","text":"Model selection involves choosing best statistical model set candidate models based data hand. Criteria Model Selection based criteria like Akaike Information Criterion (AIC), residuals check, combination several criteria, etc. Model averaging technique combines predictions multiple models improve accuracy robustness. approach particularly useful uncertainty model best. Bayesian Model Averaging (BMA) assigns weights models based posterior probabilities, allowing weighted average predictions. method incorporates uncertainty model selection directly predictions. Frequentist Model Averaging involves averaging predictions models selected based criteria like AIC BIC, without Bayesian framework, weight directly come AIC. Model averaging incoporates model uncertainty analysis can improve --sample predictive performance compared single models. Research still needed developing efficient algorithms model averaging improving interpretability facilitate application techniques regulatory decision-making.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/EFSA-Criteria.html","id":"other-suggested-criteria","dir":"Articles","previous_headings":"","what":"Other suggested Criteria","title":"EFSA Criteria","text":"Green JW, Foudoulakis M, Fredricks T, Maul J, Plautz S, Valverde P, Schapaugh , Sopko X, Gao Z, Bean T 2022. Statistical Analysis Avian Reproduction Studies. Environmental Sciences Europe. 34:31 https://doi.org/10.1186/s12302-022-00603-5 Model predictions consistent observations tested concentrations, especially control. Visually, fitted curve appear fit data across entire range test concentrations. Since x% effect estimated model predicted control mean, especially important model provide good agreement observed control mean response. Confidence interval ECx “overly” wide. hard rule given define overly wide means, confidence interval ECx spans entire range tested concentrations including 0, overly wide estimate little value risk assessment. every parameter, confidence interval include 0. eliminate overly parameterized models reduce model instability. Prediction interval predicted response ECx contain estimated control mean. Otherwise, x% effect indistinguishable effect. Figure 15 illustrates criterion.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/EFSA-Criteria.html","id":"us-epa-bmds-criteria","dir":"Articles","previous_headings":"Additional Criteria in Guidances","what":"US EPA BMDS Criteria","title":"EFSA Criteria","text":"BMD:BMDL ratio used BMDS program part model choice criteria. indicator uncertainty level (much information provided) BMD given experimental design assuming model correct. similar NW criteria used EFSA. BMD:BMDL ratio >20 results model placed “questionable” bin BMD:BMDL ratio >5 result “caution” flag. User-specified modifications decision logic also possible.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/EFSA-Criteria.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"EFSA Criteria","text":"OECD (2006), Current Approaches Statistical Analysis Ecotoxicity Data: guidance application (annexes publication exist separate document), OECD Series Testing Assessment, . 54, OECD Publishing, Paris, https://doi.org/10.1787/9789264085275-en.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Equivalence-Testing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Equivalence Testing","text":"Equivalence testing statistical testing approach used determine whether two treatments interventions produce effects practically within predefined margin difference. method particularly useful fields like pharmaceuticals, demonstrating new drug worse existing one specified margin crucial. Equivalence testing closely related difference testing. latter focuses identifying whether difference exists controlling false positive error, former aims show difference within predefined acceptable range, controlling false negative error difference testing scenario. design interpretation equivalence tests can complex traditional difference tests, requiring careful consideration equivalence margin, called biologically relevant effect size. null alternative hypotheses equivalence tests \\[ H_0: | \\mu_1 - \\mu_0 | > \\Delta \\] \\[ H_1: | \\mu_1 - \\mu_0 | \\leq \\Delta \\] \\(\\mu_1\\) \\(\\mu_0\\) means two treatments, \\(\\Delta\\) equivalence margin. also non-inferiority non-superiority cases, nulls \\(\\mu_1 - \\mu_0 <= - \\Delta\\) \\(\\mu_1 - \\mu_0 > \\Delta\\) Sometimes tests can formulated standardized differences means. Depending frame problem, multiplicative model ratios--control comparisons used. Related approach available \\(\\alpha\\) level equivalence testing probability making Type error, occurs null hypothesis incorrectly rejected. means concluding treatments equivalent . \\(\\beta\\) difference testing probability making Type II error, occurs null hypothesis rejected . means failing detect difference (concluding equivalence) one actually exists. equivalence testing, low alpha level crucial ensure conclusion equivalence reliable. Conversely, difference testing, low beta level important ensure true difference detected. hand, \\(\\alpha\\) level difference testing playing similarly complementary role \\(\\beta\\) equivalence testing.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Equivalence-Testing.html","id":"the-confusion","dir":"Articles","previous_headings":"","what":"The Confusion","title":"Equivalence Testing","text":"thinking confidence interval (CI) direction, equivalence testing uses 90% CI confidence level 95% (\\(\\alpha = 0.05\\)). illustrate . switch 95% 90% confidence intervals equivalence testing actually simple mathematical approach maintain overall 5% Type error rate (95% confidence) conclusion equivalence. equivalence testing, need show upper lower bounds confidence interval fall within predefined zone indifference. use 90% confidence interval, : 5% error probability upper tail 5% error probability lower tail (100% - 90% = 10%, split equally two tails) equivalence concluded, need bounds fall within zone indifference. probability happening chance (treatments aren’t truly equivalent) approximately 5% : multiply probability success bound (0.95 × 0.95 ≈ 0.90) gives us 95% confidence overall conclusion equivalence ’re using 90% confidence interval tool, end result gives us 95% confidence conclusion equivalence. approach effectively controls overall Type error rate traditional 5% level, maintaining statistical rigor expect hypothesis testing. equivalence testing protocols specifically call 90% confidence intervals - ’s reduction confidence standards, rather mathematical adjustment achieve desired 95% confidence final conclusion equivalence.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Equivalence-Testing.html","id":"impacts-of-changing-from-difference-to-equivalence-testing","dir":"Articles","previous_headings":"","what":"Impacts of changing from difference to equivalence testing","title":"Equivalence Testing","text":"Equivalence testing often requires larger sample sizes achieve sufficient power, can resource-intensive. design interpretation equivalence tests can complex traditional difference tests, requiring careful consideration “equivalence margin”.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Equivalence-Testing.html","id":"hypothetical-examples","dir":"Articles","previous_headings":"Impacts of changing from difference to equivalence testing","what":"Hypothetical Examples","title":"Equivalence Testing","text":"simulate dose response","code":"library(drcHelper) n_doses <- 5 dose_range <- c(0,20) ## Define a threshold dose response threshold_idx  <-  3 ## kind of global doses <- seq(dose_range[1], dose_range[2], length.out = n_doses) response_fn <- function(dose, max_effect) {   base_response <- 100   result <- rep(base_response, length(dose))   threshold_dose <- doses[threshold_idx]   high_doses <- dose >= threshold_dose   if (any(high_doses)) {     max_high_dose <- max(doses)     relative_position <- (dose[high_doses] - threshold_dose) / (max_high_dose - threshold_dose)     result[high_doses] <- base_response - relative_position * max_effect   }   return(result) }   max_effect <- 5 sim_data <- simulate_dose_response(   n_doses = 5,   dose_range = c(0,20),   m_tanks = 10,   var_tank = 3,  # Pass the dose-specific variances, note here it should be a vector instead of a singe number.   include_individuals = FALSE,  # Tank-level data only   response_function = function(dose) response_fn(dose, max_effect) ) theme_set(theme_bw()) prelimPlot3(sim_data) mod <- lm(Response~Dose, data=sim_data %>% dplyr::mutate(Dose=factor(Dose))) summary(mod) #>  #> Call: #> lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -3.5719 -1.1151  0.0437  1.1540  4.5715  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  99.2355     0.6003 165.302  < 2e-16 *** #> Dose5         0.4550     0.8490   0.536   0.5947     #> Dose10        0.5505     0.8490   0.648   0.5200     #> Dose15       -1.4720     0.8490  -1.734   0.0898 .   #> Dose20       -4.0345     0.8490  -4.752 2.09e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 1.898 on 45 degrees of freedom #> Multiple R-squared:  0.4789, Adjusted R-squared:  0.4325  #> F-statistic: 10.34 on 4 and 45 DF,  p-value: 5.039e-06 library(multcomp) summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"))) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>             Estimate Std. Error t value Pr(>|t|)     #> 5 - 0 == 0    0.4550     0.8490   0.536    0.954     #> 10 - 0 == 0   0.5505     0.8490   0.648    0.915     #> 15 - 0 == 0  -1.4720     0.8490  -1.734    0.258     #> 20 - 0 == 0  -4.0345     0.8490  -4.752   <0.001 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method)  summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"), alternative=\"greater\", rhs=-10 )) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>               Estimate Std. Error t value Pr(>t)     #> 5 - 0 <= -10    0.4550     0.8490  12.315 <1e-08 *** #> 10 - 0 <= -10   0.5505     0.8490  12.427 <1e-08 *** #> 15 - 0 <= -10  -1.4720     0.8490  10.045 <1e-08 *** #> 20 - 0 <= -10  -4.0345     0.8490   7.026 <1e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"), alternative=\"less\", rhs= 10 )) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>              Estimate Std. Error t value Pr(<t)     #> 5 - 0 >= 10    0.4550     0.8490  -11.24 <1e-10 *** #> 10 - 0 >= 10   0.5505     0.8490  -11.13 <1e-10 *** #> 15 - 0 >= 10  -1.4720     0.8490  -13.51 <1e-10 *** #> 20 - 0 >= 10  -4.0345     0.8490  -16.53 <1e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) confint(glht(mod,linfct = mcp(Dose=\"Dunnett\")),level=0.9) #>  #>   Simultaneous Confidence Intervals #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Quantile = 2.2218 #> 90% family-wise confidence level #>   #>  #> Linear Hypotheses: #>             Estimate lwr     upr     #> 5 - 0 == 0   0.4550  -1.4314  2.3413 #> 10 - 0 == 0  0.5505  -1.3359  2.4368 #> 15 - 0 == 0 -1.4720  -3.3583  0.4144 #> 20 - 0 == 0 -4.0345  -5.9209 -2.1482 max_effect <- 10 sim_data <- simulate_dose_response(   n_doses = 5,   dose_range = c(0,20),   m_tanks = 10,   var_tank = 3,  # Pass the dose-specific variances, note here it should be a vector instead of a singe number.   include_individuals = FALSE,  # Tank-level data only   response_function = function(dose) response_fn(dose, max_effect) ) theme_set(theme_bw()) prelimPlot3(sim_data) mod <- lm(Response~Dose, data=sim_data %>% dplyr::mutate(Dose=factor(Dose))) summary(mod) #>  #> Call: #> lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -4.2513 -1.0514 -0.0348  0.9322  3.7530  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  99.5264     0.5884 169.154  < 2e-16 *** #> Dose5         0.9532     0.8321   1.146    0.258     #> Dose10        0.8564     0.8321   1.029    0.309     #> Dose15       -4.5858     0.8321  -5.511 1.65e-06 *** #> Dose20       -8.4936     0.8321 -10.208 2.72e-13 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 1.861 on 45 degrees of freedom #> Multiple R-squared:  0.8167, Adjusted R-squared:  0.8004  #> F-statistic: 50.13 on 4 and 45 DF,  p-value: 5.108e-16 library(multcomp) summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"))) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>             Estimate Std. Error t value Pr(>|t|)     #> 5 - 0 == 0    0.9532     0.8321   1.146    0.611     #> 10 - 0 == 0   0.8564     0.8321   1.029    0.693     #> 15 - 0 == 0  -4.5858     0.8321  -5.511   <1e-04 *** #> 20 - 0 == 0  -8.4936     0.8321 -10.208   <1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method)  summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"), alternative=\"greater\", rhs=-10 )) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>               Estimate Std. Error t value Pr(>t)     #> 5 - 0 <= -10    0.9532     0.8321  13.163 <0.001 *** #> 10 - 0 <= -10   0.8564     0.8321  13.047 <0.001 *** #> 15 - 0 <= -10  -4.5858     0.8321   6.507 <0.001 *** #> 20 - 0 <= -10  -8.4936     0.8321   1.810  0.113     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"), alternative=\"less\", rhs= 10 )) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>              Estimate Std. Error t value Pr(<t)     #> 5 - 0 >= 10    0.9532     0.8321  -10.87 <1e-10 *** #> 10 - 0 >= 10   0.8564     0.8321  -10.99 <1e-10 *** #> 15 - 0 >= 10  -4.5858     0.8321  -17.53 <1e-10 *** #> 20 - 0 >= 10  -8.4936     0.8321  -22.23 <1e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) confint(glht(mod,linfct = mcp(Dose=\"Dunnett\")),level=0.9) #>  #>   Simultaneous Confidence Intervals #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Quantile = 2.2223 #> 90% family-wise confidence level #>   #>  #> Linear Hypotheses: #>             Estimate lwr      upr      #> 5 - 0 == 0    0.9532  -0.8960   2.8024 #> 10 - 0 == 0   0.8564  -0.9928   2.7056 #> 15 - 0 == 0  -4.5858  -6.4350  -2.7366 #> 20 - 0 == 0  -8.4936 -10.3428  -6.6444 max_effect <- 15 threshold_idx <- 1  response_fn <- function(dose, max_effect) {       base_response <- 100       mid_dose <- mean(dose_range)       return(base_response - max_effect * (1 - ((dose - mid_dose)/(mid_dose))^2)) ## Here I need a change.  }   response_fn <- function(dose, lower = 100, upper = 0, ED50 = 10, slope = 1) {       lower + (upper - lower) / (1 + exp(-slope * (dose - ED50)))   }   set.seed(456) sim_data <- simulate_dose_response(   n_doses = 10,   dose_range = c(0,20),   m_tanks = 5,   var_tank = 20,  # Pass the dose-specific variances, note here it should be a vector instead of a singe number.   include_individuals = FALSE,  # Tank-level data only   response_function = function(dose) response_fn(dose, max_effect) ) theme_set(theme_bw())  sim_data <-sim_data %>% dplyr::mutate(Dose = round(Dose, 2)) prelimPlot3(sim_data) mod <- lm(Response~Dose, data=sim_data %>% dplyr::filter(Dose <=15) %>%              dplyr::mutate(Dose=factor(Dose))) summary(mod) #>  #> Call: #> lm(formula = Response ~ Dose, data = sim_data %>% dplyr::filter(Dose <=  #>     15) %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -7.8720 -3.3567  0.5979  3.1387  5.9788  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)   13.189      1.945   6.780 2.31e-07 *** #> Dose2.22       3.771      2.751   1.371  0.18140     #> Dose4.44       3.182      2.751   1.157  0.25722     #> Dose6.67       8.351      2.751   3.036  0.00514 **  #> Dose8.89      -4.986      2.751  -1.812  0.08065 .   #> Dose11.11     -8.814      2.751  -3.204  0.00337 **  #> Dose13.33    -15.047      2.751  -5.469 7.70e-06 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 4.35 on 28 degrees of freedom #> Multiple R-squared:  0.7893, Adjusted R-squared:  0.7441  #> F-statistic: 17.48 on 6 and 28 DF,  p-value: 2.64e-08 library(multcomp)   summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"), alternative=\"greater\", rhs=-10 )) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::filter(Dose <=  #>     15) %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>                  Estimate Std. Error t value Pr(>t)     #> 2.22 - 0 <= -10     3.771      2.751   5.005 <0.001 *** #> 4.44 - 0 <= -10     3.182      2.751   4.791 <0.001 *** #> 6.67 - 0 <= -10     8.351      2.751   6.670 <0.001 *** #> 8.89 - 0 <= -10    -4.986      2.751   1.822  0.149     #> 11.11 - 0 <= -10   -8.814      2.751   0.431  0.709     #> 13.33 - 0 <= -10  -15.047      2.751  -1.834  0.999     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"), alternative=\"less\", rhs= 10 )) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::filter(Dose <=  #>     15) %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>                 Estimate Std. Error t value Pr(<t)     #> 2.22 - 0 >= 10     3.771      2.751  -2.264 0.0667 .   #> 4.44 - 0 >= 10     3.182      2.751  -2.478 0.0431 *   #> 6.67 - 0 >= 10     8.351      2.751  -0.599 0.6369     #> 8.89 - 0 >= 10    -4.986      2.751  -5.447 <0.001 *** #> 11.11 - 0 >= 10   -8.814      2.751  -6.839 <0.001 *** #> 13.33 - 0 >= 10  -15.047      2.751  -9.104 <0.001 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method)  summary(glht(mod,linfct = mcp(Dose=\"Dunnett\"))) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::filter(Dose <=  #>     15) %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Linear Hypotheses: #>                Estimate Std. Error t value Pr(>|t|)     #> 2.22 - 0 == 0     3.771      2.751   1.371   0.5692     #> 4.44 - 0 == 0     3.182      2.751   1.157   0.7183     #> 6.67 - 0 == 0     8.351      2.751   3.036   0.0248 *   #> 8.89 - 0 == 0    -4.986      2.751  -1.812   0.3011     #> 11.11 - 0 == 0   -8.814      2.751  -3.204   0.0167 *   #> 13.33 - 0 == 0  -15.047      2.751  -5.469   <0.001 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) confint(glht(mod,linfct = mcp(Dose=\"Dunnett\")),level=0.9) #>  #>   Simultaneous Confidence Intervals #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: lm(formula = Response ~ Dose, data = sim_data %>% dplyr::filter(Dose <=  #>     15) %>% dplyr::mutate(Dose = factor(Dose))) #>  #> Quantile = 2.4082 #> 90% family-wise confidence level #>   #>  #> Linear Hypotheses: #>                Estimate lwr      upr      #> 2.22 - 0 == 0    3.7705  -2.8548  10.3958 #> 4.44 - 0 == 0    3.1819  -3.4434   9.8072 #> 6.67 - 0 == 0    8.3512   1.7259  14.9765 #> 8.89 - 0 == 0   -4.9864 -11.6116   1.6389 #> 11.11 - 0 == 0  -8.8137 -15.4390  -2.1884 #> 13.33 - 0 == 0 -15.0467 -21.6720  -8.4214"},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Equivalence-Testing.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Equivalence Testing","text":"Dilba, G., Bretz, F., Guiard, V., Hothorn, L. . (2004). Simultaneous confidence intervals ratios applications comparison several treatments control. Methods Information Medicine 43, 465–469. Djira G, Hasler M, Gerhard D, Segbehoe L, Schaarschmidt F (2025). mratios: Ratios Coefficients General Linear Model. R package version 1.4.4, https://CRAN.R-project.org/package=mratios.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_Analysis_Workflow.html","id":"example-routine-analysis-flowcharts","dir":"Articles","previous_headings":"","what":"Example Routine Analysis Flowcharts","title":"Example_Analysis_Workflow","text":"Typical flowcharts derving NOECs ECx shown Figure 1 , Figure 2 Figure 3 . dose response hormesis effects highly erratic, consulted statistician. Figure 1: NOEC Monotonic Figure 2: NOEC non-Monotonic Figure 3: ECx Monotonic vignette, going use dataset oecd201 example.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_Analysis_Workflow.html","id":"assumptions-check","dir":"Articles","previous_headings":"","what":"Assumptions check","title":"Example_Analysis_Workflow","text":"Pretests checks conducted testing, however, assumptions also checked modelling, using holistic approach. follow routine procedure. allow choice appropriate statistical tests, normality homoscedasticity (variance homogeneity) certain endpoint (e.g., shoot dry weight) data checked.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_Analysis_Workflow.html","id":"an-overview-of-the-endpoints","dir":"Articles","previous_headings":"","what":"An overview of the endpoints","title":"Example_Analysis_Workflow","text":"NOER, LOER, ER25 ER50 survival, plant height shoot dry weight expressed g .s./ha summarized plant species final assessment (21 days application) can found following tables.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"example-usage-of-the-rscabs-functions-in-drchelper","dir":"Articles","previous_headings":"","what":"Example Usage of the RSCABS functions in drcHelper","title":"RSCABS","text":"function drcHelper run_threshold_RSCA run_all_threshold_tests. latter performs Rao-Scott adjusted Cochran-Armitage trend test slices (multiple injury thresholds) providing comprehensive analysis dose-response relationships different severity levels. also outputs invisible components including detailed interim results tested threshold level. step-procedure can performed using step_down_RSCABS.","code":"library(drcHelper) library(tidyverse) source(\"../knitr-setup.R\") # Example data with increasing trend in injury rates # Create the simulated fish data sim_data_1<- tibble::tibble(   treatment = c(rep(\"Control\", 8), rep(\"Low\", 4), rep(\"Medium\", 4), rep(\"High\", 4)),   tank = c(paste0(\"C\", 1:8), paste0(\"L\", 1:4), paste0(\"M\", 1:4), paste0(\"H\", 1:4)),   S0 = c(3, 2, 4, 3, 2, 1, 2, 3, 3, 3, 4, 2, 2, 3, 2, 2, 2, 3, 1, 2),   S1 = c(1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0),   S2 = c(0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1),   S3 = c(0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1),   total = c(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4) )  # Ensure treatment is an ordered factor for proper plotting sim_data_1$treatment <- factor(sim_data_1$treatment,                                         levels = c(\"Control\", \"Low\", \"Medium\", \"High\"))   # Run two-sided test two_sided_result <- run_threshold_RSCA(sim_data_1, threshold = 2,treatment_col = \"treatment\",replicate_col = \"tank\") print(paste(\"Two-sided p-value:\", round(two_sided_result$p_value, 4))) #> [1] \"Two-sided p-value: 0.0307\"  # Run one-sided test (greater) greater_result <- run_threshold_RSCA(sim_data_1, threshold = 2, alternative = \"greater\",treatment_col = \"treatment\",replicate_col = \"tank\") print(paste(\"One-sided (greater) p-value:\", round(greater_result$p_value, 4))) #> [1] \"One-sided (greater) p-value: 0.0153\"  # Run one-sided test (less) less_result <- run_threshold_RSCA(sim_data_1, threshold = 1, alternative = \"less\",treatment_col = \"treatment\",replicate_col = \"tank\") print(paste(\"One-sided (less) p-value:\", round(less_result$p_value, 4)))  #> [1] \"One-sided (less) p-value: 0.8276\" run_all_threshold_tests(sim_data_1,min_score = 0,max_score = 2,direction=\"less\",alternative =\"less\",treatment_col = \"treatment\",replicate_col = \"tank\") #>  #> result table:  #>  #>   Threshold Z_statistic    P_value Has_zero_counts Alternative      Method #> 1       S≤0  -0.9445781 0.17243715           FALSE        less RSCA (less) #> 2       S≤1  -2.1613671 0.01533349           FALSE        less RSCA (less) #> 3       S≤2          NA         NA           FALSE        less RSCA (less) #>  #>  Summarized Proportions:  #>   Treatment    S≤0    S≤1     S≤2 #> 1   Control 0.6250 0.9375 0.96875 #> 2       Low 0.7500 0.9375 1.00000 #> 3    Medium 0.5625 0.7500 0.93750 #> 4      High 0.5000 0.7500 0.87500 #>  #>  Alternative Hypothesis:  #> [1] \"less\" run_all_threshold_tests(sim_data_1,min_score = 1,max_score = 3,direction=\"greater\",alternative =\"greater\",treatment_col = \"treatment\",replicate_col = \"tank\") #>  #> result table:  #>  #>   Threshold Z_statistic    P_value Has_zero_counts Alternative #> 1       S1+   0.9445781 0.17243715           FALSE     greater #> 2       S2+   2.1613671 0.01533349           FALSE     greater #> 3       S3+          NA 0.52574008            TRUE     greater #>                          Method #> 1                RSCA (greater) #> 2                RSCA (greater) #> 3 Fisher's Exact Test (greater) #>  #>  Summarized Proportions:  #>   Treatment    S1+    S2+     S3+ #> 1   Control 0.3750 0.0625 0.03125 #> 2       Low 0.2500 0.0625 0.00000 #> 3    Medium 0.4375 0.2500 0.06250 #> 4      High 0.5000 0.2500 0.12500 #>  #>  Alternative Hypothesis:  #> [1] \"greater\" run_all_threshold_tests(sim_data_1%>%filter(treatment!=\"High\")%>%droplevels(.),min_score = 1,max_score = 3,direction=\"greater\",alternative =\"greater\",treatment_col = \"treatment\",replicate_col = \"tank\") #>  #> result table:  #>  #>   Threshold Z_statistic   P_value Has_zero_counts Alternative #> 1       S1+   0.2356454 0.4068539           FALSE     greater #> 2       S2+   1.8130002 0.0349159           FALSE     greater #> 3       S3+          NA 1.0000000            TRUE     greater #>                          Method #> 1                RSCA (greater) #> 2                RSCA (greater) #> 3 Fisher's Exact Test (greater) #>  #>  Summarized Proportions:  #>   Treatment    S1+    S2+     S3+ #> 1   Control 0.3750 0.0625 0.03125 #> 2       Low 0.2500 0.0625 0.00000 #> 3    Medium 0.4375 0.2500 0.06250 #>  #>  Alternative Hypothesis:  #> [1] \"greater\" # Run step-down procedure result <- step_down_RSCABS(   sim_data_1,   treatment_col = \"treatment\",replicate_col = \"tank\",   treatment_order = c(\"Control\", \"Low\", \"Medium\", \"High\"),   alternative = \"greater\" ) result #> Step-Down RSCABS Analysis #> ======================== #>  #> Parameters: #>   Direction: greater  #>   Alternative hypothesis: greater  #>   Treatment levels: Control, Low, Medium, High  #>  #> Summary of findings: #> Step 1 : Included treatments: Control, Low, Medium, High  #>   Significant thresholds: S2+  #> Step 2 : Included treatments: Control, Low, Medium  #>   Significant thresholds: S2+  #> Step 3 : Included treatments: Control, Low  #>   No significant findings summary_result <- summary(result) print(summary_result$summary_table) #>   Step        Included_Treatments Highest_Treatment Significant_Thresholds #> 1    1 Control, Low, Medium, High              High                    S2+ #> 2    2       Control, Low, Medium            Medium                    S2+ #> 3    3               Control, Low               Low                   None #>   Min_P_Value #> 1  0.01533349 #> 2  0.03491590 #> 3          NA plot(result) print(result,printLowest = T) #> Step-Down RSCABS Analysis #> ======================== #>  #> Parameters: #>   Direction: greater  #>   Alternative hypothesis: greater  #>   Treatment levels: Control, Low, Medium, High  #>  #> Summary of findings: #> Step 1 : Included treatments: Control, Low, Medium, High  #>   Significant thresholds: S2+  #> Step 2 : Included treatments: Control, Low, Medium  #>   Significant thresholds: S2+  #> Step 3 : Included treatments: Control, Low  #>   No significant findings #>  #> Lowest treatment level with significant findings: #>   Treatment: Medium  #>   Threshold: S2+  #>   P-value: 0.0349"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"comparison-with-joes-implementation","dir":"Articles","previous_headings":"Example Usage of the RSCABS functions in drcHelper","what":"Comparison with Joe’s Implementation","title":"RSCABS","text":"Note p-values critical treatment score combinations. think Joe’s implementation fault terms alternative hypothesis p-value calculation (can return 1-p sometimes, sure ). haven’t tried figured . Note need specify direction alternative according test hypotheses. drcHelper function provides alternative specification Two-sided test (alternative = “two.sided”): -Tests whether trend (increasing decreasing) proportion affected fish across treatment groups - Null hypothesis (H0): trend proportions - Alternative hypothesis (H1): trend (either increasing decreasing) - P-value calculation: 2 * pnorm(-abs(Z)) - Use prior expectation direction effect One-sided test (greater) (alternative = “greater”): - Tests whether proportion affected fish increases treatment level - Null hypothesis (H0): increasing trend - Alternative hypothesis (H1): Proportion increases treatment level - P-value calculation: pnorm(-Z) - Use expect higher treatment levels affected fish One-sided test (less) (alternative = “less”): Tests whether proportion affected fish decreases treatment level Null hypothesis (H0): decreasing trend Alternative hypothesis (H1): Proportion decreases treatment level P-value calculation: pnorm(Z) Use expect higher treatment levels fewer affected fish toxicology studies, alternative = “greater” combination direction = “greater” often appropriate since higher treatment levels typically expected cause adverse effects. comparison conventional RSCABS test runRSCABS, run_all_threshold_tests provides: Flexible threshold direction: Supports “greater equal ” “less equal ” thresholds Automatic score column detection: Identifies score columns based naming pattern Zero count handling: Provides warnings alternative approaches thresholds zero counts Comprehensive results: Returns detailed information including proportions, test statistics, intermediate values Fisher’s exact test fallback: Optionally uses Fisher’s exact test RSCA valid due zero counts","code":"dat1 <- convert_fish_data(sim_data_1,direction=\"to_individual\",treatment_col = \"treatment\",replicate_col = \"tank\" ) dat1 <- (dat1) %>% mutate(score1=as.numeric(factor(score))-1,score2=score1+5) %>% dplyr::select(-c(score)) %>% as.data.frame  ## Note runRSCABS expects more than one endpoints.  res <- runRSCABS(dat1,'treatment','tank',test.type='RS') res[1:5,] %>% mutate(Effect = gsub(\"score1\",\"S\",Effect) ) #>   Effect Treatment R.Score Statistic    P.Value Signif #> 1     S1         4       1 0.9445781 0.17243715      . #> 2     S2         4       2 2.1613671 0.01533349      * #> 3     S2         3       2 1.8130002 0.03491590      * #> 4     S2         2       2 0.0000000 0.50000000      . #> 5     S3         4       3 1.4057798 0.07989476      ."},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"smmary-table-of-the-data","dir":"Articles","previous_headings":"Visulaize the data","what":"Smmary table of the data","title":"RSCABS","text":"","code":"#> # A tibble: 4 × 13 #>   treatment n_tanks total_fish s0_count s0_percent s1_count s1_percent s2_count #>   <fct>       <int>      <dbl>    <dbl>      <dbl>    <dbl>      <dbl>    <dbl> #> 1 Control         8         32       20       62.5       10       31.2        1 #> 2 Low             4         16       12       75          3       18.8        1 #> 3 Medium          4         16        9       56.2        3       18.8        3 #> 4 High            4         16        8       50          4       25          2 #> # ℹ 5 more variables: s2_percent <dbl>, s3_count <dbl>, s3_percent <dbl>, #> #   any_injury <dbl>, any_injury_percent <dbl> #> # A tibble: 4 × 3 #>   treatment mean_severity sd_severity #>   <fct>             <dbl>       <dbl> #> 1 Control           0.469       0.364 #> 2 Low               0.312       0.315 #> 3 Medium            0.75        0.204 #> 4 High              0.875       0.433"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"understanding-rscabs","dir":"Articles","previous_headings":"","what":"Understanding RSCABS","title":"RSCABS","text":"RSCABS (Rao-Scott Cochran-Armitage slice) designed analyze histopathological results standard toxicology experiments, example MEOGRT. Steps testing procedure: 1.Cochran-Armitage (CA) trend test used test set organisms increase presences (score \\(>\\) 0) absence (score = 0) effect increase dose concentration treatments. Rao-Scott (RS) adjustment controls similarity experiment unit / apparatus (e.g., fish tank) calculating adjustment CA test statistic correlation organisms within apparatuses. slices (BS) part allows testing severity score (e.g., 1 5) instead just presences absence. slices works splitting severity scores associated endpoint two groups based severity score tested. RSCA test statistic calculated based two groups. Carry step-procedure excluding highest treatment level analysis recalculate RSCA test statistic test stats significant control group left. Current implementation used Rao-Scott correction always, potential inflating type-error slices low occurences. High resolution scoring system (many categories) less powerful due violation monotonicity. issue zero low counts RSCA test mathematical limitation occurs one treatment group zero affected individuals particular threshold level. leads zero variance estimate group, design effect calculation involves division zero Z-statistic calculation breaks . Possible solutions using alternative tests like Fisher’s exact test applying continuity correction.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"some-backgrounds","dir":"Articles","previous_headings":"Understanding RSCABS","what":"Some Backgrounds","title":"RSCABS","text":"Rao-Scott adjustment method account clustering binary data. Using synthetic fish injury dataset example, fish clustered within tanks (replicates), means observations within tank may correlated. Standard statistical tests assume independent observations, lead incorrect inference clustering ignored. adjustment works : Calculating observed variance within treatment groups, accounting clustering Comparing expected variance simple binomial model Computing design effect (D) ratio variances Adjusting sample sizes counts dividing D Cochran-Armitage Trend Test? Cochran-Armitage trend test examines whether linear trend proportions across ordered categories. context, tests whether proportion injured fish increases (decreases) systematically treatment level. test assigns scores treatment groups (typically 1, 2, 3, …) calculates Z-statistic measures strength linear trend.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"example-1-synthetic-dataset","dir":"Articles","previous_headings":"","what":"Example 1: synthetic dataset","title":"RSCABS","text":"’ll create simulated dataset Control 3 treatment groups (T1, T2, T3), 4 tanks, 6 fish per tank. data show trend higher treatment groups severe injuries (higher scores). Injury scores S0 (injury) S4 (severe injury). Treatment effects: - Control group mostly healthy fish (S0) - treatment level increases, proportion higher injury scores increases - T3 (highest treatment) severe injuries Variability: Small random variations probabilities tank simulates natural tank--tank variability within treatment groups   dataset shows clear trend increasing injury severity across treatment groups. can seen distribution scores average severity score. RSCABS performs Rao-Scott adjusted Cochran-Armitage trend test injury threshold level, help identify severity level treatment effect becomes significant.","code":"[1] TRUE        tmt tank total S0 S1 S2 S3 S4 1  Control   1A     6  3  2  1  0  0 2  Control   2A     6  2  3  0  1  0 3  Control   3A     6  6  0  0  0  0 4  Control   4A     6  6  0  0  0  0 5       T1   1B     6  4  1  1  0  0 6       T1   2B     6  3  3  0  0  0 7       T1   3B     6  5  1  0  0  0 8       T1   4B     6  3  3  0  0  0 9       T2   1C     6  2  1  3  0  0 10      T2   2C     6  2  3  0  1  0 11      T2   3C     6  3  2  1  0  0 12      T2   4C     6  2  1  2  1  0 13      T3   1D     6  1  1  1  2  1 14      T3   2D     6  1  2  2  1  0 15      T3   3D     6  1  1  4  0  0 16      T3   4D     6  1  1  3  1  0 [1] \"Average proportion of each score by treatment:\"       tmt   S0   S1   S2   S3   S4 1 Control 0.71 0.21 0.04 0.04 0.00 2      T1 0.62 0.33 0.04 0.00 0.00 3      T2 0.38 0.29 0.25 0.08 0.00 4      T3 0.17 0.21 0.42 0.17 0.04 [1] \"Average severity score by treatment:\"       tmt severity_score 1 Control      0.4166667 2      T1      0.4166667 3      T2      1.0416667 4      T3      1.7083333 # Plot severity score   ggplot(sim_data, aes(x = tmt, y = severity_score)) +     geom_boxplot() +     geom_jitter(width = 0.2, alpha = 0.5) +     labs(title = \"Average Injury Severity by Treatment\",          x = \"Treatment Group\",          y = \"Severity Score (weighted average)\") +     theme_minimal() #> # A tibble: 4 × 10 #>   grp         x     n     m p_hat       b       v     D n_tilde x_tilde #>   <chr>   <dbl> <dbl> <int> <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl> #> 1 Control     7    24     4 0.292 0.00861 0.0295   3.43       7    2.04 #> 2 T1          9    24     4 0.375 0.00977 0.00637  1         24    9    #> 3 T2         15    24     4 0.625 0.00977 0.00174  1         24   15    #> 4 T3         20    24     4 0.833 0.00579 0        1         24   20 #> [1] \"Z-statistic: 3.566\" #> [1] \"p-value: 4e-04\" #> [1] \"Z-statistic (severe injuries): 4.693\" #> [1] \"p-value (severe injuries): 0\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"rao-scott-adjusted-cochran-armitage-trend-test-results","dir":"Articles","previous_headings":"Example 1: synthetic dataset","what":"Rao-Scott Adjusted Cochran-Armitage Trend Test Results","title":"RSCABS","text":"RSCA Test Results Injury Threshold","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"proportion-of-fish-with-injuries-by-threshold-and-treatment","dir":"Articles","previous_headings":"Example 1: synthetic dataset","what":"Proportion of Fish with Injuries by Threshold and Treatment","title":"RSCABS","text":"Proportion Affected Fish","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"design-effects-and-adjusted-sample-sizes","dir":"Articles","previous_headings":"Example 1: synthetic dataset","what":"Design Effects and Adjusted Sample Sizes","title":"RSCABS","text":"Design Effects Threshold Treatment","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"summary-of-findings","dir":"Articles","previous_headings":"Example 1: synthetic dataset","what":"Summary of Findings","title":"RSCABS","text":"analysis examined trend fish injury rates across treatment groups using Rao-Scott adjusted Cochran-Armitage trend test. test performed multiple injury thresholds identify severity level treatment effect pronounced. strongest trend observed S2+ threshold (p = 0). indicates treatment pronounced effect injuries severity 2 higher. Statistically significant trends observed following thresholds: S1+, S2+. average design effect across analyses 1.26, maximum 3.43. Design effects greater 1 indicate clustering within tanks, Rao-Scott adjustment accounts .","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"RSCABS","text":"analysis provides evidence dose-response relationship treatment level fish injury rates. Rao-Scott adjustment applied account clustering fish within tanks, ensuring valid statistical inference despite clustered data structure. significant findings S1+, S2+ suggest treatment primarily affects specific injury severity levels.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"example-2","dir":"Articles","previous_headings":"","what":"Example 2:","title":"RSCABS","text":"Take subset F2-females 16 weeks age, run RSCABS. Note R.score table shows scores occured respective treatment groups.","code":"data(\"exampleHistData\") exampleHistData <- exampleHistData %>% as_tibble %>% mutate(across(where(is.integer),as.numeric)) %>% as.data.frame(.) #Take the subset corresponding to F0-females of 16 weeks of age  subIndex<-which(exampleHistData$Generation=='F2' &                   exampleHistData$Genotypic_Sex=='Female' &                   exampleHistData$Age=='16_wk' ) exampleHistData.Sub<-exampleHistData[subIndex, ] #Run RSCABS exampleResults<-runRSCABS(exampleHistData.Sub,'Treatment',                           'Replicate',test.type='RS') exampleResults %>% knitr::kable(.,digits=3) ggplot(exampleHistData.Sub,aes(x=Treatment,fill=factor(Gon_Asynch_Dev)))+geom_bar()+scale_fill_viridis_d()+labs(title=\"Example Data: Gon_Asynch_Dev\",subtitle = \"subset: F2 generation, 16 week age and female\") cids <-which(apply(exampleHistData.Sub[,-(1:5)],2,max)>0) responses <- names(cids)    ggplot(exampleHistData.Sub[,c(1:5,5+cids)]%>%tidyr::pivot_longer(-(1:5),values_to = \"Response\",names_to = \"Endpoint\"),aes(x=Treatment,fill=factor(Response)))+geom_bar()+scale_fill_viridis_d()+labs(title=\"Example Histopath Data\",subtitle = \"subset: F2 generation, 15 week age and female\")+facet_wrap(~Endpoint) library(scales) dat1 <- exampleHistData.Sub[,c(1:5,5+cids)]%>%tidyr::pivot_longer(-(1:5),values_to = \"Response\",names_to = \"Endpoint\") %>% group_by(Endpoint,Treatment,Response) %>% summarise(counts=n())%>% group_by(Endpoint,Treatment) %>% mutate(total=sum(counts))  ggplot(dat1,aes(x=Treatment,fill=factor(Response)))+geom_bar(aes(y=counts/total),stat = \"identity\")+scale_fill_viridis_d()+labs(title=\"Example Histopath Data\",subtitle = \"subset: F2 generation, 15 week age and female\")+facet_wrap(~Endpoint,drop = T)+ scale_y_continuous(labels = percent)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"alternative-nonparametric-tests","dir":"Articles","previous_headings":"","what":"Alternative Nonparametric Tests","title":"RSCABS","text":"example taken Hothorn’s paper. independence_test function coin package can used test independence two sets variables measured arbitrary scales. Transformations can done via trafo various test statsitcs can calculated, including Pearson \\(\\chi^2\\) test, generalized Cochran-Mantel-Haenszel test, Spearman correlation test, Fisher-Pitman permutation test, Wilcoxon-Mann-Whitney test, Kruskal-Wallis test family weighted logrank tests censored data. However, Williams’ contrast Williams’ test, just like multcomp package.","code":"ifcoin <- require(coin) data(exampleHistData) subIndex<-which(exampleHistData$Generation==\"F1\" & exampleHistData$Genotypic_Sex==\"Male\" & exampleHistData$Age==\"8_wk\") LH<-exampleHistData[subIndex, ] lh<-LH[, c(2,6)] lh$Gon<-as.numeric(lh$Gon_Phenotype) lh$EP1<-ifelse(lh$Gon >1,1,0) lh$EP2<-ifelse(lh$Gon >2,1,0) lh$EP3<-ifelse(lh$Gon >3,1,0) lh$treat<-as.factor(lh$Treatment) lhh<-droplevels(lh[lh$treat!=6, ]) Lhh<-droplevels(lhh[lhh$treat!=3, ]) library(\"coin\") library(\"multcomp\") Co1 <- function(data) trafo(data, factor_trafo = function(x) model.matrix(~x - 1) %*% t(contrMat(table(x), \"Dunnett\"))) Codu <-independence_test(EP1 +EP2+EP3~ treat, data = Lhh, teststat = \"maximum\", distribution = \"approximate\", xtrafo=Co1, alternative=\"greater\") pvalCODU <-pvalue(Codu, method=\"single-step\") pvalCODU CoW <- function(data) trafo(data, factor_trafo = function(x) model.matrix(~x - 1) %*% t(contrMat(table(x), \"Williams\"))) Cowi <-independence_test(EP1 +EP2+EP3~ treat, data = Lhh, teststat = \"maximum\", distribution = \"approximate\", xtrafo=CoW, alternative=\"greater\") pvalCOWI <-pvalue(Cowi, method=\"single-step\") pvalCOWI"},{"path":[]},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"notes-on-rscabs-functions","dir":"Articles","previous_headings":"Function Notes","what":"Notes on RSCABS functions","title":"RSCABS","text":"Select responses maximum value > 0 smaller 20 (limited ranks response). tested response/endpoints, convert2score tested response/endpoints, prepDataRSCABS, prepare data matrix/table format, treatment column, replicate row tested response/endpoints, stepKRSCABS. results look like : combine results big matrix.","code":"$Gon_Asynch_Dev            Effect Treatment R.Score Statistic     P.Value Signif 1 Gon_Asynch_Dev1         5       1  2.622022 0.004370488     ** 2 Gon_Asynch_Dev1         4       1       NaN 1.000000000      . 3 Gon_Asynch_Dev1         4       1       NaN 1.000000000      . 4 Gon_Asynch_Dev2         5       2  2.622022 0.004370488     ** 5 Gon_Asynch_Dev2         4       2       NaN 1.000000000      . 6 Gon_Asynch_Dev2         4       2       NaN 1.000000000      ."},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"validation-by-sas","dir":"Articles","previous_headings":"","what":"Validation by SAS","title":"RSCABS","text":"RSCABS code R written validated SAS Chen Meng also RSCABS procedure archived statCharrms package.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Example_RSCABS.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"RSCABS","text":"Green, John W. Springer, Timothy . Saulnier, Amy N. Swintek, Joe, (2014) Statistical analysis histopathological endpoints. Environmental Toxicology Chemistry, 33(5), 1108-1116 Hothorn, T., Hornik, K., van de Wiel, M. . Zeileis, . (2008). Implementing class permutation tests: coin package. Journal Statistical Software 28(8), 1–23. doi: 10.18637/jss.v028.i08","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples using NLS.html","id":"using-ggprism","dir":"Articles","previous_headings":"","what":"using ggprism","title":"Using nls to fit arbitrary dose-response models","text":"","code":"library(ggprism)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples using NLS.html","id":"example-dataset","dir":"Articles","previous_headings":"","what":"Example Dataset","title":"Using nls to fit arbitrary dose-response models","text":"","code":"# construct the data.frame, log10 transform the agonist concentration # convert the data.frame to long format, then remove any rows with NA df <- data.frame(   agonist = c(1e-10, 1e-8, 3e-8, 1e-7, 3e-7, 1e-6, 3e-6, 1e-5, 3e-5, 1e-4, 3e-4),   ctr1 = c(0, 11, 125, 190, 258, 322, 354, 348, NA, 412, NA),   ctr2 = c(3, 33, 141, 218, 289, 353, 359, 298, NA, 378, NA),   ctr3 = c(2, 25, 160, 196, 345, 328, 369, 372, NA, 399, NA),   trt1 = c(3, NA, 11, 52, 80, 171, 289, 272, 359, 352, 389),   trt2 = c(5, NA, 25, 55, 77, 195, 230, 333, 306, 320, 338),    trt3 = c(4, NA, 28, 61, 44, 246, 243, 310, 297, 365, NA) ) %>%    mutate(log.agonist = log10(agonist)) %>%    pivot_longer(     c(-agonist, -log.agonist),      names_pattern = \"(.{3})([0-9])\",      names_to = c(\"treatment\", \"rep\"),     values_to = \"response\"   ) %>%    filter(!is.na(response))  head(df) #> # A tibble: 6 × 5 #>        agonist log.agonist treatment rep   response #>          <dbl>       <dbl> <chr>     <chr>    <dbl> #> 1 0.0000000001         -10 ctr       1            0 #> 2 0.0000000001         -10 ctr       2            3 #> 3 0.0000000001         -10 ctr       3            2 #> 4 0.0000000001         -10 trt       1            3 #> 5 0.0000000001         -10 trt       2            5 #> 6 0.0000000001         -10 trt       3            4 dose_resp <- y ~ min + ((max - min) / (1 + exp(hill_coefficient * (ec50 - x))))  ggplot(df, aes(x = log.agonist, y = response)) +    geom_smooth(     aes(colour = treatment),     method = \"nls\", formula = dose_resp, se = FALSE,     method.args = list(start = list(min = 1.67, max = 397, ec50 = -7, hill_coefficient = 1))   ) +    scale_colour_manual(labels = c(\"No inhibitor\", \"Inhibitor\"),                       values = c(\"#00167B\", \"#9FA3FE\")) +    ggnewscale::new_scale_colour() +   geom_point(aes(colour = treatment, shape = treatment), size = 3) +    scale_colour_prism(palette = \"winter_bright\",                       labels = c(\"No inhibitor\", \"Inhibitor\")) +    scale_shape_prism(labels = c(\"No inhibitor\", \"Inhibitor\")) +    theme_prism(palette = \"winter_bright\", base_size = 16) +    scale_y_continuous(limits = c(-100, 500),                       breaks = seq(-100, 500, 100),                      guide = \"prism_offset\") +    scale_x_continuous(     limits = c(-10, -3),      breaks = -10:-3,     guide = \"prism_offset_minor\",     minor_breaks = log10(rep(1:9, 7)*(10^rep(-10:-4, each = 9))),     labels = function(lab) {       do.call(         expression,         lapply(paste(lab), function(x) bquote(bold(\"10\"^.(x))))       )     }   ) +    theme(axis.title.y = element_blank(),         legend.title = element_blank(),         legend.position.inside = c(0.05, 0.95),         legend.justification = c(0.05, 0.95)) +    labs(x = \"[Agonist], M\") #> Warning: The S3 guide system was deprecated in ggplot2 3.5.0. #> ℹ It has been replaced by a ggproto system that can be extended. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated."},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples using NLS.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Using nls to fit arbitrary dose-response models","text":"https://csdaw.github.io/ggprism/articles/web-/ex1-dose.html","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_drc.html","id":"is-there-a-difference-between-ecx-and-bmd","dir":"Articles","previous_headings":"","what":"Is there a difference between ECx and BMD?","title":"Examples of using drc and bmd","text":"BMD (Benchmark Dose) ECx (Effect Concentration x) important concepts fields toxicology ecotoxicology, respectively. originate different domains distinct definitions applications, share similarities purpose—specifying dose concentration elicits specific effect relative control background level. ECx (Effect Concentration x) commonly used ecotoxicology. ECx represents concentration substance causes specified effect certain percentage test population (e.g., 10%, 50%, 90%) causes x% reduction / inhibition / stimulation average compared control. BMD (Benchmark Dose) primarily used toxicology. refers dose substance produces predefined change response compared control group. flexibility defining BMD allows tailored assessments based specific toxicological thresholds regulatory requirements. example, bmd package, “excess”, “additional” “point” provide binomial response. “relative”, “extra”, “added”, “excess hybrid”, “additional hybrid”, “point” continuous response. “relative”, “extra”, “point” count response data. ecotoxicology area, two concepts essentially , however, terms tools, calculations use different default model suites, parameterizations, evaluation criteria, even methodology framework. Crump, K. (2002) Critical Issues Benchmark Calculations Continuous Data, Critical Reviews Toxicology 32, 133–153.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_drc.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Examples of using drc and bmd","text":"help page drc::ED several options calculating confidence intervals argument interval. option “delta” results asymptotical Wald-type confidence intervals (using delta method normal t-distribution depending type response). option “fls” produces (possibly skewed) confidence intervals back-transformation logarithm scale (meaningful case parameter model log(ED50) llogistic2) models. option “tfls” transforming back forth log scale (experimental). option “inv” results confidence intervals obtained inverse regression.","code":"## Model with ED50 as a parameter finney71.m1 <- drm(affected / total ~ dose, weights = total, data = finney71, fct = LL.2(), type = \"binomial\")  summary(finney71.m1) #>  #> Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1 (2 parms) #>  #> Parameter estimates: #>  #>               Estimate Std. Error t-value   p-value     #> b:(Intercept) -3.10363    0.38773 -8.0047 1.154e-15 *** #> e:(Intercept)  4.82890    0.24958 19.3485 < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 plot(finney71.m1, broken = TRUE, bp = 0.1, lwd = 2) ED(finney71.m1, c(10, 20, 50), interval = \"delta\", reference = \"control\",type=\"relative\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:10  2.37896    0.25164 1.88576 2.87217 #> e:1:20  3.08932    0.24372 2.61163 3.56700 #> e:1:50  4.82890    0.24958 4.33974 5.31806 ED(finney71.m1, c(0.10, 0.20, 0.50), interval = \"delta\", reference = \"control\",type=\"absolute\") #>  #> Estimated effective doses #>  #>         Estimate Std. Error   Lower   Upper #> e:1:0.1  2.37896    0.25164 1.88576 2.87217 #> e:1:0.2  3.08932    0.24372 2.61163 3.56700 #> e:1:0.5  4.82890    0.24958 4.33974 5.31806 ##  Referecen could be the upper limit or the control. In this case I am not sure what has been calcuated. ED(finney71.m1, c(10, 20, 50), interval = \"delta\", reference = \"upper\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:10  9.80184    0.97020  7.90028 11.70341 #> e:1:20  7.54803    0.55188  6.46636  8.62969 #> e:1:50  4.82890    0.24958  4.33974  5.31806  ED(finney71.m1, c(10, 20, 50), interval = \"delta\", reference = \"control\",type=\"relative\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:10  2.37896    0.25164 1.88576 2.87217 #> e:1:20  3.08932    0.24372 2.61163 3.56700 #> e:1:50  4.82890    0.24958 4.33974 5.31806  bmd::bmd(finney71.m1, c(0.1),backgType=\"modelBased\",def=\"excess\",interval=\"inv\") #>       BMD     BMDL #>  2.378965 2.020913  ## Note that in ED.plus, instead of using interval = \"delta\", we specifify CI = \"delta\", to distinguish the option to calculate CI drcHelper::ED.plus(finney71.m1, c(10, 20, 50), CI = \"inv\") #>       Estimate Std. Error    Lower    Upper #> EC 10 2.378965  0.2516419 1.965051 2.792879 #> EC 20 3.089316  0.2437215 2.688430 3.490202 #> EC 50 4.828897  0.2495753 4.418382 5.239411 ## Fitting 4-parameter log-logistic model ryegrass.m1 <- drm(ryegrass, fct = LL.4())  ## Calculating EC/ED values ## Also displaying 95% confidence intervals ED(ryegrass.m1, c(10, 50, 90), interval = \"delta\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:10  1.46371    0.18677 1.07411 1.85330 #> e:1:50  3.05795    0.18573 2.67053 3.44538 #> e:1:90  6.38864    0.84510 4.62580 8.15148 plot(ryegrass.m1,broken = TRUE) plot(ryegrass.m1, broken = TRUE, type=\"confidence\", add=TRUE) ## Fitting the Brain-Cousens model lettuce.m1 <- drm(weight ~ conc, data = lettuce, fct = BC.4()) plot(lettuce.m1,confidence.level = 0.95) ### Calculating ED[-10]  # This does not work #ED(lettuce.m1, -10)  ## Now it does work ED(lettuce.m1, c(-10,-20), bound = FALSE)  # works #>  #> Estimated effective doses #>  #>         Estimate Std. Error #> e:1:-10  1.86458    1.01634 #> e:1:-20  0.96333    1.23014  ### Using a different break point. par(mfrow = c(2, 2)) plot(lettuce.m1, main = \"bp = default\")  # using the default plot(lettuce.m1, bp = 1e-4, main = \"bp = 1e-4\") plot(lettuce.m1, bp = 1e-6, main = \"bp = 1e-6\") plot(lettuce.m1, bp = 1e-8, main = \"bp = 1e-8\") par(mfrow = c(1,1)) ## Fitting model to be plotted below spinach.m1 <- drm(SLOPE ~ DOSE, CURVE, data = spinach, fct = LL.4())  ## Plot with no colours plot(spinach.m1, main = \"Different line types (default)\") ## Plot with default colours plot(spinach.m1, col = TRUE, main = \"Default colours\") ## Plot with specified colours plot(spinach.m1, col = c(2,6,3,23,56), main = \"User-specified colours\") ## Plot of curves 1 and 2 only plot(spinach.m1, level = c(1,2), main = \"User-specified curves\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_oecd201.html","id":"evaluation-of-dataset-oecd201","dir":"Articles","previous_headings":"","what":"Evaluation of Dataset oecd201","title":"Examples_oecd201","text":"","code":"data(\"oecd201\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_oecd201.html","id":"data-overview","dir":"Articles","previous_headings":"Evaluation of Dataset oecd201","what":"Data Overview","title":"Examples_oecd201","text":"Yield Summary Time 72h","code":"sum1 <- oecd201 %>% group_by(Time,Treatment) %>% summarise(Yield_mean=mean(Yield),Yield_sd=sd(Yield),GrowthRate_mean=mean(GrowthRate),GrowthRate_sd=sd(GrowthRate)) sum0 <- sum1%>%filter(Treatment==\"Control\")%>%rename(Yield0=Yield_mean,GrowthRate0=GrowthRate_mean)%>%dplyr::select(c(Time,Yield0,GrowthRate0)) # sum0 sumtab <- left_join(sum1%>%filter(Time>0),sum0) %>% mutate(Yield_Inhibition=(Yield0-Yield_mean)/Yield0*100,GrowthRate_Inhibition=(GrowthRate0-GrowthRate_mean)/GrowthRate0*100) %>% dplyr::select(c(Time,Treatment,Yield_mean,Yield_sd,Yield_Inhibition,GrowthRate_mean,GrowthRate_sd,GrowthRate_Inhibition)) sumtab%>%dplyr::select(c(Yield_mean,Yield_sd,Yield_Inhibition))%>%filter(Time==72)%>%knitr::kable(.,digits = 2,caption=\"<center><strong>Yield Summary at Time 72h<strong><center>\",escape = FALSE)%>% kableExtra::kable_styling(bootstrap_options = \"striped\")##%>%kableExtra::kable_classic_2() sumtab%>%dplyr::select(c(GrowthRate_mean,GrowthRate_sd,GrowthRate_Inhibition))%>%filter(Time==72)%>%knitr::kable(.,digits = 2,caption=\"<center><strong>Growth Rate Summary at Time 72h<strong><center>\",escape = FALSE)##%>%kableExtra::kable_classic()"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_oecd201.html","id":"model-fitting-and-comparison-for-yield","dir":"Articles","previous_headings":"Evaluation of Dataset oecd201","what":"Model Fitting and Comparison For Yield","title":"Examples_oecd201","text":"14 day TSL Yield 14 day TSL Yield, Model Comparison Yield Model Fits   Total Shoot Length Growth Yield 14 day","code":"datTn<- subset(oecd201,Time==72)  mod <- drm(Yield~Concentration,data=datTn,fct=LL.3()) fctList <- list(LL2.3(),W2.3(),W1.3(),EXD.3(),EXD.2(),LN.3(),W2.4(),LL.4(),LL2.4()) plot(mod,type=\"all\") res <- mselect.plus(mod,fctList = fctList ) modList <- res$modList edResTab <- mselect.ED(modList = modList,respLev = c(10,20,50),trend=datTn$Trend_Yield[1]) plot_edList(edResTab) resComp <- drcCompare(modRes = res,trend=\"Decrease\") knitr::kable(edResTab,caption = \"14 day TSL Yield\",digits = 3) knitr::kable(resComp,caption = \"14 day TSL Yield, Model Comparison\",digits = 3) plot.modList(modList,scale=\"logx\") plot.modList(modList[c(1,2,3,4)],scale=\"logx\",npts=40) p <-plot.modList(modList[c(1)],scale=\"logx\",npts=80)+theme(legend.position = \"none\")+ggtitle(\"14 day Total Shoot Length, \\n3-parameter type II Weibull Model Fit\") addECxCI(p=p,object=modList[[1]],EDres=NULL,trend=\"Decrease\",endpoint=\"EC\", respLev=c(10,20,50),                      textAjust.x=0.01,textAjust.y=1,useObsCtr=FALSE,d0=NULL,textsize = 4,lineheight = 1,xmin=0.012)+ylab(\"Total Shoot Length [cm]\") + xlab(\"Concentration [µg a.s./L]\") ggsave(\"TSL_14d_Yield.png\") resED <- t(edResTab[1:3, c(2,4,5,6)]) colnames(resED) <- paste(\"EC\", c(10,20,50)) knitr::kable(resED,caption = \"Total Shoot Length Growth Yield at 14 day\",digits = 3) mod <-modList[[1]] edres <- ED.plus(mod,c(5,10,20,50),trend=\"Decrease\") pander::pander(as.data.frame(edres)) modsum <- summary(mod) pander::pander(coef(modsum))"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_using_drda.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Examples using drda","text":"","code":"?voropm2  head(voropm2) #>   response dose log_dose weight #> 1   1.1263 1.00     0.00   0.87 #> 2   1.0329 1.00     0.00   1.04 #> 3   1.1139 1.00     0.00   0.94 #> 4   1.1146 1.93     0.66   0.96 #> 5   1.0664 1.93     0.66   0.91 #> 6   1.0163 1.93     0.66   0.93"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_using_drda.html","id":"default-fitting","dir":"Articles","previous_headings":"","what":"Default Fitting","title":"Examples using drda","text":"","code":"# by default `drda` uses a 4-parameter logistic function for model fitting  # common R API for fitting models fit <- drda(response ~ log_dose, data = voropm2)  # get a general overview of the results summary(fit) #>  #> Call: drda(formula = response ~ log_dose, data = voropm2) #>  #> Pearson Residuals: #>      Min        1Q    Median        3Q       Max   #> -1.88121  -0.72514   0.06395   0.47905   2.17210   #>  #> Parameters: #>                   Estimate Std. Error Lower .95 Upper .95 #> Maximum            1.04147    0.01022   1.02144     1.061 #> Height            -1.05659    0.02059  -1.09694    -1.016 #> Growth rate        3.07405    0.31744   2.45187     3.696 #> Midpoint at        6.53555    0.03593   6.46512     6.606 #> Residual std err.  0.05069    0.00574   0.03944     0.062 #>  #> Residual standard error on 41 degrees of freedom #>  #> Log-likelihood: 72.432 #> AIC: -134.86 #> BIC: -125.83 #>  #> Optimization algorithm converged in 285 iterations  # get parameter estimates by using generic functions... coef(fit) #>     alpha     delta       eta       phi  #>  1.041465 -1.056586  3.074053  6.535548 sigma(fit) #> [1] 0.05069196  # ... or accessing the variables directly fit$coefficients #>     alpha     delta       eta       phi  #>  1.041465 -1.056586  3.074053  6.535548 fit$sigma #> [1] 0.05069196  # compare the estimated model against a flat horizontal line, or the full # 5-parameter logistic model, using AIC, BIC, and the Likelihood Ratio Test # (LRT) # # note that the LRT is testing the null hypothesis of a flat horizontal line # being as a good fit as the chosen model, therefore we expect the test to be # significant # # if the test is not significant, a horizontal line is probably a better model anova(fit) #> Analysis of Deviance Table #>  #> Model 1: a #> Model 2: a + d / (1 + exp(-e * (x - p))) (Fit) #> Model 3: a + d / (1 + n * exp(-e * (x - p)))^(1 / n) (Full) #>  #> Model 3 is the best model according to the Akaike Information Criterion. #>  #>         Resid. Df Resid. Dev Df      AIC     BIC Deviance    LRT  Pr(>Chi)     #> Model 1        44     9.0879  1   59.717   63.33                               #> Model 2        41     0.1054  4 -134.864 -125.83  -8.9825 200.58 < 2.2e-16 *** #> Model 3        40     0.0773  5 -146.774 -135.93  -0.0280  13.91 0.0001917 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_using_drda.html","id":"other-models","dir":"Articles","previous_headings":"","what":"Other models","title":"Examples using drda","text":"","code":"# use the `mean_function` argument to select a different model fit_l2 <- drda(response ~ log_dose, data = voropm2, mean_function = \"logistic2\") fit_l4 <- drda(response ~ log_dose, data = voropm2, mean_function = \"logistic4\") fit_l5 <- drda(response ~ log_dose, data = voropm2, mean_function = \"logistic5\") fit_gz <- drda(response ~ log_dose, data = voropm2, mean_function = \"gompertz\")  # which model should be chosen? anova(fit_l2, fit_l4, fit_l5, fit_gz) #> Analysis of Deviance Table #>  #> Model 1: a #> Model 2: 1 - 1 / (1 + exp(-e * (x - p))) #> Model 3: a + d * exp(-exp(-e * (x - p))) #> Model 4: a + d / (1 + exp(-e * (x - p))) #> Model 5: a + d / (1 + n * exp(-e * (x - p)))^(1 / n) (Full) #>  #> Model 5 is the best model according to the Akaike Information Criterion. #>  #>         Resid. Df Resid. Dev Df      AIC     BIC Deviance     LRT  Pr(>Chi)     #> Model 1        44     9.0879      59.717   63.33                                #> Model 2        43     0.1493  1 -123.180 -117.76  -8.9386 184.897 < 2.2e-16 *** #> Model 3        41     0.1438  2 -120.873 -111.84  -0.0055   1.692 0.4291117     #> Model 4        41     0.1054  0 -134.864 -125.83  -0.0384  13.991               #> Model 5        40     0.0773  1 -146.774 -135.93  -0.0280  13.910 0.0001917 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  # 5-parameter logistic function provides the best fit (AIC and BIC are minimum)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_using_drda.html","id":"weighted-fit","dir":"Articles","previous_headings":"","what":"Weighted fit","title":"Examples using drda","text":"","code":"# it is possible to give each observation its own weight fit_weighted <- drda(response ~ log_dose, data = voropm2, weights = weight)  # all the commands shown so far are available for a weighted fit as well"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_using_drda.html","id":"constrained-optimization","dir":"Articles","previous_headings":"","what":"Constrained optimization","title":"Examples using drda","text":"","code":"# it is possible to fix parameter values by setting the `lower_bound` and # `upper_bound` appropriately # # unconstrained parameters have a lower bound of `-Inf` and an upper bound of # `Inf` # # Important: be careful when deciding the constraints, because the optimization #            problem might become very difficult to solve within a reasonable #            number of iterations. # # In this particular example we are: #   - fixing the alpha parameter to 1 #   - fixing the delta parameter to -1 #   - constraining the growth rate to be between 1 and 5 #   - not constraining the `phi` parameter, i.e. the `log(EC50)` lb <- c(1, -1, 1, -Inf) ub <- c(1, -1, 5,  Inf)  fit <- drda(   response ~ log_dose, data = voropm2, lower_bound = lb, upper_bound = ub,   max_iter = 260 )  summary(fit) #>  #> Call: drda(formula = response ~ log_dose, data = voropm2, lower_bound = lb,  #>     upper_bound = ub, max_iter = 260) #>  #> Pearson Residuals: #>      Min        1Q    Median        3Q       Max   #> -1.76281  -0.14933   0.08862   0.81283   2.56716   #>  #> Parameters: #>                   Estimate Std. Error Lower .95 Upper .95 #> Maximum            1.00000         NA        NA        NA #> Height            -1.00000         NA        NA        NA #> Growth rate        3.58631   0.448736   2.70680     4.466 #> Midpoint at        6.57056   0.035336   6.50130     6.640 #> Residual std err.  0.05893   0.006432   0.04632     0.072 #>  #> Residual standard error on 43 degrees of freedom #>  #> Log-likelihood: 64.584 #> AIC: -123.17 #> BIC: -117.75 #>  #> Optimization algorithm DID NOT converge in 260 iterations  # if the algorithm does not converge, we can try to increase the maximum number # of iterations or provide our own starting point fit <- drda(   response ~ log_dose, data = voropm2, lower_bound = lb, upper_bound = ub,   start = c(1, -1, 2.6, 5), max_iter = 10000 )  summary(fit) #>  #> Call: drda(formula = response ~ log_dose, data = voropm2, lower_bound = lb,  #>     upper_bound = ub, start = c(1, -1, 2.6, 5), max_iter = 10000) #>  #> Pearson Residuals: #>      Min        1Q    Median        3Q       Max   #> -1.78762  -0.14935   0.08877   0.81294   2.56740   #>  #> Parameters: #>                   Estimate Std. Error Lower .95 Upper .95 #> Maximum            1.00000         NA        NA        NA #> Height            -1.00000         NA        NA        NA #> Growth rate        3.62475   0.464908   2.71355     4.536 #> Midpoint at        6.56865   0.035267   6.49953     6.638 #> Residual std err.  0.05892   0.006429   0.04632     0.072 #>  #> Residual standard error on 43 degrees of freedom #>  #> Log-likelihood: 64.59 #> AIC: -123.18 #> BIC: -117.76 #>  #> Optimization algorithm converged in 284 iterations"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_using_drda.html","id":"plotting","dir":"Articles","previous_headings":"","what":"Plotting","title":"Examples using drda","text":"","code":"fit_l5 <- drda(response ~ log_dose, data = voropm2, mean_function = \"logistic5\")  # plot the data used for fitting, the maximum likelihood curve, and # *approximate* confidence intervals for the curve plot(fit_l5) # combine all curves in the same plot fit_l2 <- drda(response ~ log_dose, data = voropm2, mean_function = \"logistic2\") fit_l4 <- drda(response ~ log_dose, data = voropm2, mean_function = \"logistic4\") plot(fit_l2, fit_l4, fit_l5) # modify default plotting options # use `legend_show = FALSE` to remove the legend altogether plot(   fit_l5, base = \"10\", col = \"magenta\", xlab = \"x\", ylab = \"y\", level = 0.9,   midpoint = FALSE, main = \"Example plot\", legend_location = \"topright\",   legend = \"5-parameter logistic function\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Examples_using_drda.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Examples using drda","text":"Malyutina , Tang J, Pessia (2023). drda: R package dose-response data analysis using logistic functions. Journal Statistical Software, 106(4), 1-26. doi:10.18637/jss.v106.i04","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Introduction.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"Introduction","text":"Getting Started section, introduce main helper functions serve foundation analyses. , ’ll find typical workflows illustrate navigate functionalities package. ’s important note multiple approaches analyzing dataset, choice method can significantly influence results. dataset contains information degree certainty, different analytical methods converge similar conclusions. Conversely, data lacks sufficient information address specific question, disparate methods may yield distinct potentially conflicting results. Thus, characterizing uncertainty crucial component statistical analysis, package emphasizes aspect throughout functionalities. routine analyses, adopt drc package core analysis tool, given robust capabilities dose-response modeling. However, recognize numerous packages designed similar analyses, drda, DoseFinding, others. Articles section, provide examples reproduce analyses using alternative packages, allowing users explore different methodologies gain insights similar analyses can conducted across various frameworks. Additionally, specific types data, offer supplementary analyses utilizing testing modeling approaches, ensuring well-rounded perspective statistical evaluation.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Introduction.html","id":"regulatory-stats","dir":"Articles","previous_headings":"","what":"Regulatory Stats","title":"Introduction","text":"Regulatory Stats section explains regulatory concepts showcases practical applications package’s functionalities, demonstrating implement analyses real-world scenarios. examples serve guide users replicate analyses adapt datasets.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Introduction.html","id":"articles","dir":"Articles","previous_headings":"","what":"Articles","title":"Introduction","text":"Articles section, delve deeper various topics related dose-response analysis, providing insights, comparisons, discussions methodologies. section aims broaden understanding statistical approaches implications research.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Introduction.html","id":"validation","dir":"Articles","previous_headings":"","what":"Validation","title":"Introduction","text":"Lastly, Validation section outlines validation processes employed within package. , discuss ensure reliability accuracy methods implemented, providing users confidence results generated analyses.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Introduction.html","id":"other-useful-packages","dir":"Articles","previous_headings":"","what":"Other useful packages","title":"Introduction","text":"several packages find useful statistical analysis (eco)toxicological data. ecotoxicology package Implementation EPA’s Ecological Exposure Research Division (EERD) tools (discontinued 1999) Probit Trimmed Spearman-Karber Analysis. Probit tables Finney’s book (code-generated, copied) generating functions included. Control correction: Abbott, Schneider-Orelli, Henderson-Tilton, Sun-Shepard. Toxicity scales: Horsfall-Barratt, Archer, Gauhl-Stover, Fullerton-Olsen, etc. drda - Gompertz log-gompertz function - growth curves dose-response analysis - Probably better optimiation algorithms compared drc. bayesnec -Effect-Concentration estimation NSEC: Introducing -Significant-Effect Concentration","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"variance-components","dir":"Articles","previous_headings":"","what":"Variance Components","title":"Mixed Models","text":"first explore variance components structure affect dose-response analysis using Intraclass Correlation Coefficient (ICC) patterns. ICC represents proportion total variance attributable -tank differences: \\[ \\mbox{ICC} = \\sigma^2_{}/(\\sigma^2_{} + \\sigma^2_{within}) \\]","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"example-1","dir":"Articles","previous_headings":"","what":"Example 1","title":"Mixed Models","text":"","code":"# Let's simulate a single dataset with your existing function and examine its properties set.seed(123)  # Simulate dose-response data with specific variance components sim_data <- simulate_dose_response(   n_doses = 5,   dose_range = c(0, 20),   m_tanks = 4,   k_individuals = 10,   var_tank = 6,     # Between-tank variance   var_individual = 2,  # Within-tank (individual) variance   include_individuals = TRUE,   response_function = function(dose) {     # Simple linear dose-response with threshold at dose 10     ifelse(dose > 10, 5 + 2 * (dose - 10), 5)   } )  # Calculate theoretical ICC theoretical_icc <- 6 / (6 + 2)  # var_tank / (var_tank + var_individual) cat(\"Theoretical ICC:\", theoretical_icc, \"\\n\") #> Theoretical ICC: 0.75  # Examine the data structure head(sim_data) #>   Dose Tank Individual Response #> 1    0    1          1 2.116990 #> 2    0    1          3 3.318858 #> 3    0    4          1 2.985193 #> 4    0    4          3 3.405375 #> 5    0    3          2 7.934101 #> 6    0    2          1 2.787365 str(sim_data) #> 'data.frame':    200 obs. of  4 variables: #>  $ Dose      : num  0 0 0 0 0 0 0 0 0 0 ... #>  $ Tank      : int  1 1 4 4 3 2 2 1 1 4 ... #>  $ Individual: int  1 3 1 3 2 1 3 2 4 2 ... #>  $ Response  : num  2.12 3.32 2.99 3.41 7.93 ...  # Visualize the data to see the hierarchical structure library(ggplot2)  # Plot individual data points with tank means ggplot(sim_data, aes(x = factor(Dose), y = Response, color = factor(Tank))) +   geom_jitter(width = 0.2, alpha = 0.5) +   stat_summary(fun = mean, geom = \"point\", size = 3) +   stat_summary(fun = mean, geom = \"line\", aes(group = factor(Tank))) +   labs(title = \"Dose-Response Data with Hierarchical Structure\",        x = \"Dose\", y = \"Response\",        color = \"Tank\") +   theme_minimal() # Calculate observed ICC using a mixed model library(lme4) mixed_model <- lmer(Response ~ factor(Dose) + (1|Tank), data = sim_data) summary(mixed_model) #> Linear mixed model fit by REML ['lmerMod'] #> Formula: Response ~ factor(Dose) + (1 | Tank) #>    Data: sim_data #>  #> REML criterion at convergence: 927.7 #>  #> Scaled residuals:  #>      Min       1Q   Median       3Q      Max  #> -2.22011 -0.64124  0.04355  0.67388  2.79017  #>  #> Random effects: #>  Groups   Name        Variance Std.Dev. #>  Tank     (Intercept) 0.424    0.6511   #>  Residual             6.060    2.4617   #> Number of obs: 200, groups:  Tank, 4 #>  #> Fixed effects: #>                Estimate Std. Error t value #> (Intercept)      5.5526     0.5074  10.942 #> factor(Dose)5    0.2649     0.5505   0.481 #> factor(Dose)10  -0.5574     0.5505  -1.013 #> factor(Dose)15  10.5100     0.5505  19.093 #> factor(Dose)20  18.6356     0.5505  33.855 #>  #> Correlation of Fixed Effects: #>             (Intr) fc(D)5 f(D)10 f(D)15 #> factor(Ds)5 -0.542                      #> factr(Ds)10 -0.542  0.500               #> factr(Ds)15 -0.542  0.500  0.500        #> factr(Ds)20 -0.542  0.500  0.500  0.500  # Extract variance components vc <- VarCorr(mixed_model) tank_var <- as.numeric(vc$Tank) residual_var <- attr(vc, \"sc\")^2 observed_icc <- tank_var / (tank_var + residual_var) cat(\"Observed ICC:\", observed_icc, \"\\n\") #> Observed ICC: 0.06538746  # Aggregate data to tank level tank_data <- aggregate(Response ~ Dose + Tank, data = sim_data, FUN = mean) head(tank_data) #>   Dose Tank  Response #> 1    0    1  3.202260 #> 2    5    1  6.156191 #> 3   10    1  3.054297 #> 4   15    1 16.318684 #> 5   20    1 26.548488 #> 6    0    2  5.604946  # Compare individual-level model with tank-level model # Individual level (mixed model) ind_model <- lmer(Response ~ factor(Dose) + (1|Tank), data = sim_data)  # Tank level (regular linear model) tank_model <- lm(Response ~ factor(Dose), data = tank_data)  # Compare model summaries summary(ind_model) #> Linear mixed model fit by REML ['lmerMod'] #> Formula: Response ~ factor(Dose) + (1 | Tank) #>    Data: sim_data #>  #> REML criterion at convergence: 927.7 #>  #> Scaled residuals:  #>      Min       1Q   Median       3Q      Max  #> -2.22011 -0.64124  0.04355  0.67388  2.79017  #>  #> Random effects: #>  Groups   Name        Variance Std.Dev. #>  Tank     (Intercept) 0.424    0.6511   #>  Residual             6.060    2.4617   #> Number of obs: 200, groups:  Tank, 4 #>  #> Fixed effects: #>                Estimate Std. Error t value #> (Intercept)      5.5526     0.5074  10.942 #> factor(Dose)5    0.2649     0.5505   0.481 #> factor(Dose)10  -0.5574     0.5505  -1.013 #> factor(Dose)15  10.5100     0.5505  19.093 #> factor(Dose)20  18.6356     0.5505  33.855 #>  #> Correlation of Fixed Effects: #>             (Intr) fc(D)5 f(D)10 f(D)15 #> factor(Ds)5 -0.542                      #> factr(Ds)10 -0.542  0.500               #> factr(Ds)15 -0.542  0.500  0.500        #> factr(Ds)20 -0.542  0.500  0.500  0.500 summary(tank_model) #>  #> Call: #> lm(formula = Response ~ factor(Dose), data = tank_data) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -4.5543 -1.2816  0.1967  1.8654  3.3025  #>  #> Coefficients: #>                Estimate Std. Error t value Pr(>|t|)     #> (Intercept)      5.5526     1.2460   4.456 0.000462 *** #> factor(Dose)5    0.2649     1.7621   0.150 0.882520     #> factor(Dose)10  -0.5574     1.7621  -0.316 0.756118     #> factor(Dose)15  10.5100     1.7621   5.964 2.59e-05 *** #> factor(Dose)20  18.6356     1.7621  10.576 2.38e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 2.492 on 15 degrees of freedom #> Multiple R-squared:  0.9261, Adjusted R-squared:  0.9063  #> F-statistic: 46.96 on 4 and 15 DF,  p-value: 2.613e-08  # Extract and compare fixed effects ind_fixed <- fixef(ind_model) tank_fixed <- coef(tank_model) cbind(ind_fixed,tank_fixed) #>                 ind_fixed tank_fixed #> (Intercept)     5.5525654  5.5525654 #> factor(Dose)5   0.2648670  0.2648670 #> factor(Dose)10 -0.5573896 -0.5573896 #> factor(Dose)15 10.5099513 10.5099513 #> factor(Dose)20 18.6355902 18.6355902"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"example-2","dir":"Articles","previous_headings":"","what":"Example 2","title":"Mixed Models","text":"Simualate dose-response unequal variances across dose range.","code":"# Example with increasing variance by dose increasing_var_tank <- c(1, 2, 4, 8, 50) increasing_var_individual <- c(0.5, 1, 1.5, 2, 2.5)  # Simulate data with inhomogeneous variance sim_data_inhomogeneous <- simulate_dose_response(   n_doses = 5,   dose_range = c(0, 20),   m_tanks = 3,   k_individuals = 10,   var_tank = increasing_var_tank,   var_individual = increasing_var_individual,   include_individuals = TRUE )  prelimPlot3(sim_data_inhomogeneous%>% group_by(Dose,Tank)%>%summarise(Response=mean(Response),.groups = \"drop\"))"},{"path":[]},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"intraclass-correlation-coefficient-icc-patterns","dir":"Articles","previous_headings":"Expected Patterns in ICC and P-values Based on Variance Structures","what":"Intraclass Correlation Coefficient (ICC) Patterns","title":"Mixed Models","text":"ICC represents proportion total variance attributable -tank differences: \\[ \\mbox{ICC} = \\sigma^2_{}/(\\sigma^2_{} + \\sigma^2_{within}) \\] : - \\(\\sigma^2_{}\\) -tank variance (var_tank) - \\(\\sigma^2_{within}\\) within-tank variance (var_individual)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"expected-icc-patterns","dir":"Articles","previous_headings":"Expected Patterns in ICC and P-values Based on Variance Structures > Intraclass Correlation Coefficient (ICC) Patterns","what":"Expected ICC Patterns:","title":"Mixed Models","text":"ICC approaches 1.0 Indicates strong tank effects individuals within tank highly similar Example: var_tank = 10, var_individual = 1 \\(\\rightarrow\\) ICC \\(\\approx\\) 0.91 ICC approaches 0 Indicates weak tank effects individuals within tank vary substantially Example: var_tank = 1, var_individual = 10 \\(\\rightarrow\\) ICC \\(\\approx\\) 0.09 ICC = 0.5 Balanced contribution tank individual effects Example: var_tank = 4, var_individual = 4 \\(\\rightarrow\\) ICC = 0.5","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"individual-level-mixed-model-vs--tank-level-aggregated-model","dir":"Articles","previous_headings":"Expected Patterns in ICC and P-values Based on Variance Structures > P-value Patterns in Relation to Variance Structure","what":"Individual-Level Mixed Model vs. Tank-Level Aggregated Model:","title":"Mixed Models","text":"Tank-level model: perform nearly well individual-level model Individual-level model: Gains little additional power individual observations P-value comparison: models produce similar p-values Efficiency: Tank-level analysis efficient computationally minimal loss statistical power Tank-level model: Loses substantial information aggregating highly variable individuals Individual-level model: Gains significant power modeling individual observations P-value comparison: Individual-level model typically produce lower p-values (higher power) Efficiency: Individual-level analysis worth computational cost due increased power Trade-zone: Balance computational efficiency statistical power P-value comparison: Individual-level model generally produces lower p-values, advantage diminishes ICC increases","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"effect-of-variance-components-on-p-values","dir":"Articles","previous_headings":"Expected Patterns in ICC and P-values Based on Variance Structures > P-value Patterns in Relation to Variance Structure","what":"Effect of Variance Components on P-values:","title":"Mixed Models","text":"Increases overall variability data Decreases statistical power detecting dose effects Increases p-values models Makes tank-level aggregation reasonable (higher ICC) Increases variability individual level Decreases ICC Makes individual-level modeling advantageous Tank-level model p-values increase dramatically individual-level model p-values small effect sizes: Variance structure pronounced impact p-values large effect sizes: models may detect significant effects despite variance structure differences","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"practical-implications","dir":"Articles","previous_headings":"Expected Patterns in ICC and P-values Based on Variance Structures","what":"Practical Implications","title":"Mixed Models","text":"High ICC scenarios (ICC > 0.7) computational efficiency concern experimental design focuses tank-level responses Low moderate ICC scenarios (ICC < 0.7) maximum statistical power required individual-level covariates important variance increases dose, individual-level models appropriate variance structures become important Tank-level models may less robust variance heterogeneity systematically exploring patterns simulation, can develop guidelines choosing appropriate analysis approach based specific variance structure dose-response studies.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"references","dir":"Articles","previous_headings":"Expected Patterns in ICC and P-values Based on Variance Structures","what":"References","title":"Mixed Models","text":"cookbook development","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/LMM-GLMM-and-GAMM.html","id":"development-notes","dir":"Articles","previous_headings":"Expected Patterns in ICC and P-values Based on Variance Structures","what":"Development Notes","title":"Mixed Models","text":"multiple comparison using multcomp, several ways code functions: using .call using `` Define contrast matrix K, see drcHelper::dunnet_test examples.","code":"# Create a list for the mcp call   mcp_list <- list(\"Dunnett\")   names(mcp_list) <- dose_var    # Set control level if not the first level   if (control_level != levels(data[[dose_var]])[1]) {     control_idx <- which(levels(data[[dose_var]]) == as.character(control_level))     mcp_list$base <- control_idx   }      dunnett_result <- multcomp::glht(model, linfct = do.call(multcomp::mcp, mcp_list)) # Create the mcp call as a string and then evaluate it   mcp_call_str <- paste0(\"mcp(\", dose_var, \" = 'Dunnett')\")   if (control_level != levels(data[[dose_var]])[1]) {     mcp_call_str <- paste0(\"mcp(\", dose_var, \" = 'Dunnett', base = \", control_idx, \")\")   }      # Create the glht call as a string and then evaluate it   glht_call_str <- paste0(\"glht(model, linfct = \", mcp_call_str, \")\")   # Evaluate the call, not sure if we need to add , envir = eval_env to the eval function.   dunnett_result <- try(eval(parse(text = glht_call_str)), silent = TRUE)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"preliminary-assessment","dir":"Articles","previous_headings":"","what":"Preliminary Assessment","title":"Limit Test","text":"","code":"ctr <- testdata %>% filter(Dose == \"0\") ctr0 <- mean(ctr$Response) sres <- testdata %>% group_by(Dose)%>% dplyr::summarize(Mean=mean(Response),SD=sd(Response)) %>% mutate(`% Inhibition` = - ((Mean-ctr0)/ctr0)*100) sres %>% knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"outlier-check","dir":"Articles","previous_headings":"","what":"Outlier Check","title":"Limit Test","text":"","code":"dixon.test <- outliers::dixon.test DixonQ[DixonQ$n==6,\"Q_critical\"] #> [1] 0.56 outRes <- testdata %>% group_by(Dose) %>% nest() %>% mutate(normtest=map(data,~dixon.test(.x$Response)),                                        tidies= map(normtest,broom::tidy)) outRes <- outRes %>% dplyr::select(-c(data,normtest)) %>% unnest(c(tidies)) outRes %>% knitr::kable(.,digits = 3) ## by specifying the opposite: a logical indicating whether you want to check not the value with largest difference from the mean, but opposite (lowest, if most suspicious is highest etc.) outRes <- testdata %>% group_by(Dose) %>% nest() %>% mutate(normtest=map(data,~dixon.test(.x$Response,opposite = TRUE)),                                        tidies= map(normtest,broom::tidy)) outRes <- outRes %>% dplyr::select(-c(data,normtest)) %>% unnest(c(tidies)) outRes %>% knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"normality-check","dir":"Articles","previous_headings":"","what":"Normality Check","title":"Limit Test","text":"Welch’s t-test requires normality group. Normality residuals Normality group Variance Homogeneity","code":"mod <- lm(Response~factor(Dose),data=testdata) normalres <- shapiro.test(residuals(mod)) normRes <- testdata %>% group_by(Dose) %>% nest() %>% mutate(normtest=map(data,~shapiro.test(.x$Response)),                                        tidies= map(normtest,broom::tidy)) normRes <- normRes %>% dplyr::select(-c(data,normtest)) %>% unnest(c(tidies)) normRes %>% knitr::kable(.,digits = 3) (varTest <- car::leveneTest(Response~factor(Dose),data=testdata,center=mean)) #> Levene's Test for Homogeneity of Variance (center = mean) #>       Df F value Pr(>F) #> group  1  1.4879 0.2505 #>       10 ## lawstat::levene.test(testdata$Response,testdata$Dose,location=\"mean\") car::leveneTest(Response~factor(Dose),data=testdata,center=median) #> Levene's Test for Homogeneity of Variance (center = median) #>       Df F value Pr(>F) #> group  1  1.5126 0.2469 #>       10"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"students-t-test","dir":"Articles","previous_headings":"","what":"Student’s t-test","title":"Limit Test","text":"two-sided one-sided greater Note using formula, greater means test group greater control one-sided smaller Note using formula, greater means test group greater control","code":"(res <- t.test(testdata$Response~testdata$Dose,var.equal = TRUE)) #>  #>  Two Sample t-test #>  #> data:  testdata$Response by testdata$Dose #> t = 2.0993, df = 10, p-value = 0.06215 #> alternative hypothesis: true difference in means between group 0 and group 100 is not equal to 0 #> 95 percent confidence interval: #>  -0.0006161316  0.0207027221 #> sample estimates: #>   mean in group 0 mean in group 100  #>         0.1364410         0.1263977 tres <- broom::tidy(res) tres1 <- c(tres$estimate1,tres$estimate2, tres$parameter,sres$`% Inhibition`[2], -tres$statistic,tres$p.value) names(tres1) <- c(\"Mean Control\", \"Mean Test Item\", \"df\", \"%Inhibition\", \"T-statistic\", \"p-value\") tres1 #>   Mean Control Mean Test Item             df    %Inhibition    T-statistic  #>     0.13644102     0.12639773    10.00000000     7.36090584    -2.09934893  #>        p-value  #>     0.06214521 (res <- t.test(testdata$Response~testdata$Dose,var.equal = TRUE,alternative=\"greater\")) #>  #>  Two Sample t-test #>  #> data:  testdata$Response by testdata$Dose #> t = 2.0993, df = 10, p-value = 0.03107 #> alternative hypothesis: true difference in means between group 0 and group 100 is greater than 0 #> 95 percent confidence interval: #>  0.001372473         Inf #> sample estimates: #>   mean in group 0 mean in group 100  #>         0.1364410         0.1263977 tres <- broom::tidy(res) tres1 <- c(tres$estimate1,tres$estimate2, tres$parameter,sres$`% Inhibition`[2], -tres$statistic,tres$p.value) names(tres1) <- c(\"Mean Control\", \"Mean Test Item\", \"df\", \"%Inhibition\", \"T-statistic\", \"p-value\") tres1 #>   Mean Control Mean Test Item             df    %Inhibition    T-statistic  #>     0.13644102     0.12639773    10.00000000     7.36090584    -2.09934893  #>        p-value  #>     0.03107261 (res <- t.test(testdata$Response~testdata$Dose,var.equal = TRUE,alternative=\"less\")) #>  #>  Two Sample t-test #>  #> data:  testdata$Response by testdata$Dose #> t = 2.0993, df = 10, p-value = 0.9689 #> alternative hypothesis: true difference in means between group 0 and group 100 is less than 0 #> 95 percent confidence interval: #>        -Inf 0.01871412 #> sample estimates: #>   mean in group 0 mean in group 100  #>         0.1364410         0.1263977 tres <- broom::tidy(res) tres1 <- c(tres$estimate1,tres$estimate2, tres$parameter,sres$`% Inhibition`[2], -tres$statistic,tres$p.value) names(tres1) <- c(\"Mean Control\", \"Mean Test Item\", \"df\", \"%Inhibition\", \"T-statistic\", \"p-value\") tres1 #>   Mean Control Mean Test Item             df    %Inhibition    T-statistic  #>      0.1364410      0.1263977     10.0000000      7.3609058     -2.0993489  #>        p-value  #>      0.9689274"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"welchs-t-test","dir":"Articles","previous_headings":"","what":"Welch’s t-test","title":"Limit Test","text":"Welch Two Sample t-test one-sided greagter one-sided smaller","code":"(res <- t.test(testdata$Response~testdata$Dose)) #>  #>  Welch Two Sample t-test #>  #> data:  testdata$Response by testdata$Dose #> t = 2.0993, df = 7.5933, p-value = 0.07085 #> alternative hypothesis: true difference in means between group 0 and group 100 is not equal to 0 #> 95 percent confidence interval: #>  -0.001092339  0.021178930 #> sample estimates: #>   mean in group 0 mean in group 100  #>         0.1364410         0.1263977 tres <- broom::tidy(res) tres1 <- c(tres$estimate1,tres$estimate2, tres$parameter,sres$`% Inhibition`[2], -tres$statistic,tres$p.value) names(tres1) <- c(\"Mean Control\", \"Mean Test Item\", \"df\", \"%Inhibition\", \"T-statistic\", \"p-value\") tres1 #>   Mean Control Mean Test Item             df    %Inhibition    T-statistic  #>     0.13644102     0.12639773     7.59330452     7.36090584    -2.09934893  #>        p-value  #>     0.07085487 (res <- t.test(testdata$Response~testdata$Dose,alternative =\"less\")) #>  #>  Welch Two Sample t-test #>  #> data:  testdata$Response by testdata$Dose #> t = 2.0993, df = 7.5933, p-value = 0.9646 #> alternative hypothesis: true difference in means between group 0 and group 100 is less than 0 #> 95 percent confidence interval: #>        -Inf 0.01900155 #> sample estimates: #>   mean in group 0 mean in group 100  #>         0.1364410         0.1263977 tres <- broom::tidy(res) tres1 <- c(tres$estimate1,tres$estimate2, tres$parameter,sres$`% Inhibition`[2], -tres$statistic,tres$p.value) names(tres1) <- c(\"Mean Control\", \"Mean Test Item\", \"df\", \"%Inhibition\", \"T-statistic\", \"p-value\") tres1 #>   Mean Control Mean Test Item             df    %Inhibition    T-statistic  #>      0.1364410      0.1263977      7.5933045      7.3609058     -2.0993489  #>        p-value  #>      0.9645726 (res <- t.test(testdata$Response~testdata$Dose,alternative =\"greater\")) #>  #>  Welch Two Sample t-test #>  #> data:  testdata$Response by testdata$Dose #> t = 2.0993, df = 7.5933, p-value = 0.03543 #> alternative hypothesis: true difference in means between group 0 and group 100 is greater than 0 #> 95 percent confidence interval: #>  0.001085044         Inf #> sample estimates: #>   mean in group 0 mean in group 100  #>         0.1364410         0.1263977 tres <- broom::tidy(res) tres1 <- c(tres$estimate1,tres$estimate2, tres$parameter,sres$`% Inhibition`[2], -tres$statistic,tres$p.value) names(tres1) <- c(\"Mean Control\", \"Mean Test Item\", \"df\", \"%Inhibition\", \"T-statistic\", \"p-value\") tres1 #>   Mean Control Mean Test Item             df    %Inhibition    T-statistic  #>     0.13644102     0.12639773     7.59330452     7.36090584    -2.09934893  #>        p-value  #>     0.03542743"},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"kruskalwallis-test","dir":"Articles","previous_headings":"Nonparametric test","what":"Kruskal–Wallis test","title":"Limit Test","text":"","code":"(kwres <- kruskal.test(Response~Dose,data=testdata)) #>  #>  Kruskal-Wallis rank sum test #>  #> data:  Response by Dose #> Kruskal-Wallis chi-squared = 4.3333, df = 1, p-value = 0.03737"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"dunns-test-many-to-one","dir":"Articles","previous_headings":"Nonparametric test","what":"Dunn’s test (many-to-one)","title":"Limit Test","text":"essence, Dunn’s test can viewed series Wilcoxon rank sum tests applied pairs groups, adjustments made multiple comparisons. link Dunn’s test Wilcoxon rank sum test lies non-parametric nature rank-based approach. Wilcoxon rank sum test used comparing two groups, Dunn’s test extends concept rank comparisons multiple groups following Kruskal-Wallis test.","code":"## (dunnres <- PMCMRplus::kwManyOneDunnTest(Response~factor(Dose),data=testdata))"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Limit-Test.html","id":"wilcoxon-test","dir":"Articles","previous_headings":"Nonparametric test","what":"Wilcoxon test","title":"Limit Test","text":"Wilcoxon rank-sum test (also called Mann–Whitney U-test) data deviates significantly normal.","code":"(Ures <- wilcox.test(Response~factor(Dose),data=testdata)) #>  #>  Wilcoxon rank sum exact test #>  #> data:  Response by factor(Dose) #> W = 31, p-value = 0.04113 #> alternative hypothesis: true location shift is not equal to 0 ## same results would be obtained by specifying x and y instead of a formula ## wilcox.test(testdata$Response[testdata$Dose==\"0\"],testdata$Response[testdata$Dose==\"100\"],data=testdata) (Ures <- wilcox.test(Response~factor(Dose),data=testdata,alternative=\"greater\")) #>  #>  Wilcoxon rank sum exact test #>  #> data:  Response by factor(Dose) #> W = 31, p-value = 0.02056 #> alternative hypothesis: true location shift is greater than 0 (Ures <- wilcox.test(Response~factor(Dose),data=testdata,alternative=\"less\")) #>  #>  Wilcoxon rank sum exact test #>  #> data:  Response by factor(Dose) #> W = 31, p-value = 0.987 #> alternative hypothesis: true location shift is less than 0"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/MQJT.html","id":"the-mqjt","dir":"Articles","previous_headings":"","what":"The MQJT","title":"MQJT","text":"step-Jonckheere-Terpstra test applied replicate medians conventionally used statistical analysis amphibian developmental stage. questions raised whether analysis focused median developmental stage rep sufficiently sensitive detect statistically effects developmental stage biologically important. Thus John Tim proposed modification standard step-Jonckheere-Terpstra test procedure examines multiple quantiles (.e. shifts Q20, Q30, Q40, Q50, . . . , Q80) simultaneously. assumption behind MQJT shift entire distribution expected “true” effect population. effect small portion sensitive population considered biologically relevant majority replicate affected. hand, even replicate median similar across test concentrations / doses, quantiles different, showing effect test item, significant effect identified test. Assuming common distribution test concentrations (standard assumption almost statistical analyses), difference nth quantile, Qn, median, Q50, constant across concentrations. Thus, shifts Q20, Q30, Q40, Q50, . . ., Q80, measure effect test concentrations segment frequency distribution stages. Excerpt John’s “Supplementary Approach Statistical Analysis Developmental Stage Amphibians” proposed method proceeds follows: 1. Determine 20th percentile stage distribution within rep test concentration. Perform Jonkheere-Terpstra trend test 20th percentiles across concentrations. Record P-value trend test. Repeat steps 1 2 30th 80th percentile. Determine median P-values obtained steps 1-3. median P-value probability trend distribution shifts across concentrations due chance. median p-value 0.05 greater, testing stops NOEC exceeds highest tested concentration. Otherwise, proceed step (5). Drop data highest test concentration, repeat steps 1-4, new median P-value calculated reduced data set. median p-value 0.05 greater, testing stops NOEC highest tested concentration used analysis. Otherwise, proceed step (6). Drop data highest concentration used current analysis, repeat steps 1-4, new median P-value calculated reduced data set. Continue dropping treatment groups new median P-value longer statistically significant. highest concentration occurs noobserved- effect-concentration (NOEC).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/MQJT.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"MQJT","text":"OECD TG 231, https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119488798.ch9","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_ECx_BMD.html","id":"current-statistical-practices","dir":"Articles","previous_headings":"","what":"Current Statistical Practices","title":"NOEC, ECx, BMD, etc.","text":"Current statistical practices typically involve following steps: Define endpoints (survival, growth, reproduction, etc.) Identify concentration range replication Randomization controls Data integrity, outliers, missing values Plot response vs. dose Assess data distribution variance homogeneity Apply ANOVA/multiple comparisons (e.g., Dunnett’s) sequential tests. Identify highest dose without significant difference Fit model (e.g., logistic, probit, Weibull) data Evaluate goodness--fit, possible data transformations Derive ECx values (EC10, EC20, etc.) using fitted model Estimations predictions needed Confidence intervals NOEC ECx values Comparison model-based ECx estimates versus NOEC Use NOEC ECx values along safety factors define acceptable exposure limits","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_ECx_BMD.html","id":"noec","dir":"Articles","previous_headings":"Current Statistical Practices","what":"NOEC","title":"NOEC, ECx, BMD, etc.","text":"Definition: highest tested concentration statistically significant adverse effect observed relative control. Regulatory Role: Historically used primary benchmark (e.g., deriving acceptable daily intakes environmental quality standards). Strengths: Straightforward concept quick interpret Familiar risk assessors historically embedded many regulatory frameworks Weaknesses: Strongly dependent dose spacing study design provide information magnitude effects progression along dose–response curve Binary interpretation (“effect” vs. “effect”) can oversimplify data Potentially influenced low statistical power, especially studies small sample sizes","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_ECx_BMD.html","id":"ecx-and-bmd","dir":"Articles","previous_headings":"Current Statistical Practices","what":"ECx and BMD","title":"NOEC, ECx, BMD, etc.","text":"Definition: concentration predefined percentage (x) effect (e.g., 10%, 20% reduction biological endpoint) observed relative control. Regulatory Role: Increasingly used quantitatively describe magnitude adverse effects along dose–response curve considered informative deriving species sensitivity distributions. Strengths: Utilizes full data set modeling dose–response relationship Provides nuanced continuous estimate along effect continuum (e.g., EC10 often seen protective) Facilitates interpolation extrapolation within tested range Offers possibility quantify uncertainty via confidence intervals Weaknesses: Heavily dependent choice fit dose–response model Requires sophisticated statistical methods expertise May sensitive violations model assumptions data quality distribution suboptimal cases, different models may yield different ECx estimates, raising issues model selection validation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_ECx_BMD.html","id":"methodological-improvements","dir":"Articles","previous_headings":"","what":"Methodological Improvements","title":"NOEC, ECx, BMD, etc.","text":"Papers, scientific opinions, guidance regularly published methodological improvements statistical evaluation ecotoxicological studies. advocate transparent reporting uncertainties assumptions model selection model averaging. Integration Bayesian methods bootstrap techniques better quantify uncertainty emerging research discussions. Model averaging.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_ECx_BMD.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"NOEC, ECx, BMD, etc.","text":"U.S. Environmental Protection Agency (EPA). EPA Guidelines Ecological Risk Assessment – available EPA website. URL: https://www.epa.gov/risk EFSA (2013) Guidance environmental risk assessment plant protection products. OECD Guidelines Testing Chemicals detail several standardized tests ecotoxicity discuss NOEC model-based endpoints. URL: https://www.oecd-ilibrary.org/environment/oecd-guidelines---testing--chemicals","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"noec-in-general","dir":"Articles","previous_headings":"","what":"NOEC in General","title":"NOEC Calculation for Continuous Data","text":"NOEC (Observed Effect Concentration) critical value ecotoxicology, representing highest concentration substance produce statistically significant effect test organisms compared control group. concept various names, including NOER(Observed Effect Rate), NOEDD(Observed Effect Daily Dose), NOAEL(Observed Adverse Effect Level), . important metric determining safe exposure levels chemicals assessing potential risks human health environment. relatively straightforward calulate intepret NOEC, widely used accepted regulatory world. However, also criticized limitations: focuses single concentration without statistically significant adverse effects tested study, potentially overlooking information complete dose-response study. observed responses NOEC vary studies, making harder compare studies ECx values. NOEC approach take test concentrations continuous variable, therefore allow estimation/prediction response test concentrations. heavily impacted sample size test concentration selections. Poor experimental design may yield high NOEC due decreased statistical sensitivity, desired regulatory context. article, focus NOEC methods continuous data, can also applied count data. can achieved either simply treating count data continuous transforming data stabilize variance. quantal data, please go Quantal Data information. Continuous data numerical data can take value within range (e.g., weight, height), count data discrete represent number occurrences event (e.g., number species observed pitfall). hard determine distribution count data real world. Poisson, negative-binomial common distributions used model count data. Poisson distribution often used mean variance equal, negative-binomial distribution used data exhibit overdispersion (variance greater mean). Many count datasets zeros expected standard count models, leading zero-inflated models hurdle models account excess. Small sample sizes can make difficult determine underlying distribution data can affect robustness statistical methods. also challenges like non-constant variance follow mean variance relationship, issues caused censoring truncation, etc. Therefore, transformations, logarithmic square root transformations, often used stabilize variance meet assumptions standard statistical tests continuous data dealing non-normal data distributions.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"methods-for-deriving-noec","dir":"Articles","previous_headings":"NOEC in General","what":"Methods for deriving NOEC","title":"NOEC Calculation for Continuous Data","text":"Dunnett’s Test: used compare multiple treatment groups control group controlling Type error, Step-Williams’ test: used identify significant trend. Non-parametric tests: like Dunn’s test Kruskal-Wallis test step-Jonckheere-Terpstra trend test. Williams’ test Dunnett’s test commonly used parametric methods used NOEC calculations. Williams’ test assumes data monotonic, meaning response variable consistently increases decreases across levels independent variable. assumption crucial validity test results. contrast, Dunnett’s test require data monotonic. flexibility allows applied wider range situations. data meet monotonicity assumption, Williams’ test tends bit greater statistical power compared Dunnett’s test. means Williams’ test likely detect true effect one exists, leading fewer Type II errors (failing reject false null hypothesis). However, situations data monotonic, Dunnett’s test appropriate. may slightly less power data monotonic, robustness handling non-monotonic data makes valuable tool statistical analysis.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"dealing-with-inhomogenous-variance","dir":"Articles","previous_headings":"NOEC in General","what":"Dealing with inhomogenous variance","title":"NOEC Calculation for Continuous Data","text":"several ways deal inhomogeneous variances. Welch’s ANOVA (adaptation ANOVA dose assume equal variance) followed Dunnett’s test inhomogeneous variances. Robust statistical techniques sandwich standard error estimations. Bootstrapping can used estimate confidence intervals NOEC without relying normality assumptions. Applying data transformations can stablize variances meet assumptions parametric tests. However, increases complexity results interpretation avoided possible. use mock Myriophyllum study illustrate NOECs derived different approaches. test full dose response study test organism Myriophyllum. 7 test concentrations. interested endpoint Growth Rate Total shoot length 14 d mock study data. Visualize data   Basic Summary Data Check normality residuals  Check homogeneity variance \\(\\alpha=0.01\\), homogeneity variance assumption rejected. \\(\\alpha=0.05\\), enough evidence reject homogeneity variance assumption. Check Monotonicity data shows significant linear trend can considered monotonic.","code":"data(\"test_cases_data\") testdata <- test_cases_data%>% filter(`Test organism` == \"Myriophyllum\" & Design ==\"NOEC/ECx\") unique(testdata$`Study ID`) #> [1] \"MOCK0065\" testdata$Dose <- as.numeric(gsub(\",\",\".\",testdata$Dose)) metainfo <- testdata[1,] design <- ifelse(metainfo$Design==\"Limit\",\"limit test\", \"full dose response study\") nconc <- length(unique(testdata$Dose)) # endpoints <- unique(testdata$Endpoint) # obsVar <- unique(testdata$`Measurement Variable`) endpoints <- unique(testdata[,c(\"Endpoint\",\"Measurement Variable\",\"Time\")]) str_endpoints <- apply(endpoints,1,function(x) paste(x[1], \"of\",x[2], \"at\",x[3])) concunit <- metainfo$Unit conctype <- metainfo$`Concentration type` #log1p <- function(x) log(x+1) ilog1p <- function(x) {   exp(x) - 1 } theme_set(theme_bw()) theme_update(plot.title =  element_text(hjust = 0.5)) ggplot(testdata,aes(x=as.character(Dose),y=Response))+geom_point() + ylab(\"Growth Rate\") + xlab(paste0(\"Test Concentration [\",conctype,\", \",concunit,\"]\"))+ggtitle(\"Total Shoot Length\") doses <- unique(testdata$Dose) ratios <- sapply(2:(length(doses) - 1), function(i) doses[i + 1] / doses[i]) ## note that the factor between the doses is around 2.95.  ggplot(testdata,aes(x=Dose,y=Response))+geom_point() + ylab(\"Growth Rate\") + xlab(paste0(\"Test Concentration [\",conctype,\", \",concunit,\"]\"))+ggtitle(\"Total Shoot Length\")+scale_x_continuous(breaks=doses,trans = scales::trans_new(\"log1p\",log1p,ilog1p))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) ctr <- testdata %>% filter(Dose == 0) ctr0 <- mean(ctr$Response) sres <- testdata %>% group_by(Dose)%>% dplyr::summarize(Mean=mean(Response),SD=sd(Response)) %>% mutate(`% Inhibition` = - ((Mean-ctr0)/ctr0)*100, CV=SD/Mean*100) sres %>% knitr::kable(.,digits = 3) testdata <- testdata %>% mutate(Treatment=factor(Dose)) mod0 <- lm(Response~Treatment,data=testdata) shapiro.test(residuals(mod0)) ## not completely normal  #>  #>  Shapiro-Wilk normality test #>  #> data:  residuals(mod0) #> W = 0.98098, p-value = 0.851 opar <- par(no.readonly = TRUE)  qqnorm(residuals(mod0)) qqline(residuals(mod0), col = 2) #par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))  #plot(mod0,ask=F) car::leveneTest(Response~Treatment,data=testdata,center=mean) #> Levene's Test for Homogeneity of Variance (center = mean) #>       Df F value  Pr(>F)   #> group  6  3.6043 0.01148 * #>       23                   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 car::leveneTest(Response~Treatment,data=testdata,center=median) #> Levene's Test for Homogeneity of Variance (center = median) #>       Df F value  Pr(>F)   #> group  6  2.7571 0.03616 * #>       23                   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 monotonicityTest(testdata,Treatment=\"Treatment\",Response=\"Response\") #>        Test t value Pr(>|t|) Significance #> 1    Linear  -12.55  <0.0001          *** #> 2 Quadratic    1.10   0.2814            ."},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"williams-trend-test","dir":"Articles","previous_headings":"","what":"Williams’ trend test","title":"NOEC Calculation for Continuous Data","text":"Note PMCMRplus::williamsTest produces accurate results. functions gives almost perfect agreement cases. Inside drcHelper package, getwilliamRes function get accept reject vector results.","code":"(will <- PMCMRplus::williamsTest(Response~Treatment,testdata,alternative =\"less\")) #>  #>   Williams trend test  #>  #> data:  Response by Treatment  #> alternative hypothesis:  less  #>  #> H0 #>                t'-value df t'-crit decision alpha #> mu1 - ctr >= 0    0.672 23   1.714   accept  0.05 #> mu2 - ctr >= 0    6.635 23   1.784   reject  0.05 #> mu3 - ctr >= 0   13.624 23   1.808   reject  0.05 #> mu4 - ctr >= 0   20.082 23   1.817   reject  0.05 #> mu5 - ctr >= 0   24.468 23   1.825   reject  0.05 #> mu6 - ctr >= 0   24.468 23   1.827   reject  0.05 #> --- drcHelper::williamsTest_JG(testdata,trt =\"Treatment\",res =\"Response\") #>    Treatment Y.Tilde     Y0  Se.Diff DF    Will TCrit Signif #> Q6        10 0.02885 0.1264 0.003987 23 24.4700 1.827      * #> Q5      3.39 0.02885 0.1264 0.003987 23 24.4700 1.825      * #> Q4      1.15 0.04630 0.1264 0.003987 23 20.0900 1.817      * #> Q3      0.39 0.07210 0.1264 0.003987 23 13.6200 1.808      * #> Q2     0.132 0.09990 0.1264 0.003987 23  6.6470 1.785      * #>       0.0448 0.12370 0.1264 0.003987 23  0.6772 1.714      . getwilliamRes(will) #> [1] \"accept\" \"reject\" \"reject\" \"reject\" \"reject\" \"reject\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"dunnetts-tests","dir":"Articles","previous_headings":"","what":"Dunnett’s Tests","title":"NOEC Calculation for Continuous Data","text":"Dunnett’s test multiple comparison test determining significant differences mean values several test groups control normally distributed errors homogeneous variance. Dunnett’s test robust slight violations normality variance homogeneity assumptions. several packages providing function calculation Dunnett’s test. function DunnettTest library DescTools calculating correct results “two.sided” direction. function dunnettTest library PMCMRplus can used calculate test options “less” (smaller), “greater” “two.sided”. results “two.sided” option differ cases results DunnettTest library DescTools, due multivariate normal calculations. Another commonly used tool glht function Dunnet type contrast multcomp package. also possibilities use packages. example, emmeans package estimating marginal means conducting pairwise comparisons. Another approach use emmeans package. Note p value adjustment method different called “dunnettx”. However t statistic, df, SE estimations . NOEC lowest tested concentration rdoses[2]`.","code":"library(multcomp) (dun <- summary(glht(aov(Response~Treatment, data=testdata), linfct=mcp(Treatment=\"Dunnett\"),alternative=\"less\"))) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: aov(formula = Response ~ Treatment, data = testdata) #>  #> Linear Hypotheses: #>                  Estimate Std. Error t value Pr(<t)     #> 0.0448 - 0 >= 0 -0.002679   0.003987  -0.672  0.648     #> 0.132 - 0 >= 0  -0.026454   0.003987  -6.635 <1e-04 *** #> 0.39 - 0 >= 0   -0.054314   0.003987 -13.624 <1e-04 *** #> 1.15 - 0 >= 0   -0.080064   0.003987 -20.082 <1e-04 *** #> 3.39 - 0 >= 0   -0.098517   0.003987 -24.711 <1e-04 *** #> 10 - 0 >= 0     -0.096580   0.003987 -24.225 <1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method)  (dun <- summary(glht(aov(Response~Treatment, data=testdata), linfct=mcp(Treatment=\"Dunnett\"),alternative=\"two.sided\"))) #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: aov(formula = Response ~ Treatment, data = testdata) #>  #> Linear Hypotheses: #>                  Estimate Std. Error t value Pr(>|t|)     #> 0.0448 - 0 == 0 -0.002679   0.003987  -0.672     0.97     #> 0.132 - 0 == 0  -0.026454   0.003987  -6.635   <1e-04 *** #> 0.39 - 0 == 0   -0.054314   0.003987 -13.624   <1e-04 *** #> 1.15 - 0 == 0   -0.080064   0.003987 -20.082   <1e-04 *** #> 3.39 - 0 == 0   -0.098517   0.003987 -24.711   <1e-04 *** #> 10 - 0 == 0     -0.096580   0.003987 -24.225   <1e-04 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) library(emmeans) m <- aov(Response~Treatment, data=testdata) emmeans(m, specs = trt.vs.ctrl ~ Treatment) #> $emmeans #>  Treatment emmean      SE df lower.CL upper.CL #>  0         0.1264 0.00252 23   0.1212   0.1316 #>  0.0448    0.1237 0.00309 23   0.1173   0.1301 #>  0.132     0.0999 0.00309 23   0.0936   0.1063 #>  0.39      0.0721 0.00309 23   0.0657   0.0785 #>  1.15      0.0463 0.00309 23   0.0399   0.0527 #>  3.39      0.0279 0.00309 23   0.0215   0.0343 #>  10        0.0298 0.00309 23   0.0234   0.0362 #>  #> Confidence level used: 0.95  #>  #> $contrasts #>  contrast                     estimate      SE df t.ratio p.value #>  Treatment0.0448 - Treatment0 -0.00268 0.00399 23  -0.672  0.9198 #>  Treatment0.132 - Treatment0  -0.02645 0.00399 23  -6.635  <.0001 #>  Treatment0.39 - Treatment0   -0.05431 0.00399 23 -13.624  <.0001 #>  Treatment1.15 - Treatment0   -0.08006 0.00399 23 -20.082  <.0001 #>  Treatment3.39 - Treatment0   -0.09852 0.00399 23 -24.711  <.0001 #>  Treatment10 - Treatment0     -0.09658 0.00399 23 -24.225  <.0001 #>  #> P value adjustment: dunnettx method for 6 tests"},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"jonckheere-terpstra-test","dir":"Articles","previous_headings":"Nonparametric Tests","what":"Jonckheere-Terpstra test","title":"NOEC Calculation for Continuous Data","text":"","code":"jonckheere <- PMCMRplus::stepDownTrendTest(Response~Treatment, data=testdata,test = \"jonckheereTest\",                          alternative = \"less\") summary(jonckheere) #>  #>   Step down Jonckheere-Terpstra test  #> data:  Response by Treatment  #> alternative hypothesis:  less  #> P value adjustment method:  none  #> H0 #>                           z value     Pr(<z)     #> 0.0448 >= 0                -1.066  0.1432110     #> 0.132 >= 0.0448 >= 0       -2.946  0.0016081  ** #> 0.39 >= 0.132 >= ... >= 0  -4.181 1.4491e-05 *** #> 1.15 >= 0.39 >= ... >= 0   -5.150 1.3033e-07 *** #> 3.39 >= 1.15 >= ... >= 0   -5.968 1.2019e-09 *** #> 10 >= 3.39 >= ... >= 0     -6.290 1.5913e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"dunns-test","dir":"Articles","previous_headings":"Nonparametric Tests","what":"Dunn’s test","title":"NOEC Calculation for Continuous Data","text":"Dunn’s test powerful general.","code":"m <- lm(Response~Treatment, data=testdata) dunn <- PMCMRplus::kwManyOneDunnTest(Response~Treatment, data=testdata,alternative = \"less\") summary(dunn) #>                 z value     Pr(<z)     #> 0.0448 - 0 >= 0  -0.367 0.77622945     #> 0.132 - 0 >= 0   -1.378 0.30718909     #> 0.39 - 0 >= 0    -2.082 0.08734203   . #> 1.15 - 0 >= 0    -2.786 0.01445234   * #> 3.39 - 0 >= 0    -3.974 0.00021077 *** #> 10 - 0 >= 0      -3.710 0.00062473 ***"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"dunnetts-tests-with-inhomogenious-variance","dir":"Articles","previous_headings":"","what":"Dunnett’s Tests with Inhomogenious Variance","title":"NOEC Calculation for Continuous Data","text":"","code":"inhomo <- require(nlme) library(nlme) gls0 <- gls(Response ~ Treatment, data=testdata,weights=varIdent(form= ~1|Treatment)) plot(gls0,Treatment ~ fitted(.)) ## Looking at the variances plot(gls0,Treatment ~ resid(.),abline=0) treat.means <- emmeans(gls0, ~ Treatment) ## no adjustment for p-values ## contrast(treat.means, adjust=\"none\", method=\"dunnett\", ref = 1) contrast(treat.means, method=\"dunnett\", ref = 1) #>  contrast                     estimate      SE   df t.ratio p.value #>  Treatment0.0448 - Treatment0 -0.00268 0.00345 6.66  -0.776  0.8819 #>  Treatment0.132 - Treatment0  -0.02645 0.00413 5.43  -6.402  0.0043 #>  Treatment0.39 - Treatment0   -0.05431 0.00623 3.89  -8.715  0.0042 #>  Treatment1.15 - Treatment0   -0.08006 0.00297 7.96 -26.947  <.0001 #>  Treatment3.39 - Treatment0   -0.09852 0.00279 8.01 -35.321  <.0001 #>  Treatment10 - Treatment0     -0.09658 0.00248 6.99 -38.867  <.0001 #>  #> Degrees-of-freedom method: satterthwaite  #> P value adjustment: dunnettx method for 6 tests summary(glht(gls0,mcp(Treatment=\"Dunnett\")))  #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: gls(model = Response ~ Treatment, data = testdata, weights = varIdent(form = ~1 |  #>     Treatment)) #>  #> Linear Hypotheses: #>                  Estimate Std. Error z value Pr(>|z|)     #> 0.0448 - 0 == 0 -0.002679   0.003453  -0.776    0.935     #> 0.132 - 0 == 0  -0.026454   0.004132  -6.402   <1e-05 *** #> 0.39 - 0 == 0   -0.054314   0.006232  -8.715   <1e-05 *** #> 1.15 - 0 == 0   -0.080064   0.002971 -26.947   <1e-05 *** #> 3.39 - 0 == 0   -0.098517   0.002789 -35.321   <1e-05 *** #> 10 - 0 == 0     -0.096580   0.002485 -38.867   <1e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- single-step method) fit <- aov(Response ~ Treatment, data=testdata) summary(PMCMRplus::welchManyOneTTest(fit, alternative = \"two.sided\", p.adjust=\"holm\")) #>                 t value   Pr(>|t|)     #> 0.0448 - 0 == 0  -0.776  0.4640697     #> 0.132 - 0 == 0   -6.402  0.0030079  ** #> 0.39 - 0 == 0    -8.715  0.0030079  ** #> 1.15 - 0 == 0   -26.947 1.9119e-08 *** #> 3.39 - 0 == 0   -35.321 2.7730e-09 *** #> 10 - 0 == 0     -38.867 1.0129e-08 *** summary(glht(gls0,mcp(Treatment=\"Dunnett\")),test = adjusted(\"holm\"))  #>  #>   Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Dunnett Contrasts #>  #>  #> Fit: gls(model = Response ~ Treatment, data = testdata, weights = varIdent(form = ~1 |  #>     Treatment)) #>  #> Linear Hypotheses: #>                  Estimate Std. Error z value Pr(>|z|)     #> 0.0448 - 0 == 0 -0.002679   0.003453  -0.776    0.438     #> 0.132 - 0 == 0  -0.026454   0.004132  -6.402 3.07e-10 *** #> 0.39 - 0 == 0   -0.054314   0.006232  -8.715  < 2e-16 *** #> 1.15 - 0 == 0   -0.080064   0.002971 -26.947  < 2e-16 *** #> 3.39 - 0 == 0   -0.098517   0.002789 -35.321  < 2e-16 *** #> 10 - 0 == 0     -0.096580   0.002485 -38.867  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> (Adjusted p values reported -- holm method)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"alternative-approaches","dir":"Articles","previous_headings":"","what":"Alternative Approaches","title":"NOEC Calculation for Continuous Data","text":"approaches routinely used regulatory NOEC calculations. However, useful certain situations.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"tamhane-dunnetts-test","dir":"Articles","previous_headings":"Alternative Approaches","what":"Tamhane-Dunnett’s Test","title":"NOEC Calculation for Continuous Data","text":"many--one comparisons one-factorial layout normally distributed residuals unequal variances Tamhane-Dunnett’s test can used.","code":"set.seed(245) mn <- c(1, 2, 2^2, 2^3, 2^4) x <- rep(mn, each=5) + rnorm(25) g <- factor(rep(1:5, each=5))  fit <- aov(x ~ g - 1) shapiro.test(residuals(fit)) #>  #>  Shapiro-Wilk normality test #>  #> data:  residuals(fit) #> W = 0.96609, p-value = 0.5484 bartlett.test(x ~ g - 1) #>  #>  Bartlett test of homogeneity of variances #>  #> data:  x by g #> Bartlett's K-squared = 1.0766, df = 4, p-value = 0.898 anova(fit) #> Analysis of Variance Table #>  #> Response: x #>           Df  Sum Sq Mean Sq F value    Pr(>F)     #> g          5 1761.11  352.22  171.01 1.069e-15 *** #> Residuals 20   41.19    2.06                       #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## works with object of class aov library(PMCMRplus) summary(tamhaneDunnettTest(fit, alternative = \"greater\")) #>            t value     Pr(>t)     #> 2 - 1 <= 0   1.399 0.32792374     #> 3 - 1 <= 0   3.368 0.01849964   * #> 4 - 1 <= 0   7.223 0.00021346 *** #> 5 - 1 <= 0  15.186 3.5096e-09 *** ## summary(welchManyOneTTest(fit, alternative = \"greater\", p.adjust=\"single-step\")) ## p.adjust “holm”, “hochberg”, “hommel”, “bonferroni”, “BH”, “BY”, “fdr”, “none” summary(welchManyOneTTest(fit, alternative = \"greater\", p.adjust=\"holm\")) #>            t value     Pr(>t)     #> 2 - 1 <= 0   1.399 0.10262533     #> 3 - 1 <= 0   3.368 0.01089476   * #> 4 - 1 <= 0   7.223 0.00013621 *** #> 5 - 1 <= 0  15.186 7.0276e-07 *** DescTools::DunnettTest(x~g, alternative = \"greater\") ## alternative is not taking effect in this case #>  #>   Dunnett's test for comparing several treatments with a control :   #>     95% family-wise confidence level #>  #> $`1` #>          diff     lwr.ci    upr.ci    pval     #> 2-1  1.201147 -1.2064128  3.608708  0.4992     #> 3-1  3.041632  0.6340717  5.449192  0.0110 *   #> 4-1  7.245476  4.8379162  9.653037 5.1e-08 *** #> 5-1 15.611204 13.2036439 18.018764 < 2e-16 *** #>  #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 PMCMRplus::dunnettTest(x~g) #>   1       #> 2 0.511   #> 3 0.012   #> 4 1.2e-07 #> 5 < 2e-16 PMCMRplus::dunnettTest(x~g, alternative = \"greater\") #>   1       #> 2 0.2554  #> 3 0.0055  #> 4 1.9e-08 #> 5 < 2e-16"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/NOEC_Methods.html","id":"references","dir":"Articles","previous_headings":"Alternative Approaches","what":"References","title":"NOEC Calculation for Continuous Data","text":"DUNNETT C. W. (1955): multiple comparison procedure comparing several treatments control, Journal American Statistical Association, 50, pp. 1096-1121.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Normality-Check.html","id":"standard-practices","dir":"Articles","previous_headings":"","what":"Standard Practices","title":"Normality Check","text":"context statistical analysis, conducting normality assessment preliminary step outlined decision flowchart established OECD 54 various testing guidelines. Shapiro-Wilk test robust option purpose, particularly dealing relatively small sample sizes. important note several methodologies available evaluating normality. One approach involves assessing whether data within treatment group test concentration group adheres normal distribution. Alternatively, one can examine normality residuals following ANOVA linear regression analysis. first approach assumes data within treatment group normally distributed, without imposing constraints homogeneity variance. Conversely, second approach posits residuals drawn single normal distribution, thereby providing different perspective data’s adherence normality. Check normality Significance level \\(\\alpha\\) = 0.05. p-value conditional probability obtaining test results extreme observed one given null hypothesis H0 (normal distribution) true. p smaller pre-determined significance level \\(\\alpha\\), null hypothesis rejected. Result Shapiro-Wilk’s test: Residuals ANOVA presented QQ-plot.","code":"## It is possible to use options(digits = 7) to control the number ## of digits in print outs. However, it is not necessary to do so. vgl_0 <- c(0.131517109035102, 0.117455425985384, 0.130835155683102,            0.12226548296818, 0.127485057136569, 0.128828137633933) vgl_1 <- c(0.122888192029009, 0.126866725094641, 0.128467082586674,            0.116653888503673) vgl_2 <- c(0.0906079518188219, 0.102060998252763, 0.107240263636048,            0.0998663441976353) vgl_3 <- c(0.0584507373938537, 0.066439126181113, 0.0806046608441279,            0.0828404794158172) vgl_4 <- c(0.0462632004630849, 0.0461876546375037, 0.0512317665813575,            0.0416533060961155) vgl_5 <- c(0.0267638178172436, 0.0314508456741666, 0.0237960318948956,            0.0295133681572911) vgl_6 <- c(0.0273565894468647, 0.0324226779638651, 0.0289617934362975,             0.0305317153447814)  x0 <- vgl_0 - mean(vgl_0) x1 <- vgl_1 - mean(vgl_1) x2 <- vgl_2 - mean(vgl_2) x3 <- vgl_3 - mean(vgl_3) x4 <- vgl_4 - mean(vgl_4) x5 <- vgl_5 - mean(vgl_5) x6 <- vgl_6 - mean(vgl_6)  res <- shapiro.test(c(x0, x1, x2, x3, x4, x5, x6)) res #>  #>  Shapiro-Wilk normality test #>  #> data:  c(x0, x1, x2, x3, x4, x5, x6) #> W = 0.98098, p-value = 0.851 knitr::kable(broom::tidy(res), digits = 2) ## pander::pander(broom::tidy(res), digits = 2)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Normality-Check.html","id":"limitations","dir":"Articles","previous_headings":"","what":"Limitations","title":"Normality Check","text":"fundamental issue passing normality test small sample size provides little evidence underlying distribution actually normal. hand, large sample size, almost tiny deviation flagged non-normal. Therefore, rather hard interpret normality check results meaningfully. importantly, pre-testing largely unnecessary since common parametric tests like ANOVA t-tests robust moderate violations normality due Central Limit Theorem. combination unreliability small samples unnecessary verification assumptions makes normality testing questionable practice many research contexts. example, mixture normals (almost-normal terms Q-Q plots) detected easily small sample size (smaller 1000) (taken post1).","code":"x <- replicate(   100,   {     c(       shapiro.test(rnorm(10) + c(1, 0, 2, 0, 1))$p.value, # $       shapiro.test(rnorm(100) + c(1, 0, 2, 0, 1))$p.value, # $       shapiro.test(rnorm(1000) + c(1, 0, 2, 0, 1))$p.value, # $       shapiro.test(rnorm(5000) + c(1, 0, 2, 0, 1))$p.value     )   } ) rownames(x) <- c(\"n10\", \"n100\", \"n1000\", \"n5000\") apply(x, 1, function(y) {   sum(y < 0.05) }) #>   n10  n100 n1000 n5000  #>     8     7    15    85"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Normality-Check.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Normality Check","text":"Micceri, T. (1989). unicorn, normal curve, improbable creatures. Psychological Bulletin, 105(1), 156-166.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"xeta-xenopus-embryonic-thyroid-assay","dir":"Articles","previous_headings":"","what":"XETA (Xenopus embryonic thyroid assay)","title":"Aquatic ED Assays","text":"OECD 248","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"validity-criteria","dir":"Articles","previous_headings":"XETA (Xenopus embryonic thyroid assay)","what":"Validity Criteria","title":"Aquatic ED Assays","text":"statistically significant induction fluorescence measured test medium control group T3 control group. mean fluorescence T3 group least 20% higher mean fluorescence test medium control group. statistically significant induction fluorescence least 70% present T4 control group test medium control. coefficient variation fluorescence intensity measured test medium control exceed 30%. initial pH exposure solutions 6.5 8.5 renewal. mortality exceed 10% control group. percentage malformed organisms exceed 10% control group.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"recommendations","dir":"Articles","previous_headings":"XETA (Xenopus embryonic thyroid assay)","what":"Recommendations","title":"Aquatic ED Assays","text":"test duration: 72 h test temperature: 21°C","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"decision-logic","dir":"Articles","previous_headings":"XETA (Xenopus embryonic thyroid assay)","what":"Decision logic","title":"Aquatic ED Assays","text":"link increase fluorescence endocrine mechanism. increase \\(>\\) 12% unspiked mode needs observed conclude test substance thyroid active. increase >12% spiked mode needs observed conclude test substance thyroid active.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"trimming","dir":"Articles","previous_headings":"XETA (Xenopus embryonic thyroid assay)","what":"Trimming","title":"Aquatic ED Assays","text":"Trimming done usually stablize variance. Analysis without trimming can presented understand sensitivity trimming.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"ama","dir":"Articles","previous_headings":"","what":"AMA","title":"Aquatic ED Assays","text":"TG: OECD 231; U.S. EPA OPPTS 890.1100","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"validity","dir":"Articles","previous_headings":"AMA","what":"Validity","title":"Aquatic ED Assays","text":"given treatment (including controls), mortality exceed 10%. given replicate, mortality exceed three tadpoles, otherwise replicate considered compromised. least two treatment levels, four uncompromised replicates, available analysis. least two treatment levels without overt toxicity available analysis. Mortality two tadpoles/replicate control group can occur.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"recommended-analylsis","dir":"Articles","previous_headings":"AMA","what":"Recommended Analylsis:","title":"Aquatic ED Assays","text":"Data continuous quantitative endpoints (HHL, nHHL, SVL, wet weight) monotone dose-response analysed Jonckheere-Terpstra test applied replicate medians. non-monotone dose-response relationships data analysed Dunnet’s test applied replicate means. Median Development Stage: multi-quantile Jonckheere-Terpstra trend test","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"fistra","dir":"Articles","previous_headings":"","what":"FISTRA","title":"Aquatic ED Assays","text":"Short-term reproduction assay fathead minnow (Pimephales promelas) TG: OECD 229 (2012); OCSPP 890.1350 (2009)","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/OECD_ED_Assays.html","id":"softwares","dir":"Articles","previous_headings":"Statisstical Analysis","what":"Softwares","title":"Aquatic ED Assays","text":"Welch’s t-test Bonferroni-Holm heterogeneuous variance Bonferroni-Median-test (Dunn’s test?) xereda","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Example Ordinal Data Analysis","text":"routine procedures regulatory frameworks ordinal data analysis yet. histopathological data, recommended use RSCABS (Rao-Scott Adjusted Cochran-Armitage Trend Test Slices) derive NOEALs. alternative MQJT(Multiquantal Jonckheere–Terpstra), mentioned OECD TG 231 AMA life stage analysis. Plant visual injury data evaluated qualitatively possible analyze quantitatively. well-behaving data (full clear dose-response), approaches produce similar results long target endpoint (test rate concentration average injury reaching 50% medium injury category) . article, explain several regression modelling can applied, focusing nonlinear regression sigmoid shaped curve, logistic regression quasibinomial likelihood, conventional proportional odds logistic regression. approaches different endpoint type demonstrated well, including BMD ordinal data using bmdordinal, RSCABS, etc. approaches limitations need treated caution. example, nonlinear model normal error assumption behind, issues occur inhomogeneous variance, uncertain considerations critical data -spread across many categories close estimated ER50. think whichever method choose, careful evaluation assumptions model check model data agreement always necessary.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"ordinal-data-in-general","dir":"Articles","previous_headings":"","what":"Ordinal Data in General","title":"Example Ordinal Data Analysis","text":"statistical point view, ordinal data type categorical data order matters, exact differences distances categories defined. example, survey responses like “satisfied,” “neutral,” “dissatisfied”, ranking like 1st, 2nd, 3rd, levels education like high school, bachelor, master. Market research, psychology, health studies, social sciences often use ordinal data. Since ordinal data doesn’t assume equal intervals, non-parametric methods often used. Medians rather means often basis comparisons. Chi-Square test can used determine significant association two categorical variables. Spearman’s Rank Correlation Kendall’s tau correlation measures can assess strength direction association two ranked variables. Ordinal Regression somewhat complex method can predict outcomes based ordinal data. helps understand different factors influence rankings transition ordered categories. Proportional Odds Model: Coefficient (slopes) remains constant across categories. Continuation Ratio Model: Model cumulative odds ratios. Adjacent Categories Model: useful neighboring categories influence . Due limited information potentially unequal intervals, requires clear understanding subtleties complexities, careful attentions implementing regression modelling. ecotoxicology area, histopathology assessment visual injury data ranked categorical data. focus plant visual injury data (PVI).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"type-of-endpoints","dir":"Articles","previous_headings":"","what":"Type of Endpoints","title":"Example Ordinal Data Analysis","text":"Depending response variables independent variables treated, different types endpoints can derived. independent variable treated factor categorical, Observed Effect Concentration (NOEC) regarding specific injury level can derived treating response ordinal. Alternatively, NOEC can calculated treating response continuous, using either direct hypothesis testing post hoc testing regression modeling. Conversely, independent variable treated continuous, endpoints ECx Benchmark Dose (BMDx) regarding specific injury level (response treated ordinal) regarding average injury level (response treated continuous) can calculated.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"data-characteristics","dir":"Articles","previous_headings":"","what":"Data Characteristics","title":"Example Ordinal Data Analysis","text":"systematic error bias can occur assessment Plant Visual Injury (PVI) data beyond scope discussion. , focus solely analysis approaches.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"limitations","dir":"Articles","previous_headings":"","what":"Limitations","title":"Example Ordinal Data Analysis","text":"method makes assumptions inherent limitations. example, Rao-Scott Cochran-Armitage slice (RSCABS) method handle many categories effectively. Ordinal regression can complex determining Effective Rate (ER50) Effective Concentration (EC50). Additionally, treating response continuous (0 1 0 100%) may lead issues heterogeneous variance.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"regression-approaches-with-continuous-x","dir":"Articles","previous_headings":"","what":"Regression Approaches with Continuous x","title":"Example Ordinal Data Analysis","text":"natural approach using conventional ordinal regression modelling derive ER50. However, approach routinely applied regulatory ecotoxicology, interpretation including assumption behind bit complex. derive ER50, specific function optimization need defined purpose. Confidence intervals need derived bootstrap method take longer time calculation. use approach comparison commonly easily applied modelling approaches. transforming ordinal variable percentages proportions, also possible model continuous data using logitic regression quasibinomial assumptions. two approaches produce similar results data behaving truly like dose-response -dispersed binomial distributions. data artificial full dose-response relationship observed true ER50=12.18.","code":"library(drcHelper) dattab_new <- pvi_example ## use the example PVI data in the drcHelper package ## Note that yy2 is transformed by increment of 90/5 = 16.  dattab_new$y0 <- factor(dattab_new$y0,ordered = T) ftable(xtabs(~ y0 + dose, data = dattab_new)) ##%>% gt::gt() ## as.data.frame(.) %>% knitr::kable(.,digits = 3) #>    dose  2  4  8 16 32 64 #> y0                        #> 0        8  3  1  0  0  0 #> A        2  5  2  0  1  0 #> B        0  2  4  2  0  0 #> C        0  0  2  1  1  0 #> D        0  0  1  5  2  0 #> E        0  0  0  2  5  0 #> F        0  0  0  0  1 10 dattab_new %>% group_by(y0) %>% summarise(n=n(),meany=mean(yt),meanyy2=mean(yy2)) %>% knitr::kable(.,digits = 3) dattab_new %>% group_by(dose) %>% summarise(n=n(),meany=mean(yt),meanyy=mean(yy)) %>% knitr::kable(.,digits = 3) ggplot(dattab_new,aes(x = dose, y=yt))+geom_point() +  geom_smooth(method=\"glm\", method.args=list(family=\"quasibinomial\"), formula=\"y ~ log(x)\",                        se =TRUE, linewidth=1.5) library(drc) mod_drc  <- drm(yy2 ~ dose, data = dattab_new, fct = LL.2()) summary(mod_drc) #>  #> Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1 (2 parms) #>  #> Parameter estimates: #>  #>               Estimate Std. Error t-value   p-value     #> b:(Intercept) -1.33865    0.13595 -9.8465 5.487e-14 *** #> e:(Intercept) 12.74391    1.03919 12.2633 < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: #>  #>  0.1446638 (58 degrees of freedom) ED(mod_drc, c(50), interval = \"delta\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:50  12.7439     1.0392 10.6637 14.8241 suppressWarnings({ plot(mod_drc, type = \"all\",main=\"log-logistic + normal, ER50= 12.74\", broken = TRUE) plot(mod_drc, broken = TRUE, type=\"confidence\", add=TRUE) })"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"putting-quasi-binomial-and-normal-fit-together","dir":"Articles","previous_headings":"Regression Approaches with Continuous x","what":"Putting quasi-binomial and normal fit together","title":"Example Ordinal Data Analysis","text":"","code":"library(drc) predictCIglm <- function(mod,dat,newdata=NULL){  if(is.null(newdata)){     preddata <- with(dat, data.frame(x = seq(min(x), max(x), length = 100)))  }else predata <- newdata   preds <- predict(mod, newdata = preddata, type = \"link\", se.fit = TRUE)   critval <- 1.96 ## approx 95% CI qnorm(0.975)   upr <- preds$fit + (critval * preds$se.fit)   lwr <- preds$fit - (critval * preds$se.fit)   fit <- preds$fit   fit2 <- mod$family$linkinv(fit)   upr2 <- mod$family$linkinv(upr)   lwr2 <- mod$family$linkinv(lwr)   preddata$Prediction <- fit2    preddata$Lower <- lwr2    preddata$Upper <- upr2    return(preddata) }   preddrc <- function(mod,dat,newdata=NULL){  if(is.null(newdata)){     preddata <- with(dat, data.frame(x = seq(min(x), max(x), length = 100)))  }else predata <- newdata  preds <- predict(mod,newdata=preddata,interval=\"confidence\")  preddata <- cbind(preddata,preds)  return(preddata) } modelall <- function(dat,addbeta = FALSE){   mod1 <- glm(y~log(x),data=dat,family = \"quasibinomial\")   mod2 <- drm(y~x,fct=LL.2(),data=dat)     ## mod3 <- MASS::glmmPQL(y ~ log(x),random=~1|x,family=\"quasibinomial\",data=dat)    ## Estimation the same as quasibinomial without random effects, uncertainty estimation wider.    ## mod3 <- lme4::glmer(y ~ log(x)+ (1|x),family=\"binomial\",data=dat) ## dose not work without sample size.   # mod4 <- betareg::betareg(y ~ log(x),link=\"logit\",data=dat)   # y3<- predict(mod3,newdata=data.frame(x=dat$x),type=\"response\")   y1 <- predictCIglm(mod1,dat=dat)   y1$model <- \"quasibinomial\"    y2 <- preddrc(mod2,dat = dat)   y2$model <- \"drc LL.2\"   preddata <- rbind(y1,y2)      ec1 <- getEC50(mod1)   ec2 <- getEC50(mod2)   ec50 <- data.frame(rbind(ec1,ec2),model=c(\"quasibinomial\",\"drc LL.2\"))      if(addbeta) {     mod3 <- gam(y ~ log(x), family=betar(link=\"logit\"), data=dat)     y3 <- predictCIglm(mod3,dat=dat)     y3$model <- \"beta\"     preddata <- rbind(preddata,y3)     ec3 <- getEC50(mod3)     ec50 <- rbind(ec50,data.frame(ec3,model=c(\"beta\")))   }   #ec4 <- uniroot(function(x) predict(mod4, newdata = data.frame(x=x)) - 0.5,lower = 1, upper = 80)$root   ## 19.55968 beta regression does not perform better than binomial or quasi-binomial regression!      return(list(ec50=ec50,predata=preddata)) } modelallbeta <- function(dat){   modelall(dat,addbeta=TRUE) } dattab_new <- dattab_new %>% mutate(y=yy,x=dose)%>%as.data.frame(.) suppressWarnings({modres <- modelall(dattab_new)}) #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:50  12.7097     1.0856 10.5367 14.8826 predres <- modres[[2]] knitr::kable(rbind(modres[[1]]%>%mutate(TrueEC50 = 12.18),data.frame(EC50=12.15856,lower=10.16505,upper=15.09790,se=NA,model=\"ordinal regression\", TrueEC50 =12.18)),digits=3) p_drc_qb <- ggplot(dattab_new, aes(x=dose, y=yt)) +geom_point(alpha=0.1)+ geom_point(aes(x=dose, y=yy),col=\"green\")+                 #scale_color_viridis_d()+scale_fill_viridis_d()+         # scale_color_brewer(palette = \"Reds\") +          # #geom_smooth(method=\"loess\", se = FALSE, size=1.5) +         geom_ribbon(data=predres,aes(x=x,y=Prediction,ymin=Lower,ymax=Upper,col=model,fill=model),alpha=0.2)+geom_line(data=predres,aes(x=x,y=Prediction,col=model))+         xlab(\"Concentration\") +          ylab(\"% Injury / 100\") p_drc_qb"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"on-the-gof","dir":"Articles","previous_headings":"Regression Approaches with Continuous x > Putting quasi-binomial and normal fit together","what":"On the GoF","title":"Example Ordinal Data Analysis","text":"Normally test lack fit continuous data comparing model fit ANOVA model, achieve least square estimation. Changjian proposed use prediction intervals models estimate frequency table usually product conventional ordinal regression, followed chi-square test. common goodness fit tests measures logistic regression include deviance likelihood ratio test, Hosmer-Lemeshow Test, pseudo R-squared measures, residual analysis, classification/frequency tables.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"additional-thoughts","dir":"Articles","previous_headings":"Regression Approaches with Continuous x > Putting quasi-binomial and normal fit together","what":"Additional Thoughts","title":"Example Ordinal Data Analysis","text":"Thinking (quasi)-binomial type modelling data-generation process, possible assume see level B injury, many independent binary yes/outcomes (conditional observed covariate values replicate experiment unit) injury level arbitrary number categories, proportion yes answer average injury. probabilities binary outcome , may mismatch observed data rather badly. Beta regression can used model proportions , however, 0 1’s need specifically handled.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"using-conventional-ordinal-regression-approaches","dir":"Articles","previous_headings":"Regression Approaches with Continuous x","what":"Using Conventional Ordinal Regression Approaches","title":"Example Ordinal Data Analysis","text":"Ordinal regression approaches works well terms prediction need specific function calculate ER50. \\(\\sum p_i Y_{ij}\\) average injury level. achieved steps : fit ordinal regression model using polr ordinal response data. Define expected Response Function: key solving problem calculating expected response dose: calculate probability category given dose multiply probabilities corresponding injury percentages (0%, 10%, 30%, 50%, 70%, 90%, 100%) sum gives us expected injury percentage dose Finding EC50: search range doses find expected injury percentage closest 50%. Alternatively, define objective function use optimization find dose, precise grid search approach. resample data replacement 1000 times bootstrap sample, calculate EC50 2.5th 97.5th percentiles bootstrap EC50 values form 95% confidence interval approach provides robust estimate EC50 confidence intervals account uncertainty data model. bootstrap method particularly valuable doesn’t require assumptions distribution EC50 estimator. proportional odds model can interpreted terms probabilities transitions also terms covariate-specific cumulative probabilities. latter bit easier understand. Ordinal regression can conducted using MASS::polr function function provided GLMcat, R package encompasses lots models specified similar way: (ratio, cdf, design: parallel complete). find EC50 optimization Note implementing bootstrap approach, bootstrap samples causing separation problems ordinal regression model, common resampling smaller datasets. Therefore, robust solution given gracefully handle issue.","code":"## fit ordered logit model and store results 'm' dattab_new $y0 <- factor(dattab_new$y0, levels = c(\"0\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"),ordered = TRUE)  m <- MASS::polr(y0 ~ log(dose), data = dattab_new, Hess=TRUE) summary(m) #> Call: #> MASS::polr(formula = y0 ~ log(dose), data = dattab_new, Hess = TRUE) #>  #> Coefficients: #>           Value Std. Error t value #> log(dose) 3.465     0.4876   7.106 #>  #> Intercepts: #>     Value   Std. Error t value #> 0|A  4.0061  0.8091     4.9513 #> A|B  6.3415  1.0283     6.1669 #> B|C  8.1921  1.2395     6.6092 #> C|D  9.1287  1.3489     6.7677 #> D|E 10.9709  1.5691     6.9917 #> E|F 12.9482  1.8234     7.1011 #>  #> Residual Deviance: 128.7906  #> AIC: 142.7906 # Extract the coefficients and thresholds coefficients <- coef(m) thresholds <- m$zeta  # Define a function to calculate the expected response category at any given dose expected_response <- function(log_dose, coefficients, thresholds) {   # Calculate probabilities for each category   probabilities <- sapply(1:length(thresholds), function(i) {     plogis(thresholds[i] - coefficients * log_dose)   })      # Convert to category probabilities   probabilities <- c(probabilities, 1) - c(0, probabilities)      # Define the injury percentage for each category   categories <- c(0, 10, 30, 50, 70, 90, 100)      # Calculate expected value (weighted average)   expected_value <- sum(probabilities * categories)   return(expected_value) }  # Find the dose where the expected response is closest to 50% log_doses <- seq(log(0.1), log(100), length.out = 1000) responses <- sapply(log_doses, expected_response,                     coefficients = coefficients[\"log(dose)\"],                     thresholds = thresholds) closest_index <- which.min(abs(responses - 50)) dose_ec50 <- exp(log_doses[closest_index])  # Print the EC50 value print(dose_ec50) #> [1] 12.13624 # Define the objective function to minimize (distance from 50%) objective_function <- function(log_dose) {   abs(expected_response(log_dose, coefficients[\"log(dose)\"], thresholds) - 50) }  # Use optimization to find the EC50 result <- optimize(objective_function, interval = c(log(0.1), log(100))) dose_ec50 <- exp(result$minimum)  # Print the EC50 value and the corresponding expected response print(paste(\"EC50:\", round(dose_ec50, 4))) #> [1] \"EC50: 12.1586\" print(paste(\"Expected response at EC50:\",              round(expected_response(result$minimum, coefficients[\"log(dose)\"], thresholds), 4))) #> [1] \"Expected response at EC50: 49.9986\" # Define the function to calculate EC50 for a bootstrap sample with error handling calculate_ec50 <- function(data) {   # Try to fit the model, return NA if it fails   m_boot <- try(polr(y0 ~ log(dose), data = data, Hess = TRUE), silent = TRUE)   if (inherits(m_boot, \"try-error\")) return(NA)      coefficients <- coef(m_boot)   thresholds <- m_boot$zeta      # Define objective function to minimize   objective_function <- function(log_dose) {     abs(expected_response(log_dose, coefficients[\"log(dose)\"], thresholds) - 50)   }      # Try to optimize, return NA if it fails   result <- try(optimize(objective_function, interval = c(log(0.1), log(100))), silent = TRUE)   if (inherits(result, \"try-error\")) return(NA)      dose_ec50 <- exp(result$minimum)   return(dose_ec50) }  # Bootstrap resampling with error handling set.seed(123) n_bootstrap <- 1000 bootstrap_ec50 <- replicate(n_bootstrap, {   # Sample with replacement   sample_indices <- sample(1:nrow(dattab_new), replace = TRUE)   bootstrap_sample <- dattab_new[sample_indices, ]      # Calculate EC50 for this sample   calculate_ec50(bootstrap_sample) })  # Remove NA values from bootstrap results bootstrap_ec50 <- na.omit(bootstrap_ec50) valid_samples <- length(bootstrap_ec50)  # Calculate point estimate using original data rather than as the mean of bootstrap estimates, which is more statistically sound. ec50_point <- calculate_ec50(dattab_new) # Calculate confidence intervals ec50_ci <- quantile(bootstrap_ec50, c(0.025, 0.975))  # Print the results print(paste(\"EC50:\", round(ec50_point, 4))) #> [1] \"EC50: 12.1586\" print(paste(\"95% Confidence Interval:\", round(ec50_ci[1], 4), \"-\", round(ec50_ci[2], 4))) #> [1] \"95% Confidence Interval: 10.1651 - 15.0979\" ## Reporting Valid Samples: how many bootstrap samples were valid, which helps assess the reliability of the confidence interval. print(paste(\"Based on\", valid_samples, \"valid bootstrap samples out of\", n_bootstrap)) #> [1] \"Based on 957 valid bootstrap samples out of 1000\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"additional-understanding-of-the-ordinal-regression-model","dir":"Articles","previous_headings":"Regression Approaches with Continuous x","what":"Additional understanding of the ordinal regression model","title":"Example Ordinal Data Analysis","text":"","code":"ctable <- coef(summary(m))  ## At ER50, the cumulative probability probability of the response being in a higher category is close to 1. plogis(ctable[,1] + ctable[,2]*log(12.18)) #> log(dose)       0|A       A|B       B|C       C|D       D|E       E|F  #> 0.9908438 0.9975973 0.9998653 0.9999875 0.9999963 0.9999997 1.0000000 ## calculate and store p values p <- pnorm(abs(ctable[, \"t value\"]), lower.tail = FALSE) * 2  ## combined table (ctable <- cbind(ctable, \"p value\" = p)) #>               Value Std. Error  t value      p value #> log(dose)  3.465155  0.4876298 7.106117 1.193530e-12 #> 0|A        4.006148  0.8091031 4.951344 7.370254e-07 #> A|B        6.341529  1.0283150 6.166913 6.963590e-10 #> B|C        8.192141  1.2395138 6.609156 3.865169e-11 #> C|D        9.128696  1.3488680 6.767672 1.308710e-11 #> D|E       10.970866  1.5691374 6.991654 2.716642e-12 #> E|F       12.948174  1.8234117 7.101070 1.237950e-12  (ci <- confint(m)) ## profiled CI #>    2.5 %   97.5 %  #> 2.582836 4.504378  exp(cbind(coef(m),t(ci))) #>                       2.5 %   97.5 % #> log(dose) 31.98141 13.23462 90.41212 ## OR and CI exp(cbind(OR = coef(m), ci)) #>              OR       ci #> 2.5 %  31.98141 13.23462 #> 97.5 % 31.98141 90.41212  newdat <- data.frame(dose = unique(dattab_new$dose)) %>% mutate(logdose = log(dose)) (phat <- predict(object = m, newdat, type=\"p\")) #>              0            A           B           C          D            E #> 1 8.326166e-01 0.1483000019 0.016035611 0.001850927 0.00100702 0.0001635762 #> 2 3.105443e-01 0.5126011687 0.144195119 0.019598385 0.01096824 0.0018025754 #> 3 3.918687e-02 0.2573055374 0.431914336 0.144078094 0.10487831 0.0194406374 #> 4 3.342916e-04 0.0031093320 0.018073161 0.031603441 0.20832988 0.4574198047 #> 5 3.679470e-03 0.0330795765 0.158639125 0.187148646 0.41376767 0.1694853156 #> 6 3.027903e-05 0.0002825179 0.001674417 0.003066947 0.02600507 0.1569497884 #>              F #> 1 2.628958e-05 #> 2 2.902582e-04 #> 3 3.196213e-03 #> 4 2.811301e-01 #> 5 3.420020e-02 #> 6 8.119910e-01  phat %>% knitr::kable(.,digits = 3) library(GLMcat)  dattab_new <- dattab_new %>% mutate(logdose = log(dose)) mod_ref_log_c <- glmcat(formula = y0 ~ logdose, ratio = \"reference\", cdf = \"logistic\", data = as.data.frame(dattab_new),ref=\"0\",parallel = F) summary(mod_ref_log_c) #> y0 ~ logdose #>                 ratio      cdf nobs niter    logLik #> Model info: reference logistic   60    15 -61.33542 #>                 Estimate Std. Error z value Pr(>|z|)     #> (Intercept) A     -2.907      1.309  -2.221 0.026323 *   #> (Intercept) B     -5.398      1.835  -2.942 0.003260 **  #> (Intercept) C     -9.347      3.019  -3.096 0.001958 **  #> (Intercept) D    -10.923      3.065  -3.564 0.000366 *** #> (Intercept) E    -17.421      4.838  -3.600 0.000318 *** #> (Intercept) F   -118.572 109742.356  -0.001 0.999138     #> logdose A          2.179      0.993   2.194 0.028225 *   #> logdose B          3.415      1.177   2.901 0.003725 **  #> logdose C          4.803      1.504   3.194 0.001404 **  #> logdose D          5.633      1.499   3.758 0.000172 *** #> logdose E          7.692      1.895   4.058 4.94e-05 *** #> logdose F         36.404  31664.951   0.001 0.999083     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 (phat <- predict(object = mod_ref_log_c, newdat, type=\"prob\")) #>                 A            B            C            D            E #> [1,] 1.904456e-01 3.716346e-02 1.873707e-03 6.891895e-04 4.324730e-06 #> [2,] 4.075170e-01 1.873256e-01 2.472185e-02 1.616443e-02 4.225492e-04 #> [3,] 3.188563e-01 3.452649e-01 1.192710e-01 1.386298e-01 1.509628e-02 #> [4,] 5.226961e-03 3.140645e-02 7.433584e-02 2.730262e-01 5.159543e-01 #> [5,] 7.795418e-02 1.988396e-01 1.797976e-01 3.714905e-01 1.685225e-01 #> [6,] 2.602312e-12 3.683282e-11 2.281986e-10 1.489914e-09 1.172910e-08 #>                 F            0 #> [1,] 2.238527e-41 7.698238e-01 #> [2,] 9.621150e-31 3.638486e-01 #> [3,] 1.512050e-20 6.288173e-02 #> [4,] 1.000000e-01 5.029071e-05 #> [5,] 7.425066e-11 3.395654e-03 #> [6,] 1.000000e+00 5.662137e-15 phat %>% knitr::kable(.,digits = 3) ## (phat <- predict(object = mod_ref_log_c, newdat, type=\"linear.predictor\"))  mod_cum_logis <- glmcat(formula = y0 ~ logdose, ratio = \"cumulative\", cdf = \"logistic\", data = as.data.frame(dattab_new),parallel = TRUE) summary(mod_cum_logis) #> y0 ~ logdose #>                  ratio      cdf nobs niter   logLik #> Model info: cumulative logistic   60     9 -64.3953 #>               Estimate Std. Error z value Pr(>|z|)     #> (Intercept) 0   4.0061     0.8142   4.920 8.64e-07 *** #> (Intercept) A   6.3415     1.0419   6.086 1.16e-09 *** #> (Intercept) B   8.1920     1.2583   6.510 7.50e-11 *** #> (Intercept) C   9.1286     1.3693   6.666 2.62e-11 *** #> (Intercept) D  10.9707     1.6005   6.854 7.16e-12 *** #> (Intercept) E  12.9479     1.8194   7.117 1.11e-12 *** #> logdose        -3.4651     0.4912  -7.054 1.74e-12 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  (phat <- predict(object = mod_cum_logis, newdat, type=\"prob\")) #>                 0            A           B           C           D           E #> [1,] 8.326186e-01 0.1482975531 0.016035767 0.001851046 0.001007102 0.000163596 #> [2,] 3.105557e-01 0.5125923926 0.144191357 0.019598856 0.010968693 0.001802725 #> [3,] 3.919032e-02 0.2573138937 0.431903119 0.144076171 0.104878455 0.019441472 #> [4,] 3.343480e-04 0.0031097342 0.018074387 0.031605029 0.208331116 0.457408504 #> [5,] 3.679947e-03 0.0330824671 0.158642283 0.187148395 0.413758936 0.169485389 #> [6,] 3.028531e-05 0.0002825654 0.001674598 0.003067232 0.026006412 0.156948672 #>                 F #> [1,] 2.629451e-05 #> [2,] 2.903015e-04 #> [3,] 3.196565e-03 #> [4,] 2.811369e-01 #> [5,] 3.420258e-02 #> [6,] 8.119902e-01 phat %>% knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"other-understanding-of-the-dataset","dir":"Articles","previous_headings":"Regression Approaches with Continuous x","what":"Other understanding of the dataset","title":"Example Ordinal Data Analysis","text":"principle, ordinal regression treating ranked categorical several binomial category. Note intercept 0|-1.386294e+00.","code":"fit0 <- MASS::polr(y0 ~  1,                       data = dattab_new,                       Hess= T) fit0 #> Call: #> MASS::polr(formula = y0 ~ 1, data = dattab_new, Hess = T) #>  #> No coefficients #>  #> Intercepts: #>           0|A           A|B           B|C           C|D           D|E  #> -1.386294e+00 -5.465462e-01 -1.793225e-06  2.682586e-01  8.472940e-01  #>           E|F  #>  1.493920e+00  #>  #> Residual Deviance: 228.003  #> AIC: 240.003 ## Note that   #source(\"https://github.com/rwnahhas/RMPH_Resources/raw/main/Functions_rmph.R\") ilogit <- function(x) exp(x)/(1+exp(x)) ilogit(fit0$zeta) #>       0|A       A|B       B|C       C|D       D|E       E|F  #> 0.2000001 0.3666661 0.4999996 0.5666653 0.6999992 0.8166659   sf <- function(y) {   c('Y>=1' = qlogis(mean(y >= 1)),     'Y>=2' = qlogis(mean(y >= 2)),     'Y>=3' = qlogis(mean(y >= 3)),     'Y>=4' = qlogis(mean(y >= 4)),     'Y>=5' = qlogis(mean(y >= 5)),     'Y>=6' = qlogis(mean(y >= 6))     ) } library(Hmisc) (s <- with(dattab_new,summary(as.numeric(y0) ~ (dose), fun=sf))) #> as.numeric(y0)      N= 60   #>  #> +-------+--+--+----+----------+----------+----------+----------+----------+ #> |       |  | N|Y>=1|      Y>=2|      Y>=3|      Y>=4|      Y>=5|      Y>=6| #> +-------+--+--+----+----------+----------+----------+----------+----------+ #> |   dose| 2|10| Inf|-1.3862944|      -Inf|      -Inf|      -Inf|      -Inf| #> |       | 4|10| Inf| 0.8472979|-1.3862944|      -Inf|      -Inf|      -Inf| #> |       | 8|10| Inf| 2.1972246| 0.8472979|-0.8472979|-2.1972246|      -Inf| #> |       |16|10| Inf|       Inf|       Inf| 1.3862944| 0.8472979|-1.3862944| #> |       |32|10| Inf|       Inf| 2.1972246| 2.1972246| 1.3862944| 0.4054651| #> |       |64|10| Inf|       Inf|       Inf|       Inf|       Inf|       Inf| #> +-------+--+--+----+----------+----------+----------+----------+----------+ #> |Overall|  |60| Inf| 1.3862944| 0.5465437| 0.0000000|-0.2682640|-0.8472979| #> +-------+--+--+----+----------+----------+----------+----------+----------+   mod2 <- glm(I(as.numeric(y0) >= 2) ~ factor(dose), family=\"binomial\", data = dattab_new) predict.glm(mod2,data.frame(dose=2)) #>         1  #> -1.386294 predict.glm(mod2,data.frame(dose=4)) #>         1  #> 0.8472979 mod3 <- glm(I(as.numeric(y0) >= 3) ~ factor(dose), family=\"binomial\", data = dattab_new) predict.glm(mod3,data.frame(dose=2)) #>         1  #> -20.56607 glm(I(as.numeric(y0) >= 4) ~ factor(dose), family=\"binomial\", data = dattab_new) #>  #> Call:  glm(formula = I(as.numeric(y0) >= 4) ~ factor(dose), family = \"binomial\",  #>     data = dattab_new) #>  #> Coefficients: #>    (Intercept)   factor(dose)4   factor(dose)8  factor(dose)16  factor(dose)32   #>     -2.057e+01       9.728e-12       1.972e+01       2.195e+01       2.276e+01   #> factor(dose)64   #>      4.113e+01   #>  #> Degrees of Freedom: 59 Total (i.e. Null);  54 Residual #> Null Deviance:       83.18  #> Residual Deviance: 28.73     AIC: 40.73"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"log-logistic-with-quasi-binomial-replicate-effects","dir":"Articles","previous_headings":"Regression Approaches with Continuous x","what":"log-logistic with quasi-binomial: replicate effects","title":"Example Ordinal Data Analysis","text":"Original study design CRD. However, argued treat RCBD blocking effect coming replicate numbering. can compare result differences. Note glmer glmmPQL (based lme nlme pacakge) differs terms parameter estimation algorithm nlme optimized dealing crossed random effects, associated sparse design matrix. See book Pinheiro & Bates.[^1]","code":"mod <- glm(yy2~log(dose),data = dattab_new,family = quasibinomial) summary(mod) #>  #> Call: #> glm(formula = yy2 ~ log(dose), family = quasibinomial, data = dattab_new) #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  -3.5064     0.3132  -11.19 4.02e-16 *** #> log(dose)     1.3832     0.1171   11.81  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for quasibinomial family taken to be 0.1163524) #>  #>     Null deviance: 31.8277  on 59  degrees of freedom #> Residual deviance:  6.3595  on 58  degrees of freedom #> AIC: NA #>  #> Number of Fisher Scoring iterations: 5 ER50 <- exp(-coef(mod)[1]/coef(mod)[2]) ER50 #> (Intercept)  #>      12.617 getEC50(mod) #>     EC50    lower    upper       se #> 1 12.617 10.77038 14.78023 1.023657 pred <- predict(mod,newdata = dattab_new,type = \"response\") dattab_new$pred <- pred dattab_new %>% group_by(y0) %>% summarise(n=n(),meany=mean(yt),meanyy2=mean(yy2),meanEst=mean(pred)) %>% knitr::kable(.,digits = 3) ## Consider Replicate effect modr <- MASS::glmmPQL(yy2~ log(dose),random=~1|rep,family=\"quasibinomial\",data=dattab_new) ER50 <- exp(-coef(modr)[1]/coef(modr)[2]) exp(-modr$coefficients$fixed[1]/ modr$coefficients$fixed[2]) #> (Intercept)  #>    12.61695 summary(modr) #> Linear mixed-effects model fit by maximum likelihood #>   Data: dattab_new  #>   AIC BIC logLik #>    NA  NA     NA #>  #> Random effects: #>  Formula: ~1 | rep #>         (Intercept)  Residual #> StdDev:   0.2256918 0.3155037 #>  #> Variance function: #>  Structure: fixed weights #>  Formula: ~invwt  #> Fixed effects:  yy2 ~ log(dose)  #>                 Value Std.Error DF   t-value p-value #> (Intercept) -3.517527 0.3039553 49 -11.57251       0 #> log(dose)    1.387562 0.1103306 49  12.57640       0 #>  Correlation:  #>           (Intr) #> log(dose) -0.907 #>  #> Standardized Within-Group Residuals: #>        Min         Q1        Med         Q3        Max  #> -3.9592347 -0.3047297  0.1382668  0.4944066  1.9353183  #>  #> Number of Observations: 60 #> Number of Groups: 10 getEC50(modr) #>              EC50    lower    upper       se #> p = 0.5: 12.61695 10.56476 15.06777 1.149772 pred <- predict(modr,newdata = dattab_new,type = \"response\") dattab_new$predr <- pred dattab_new %>% group_by(y0) %>% summarise(n=n(),meany=mean(yt),meanyy2=mean(yy2),meanEst=mean(pred),meanEstR=mean(predr)) %>% knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"drm-ordinal","dir":"Articles","previous_headings":"Regression Approaches with Continuous x","what":"DRM Ordinal","title":"Example Ordinal Data Analysis","text":"","code":"library(drc) library(bmd) dat_ord <- dattab_new %>% group_by(y0,dose) %>% summarise(n=n()) %>% ungroup() %>% pivot_wider(names_from = y0,values_from = n) dat_ord <- dat_ord %>% mutate(across(c(`0`,`A`,`B`,`C`,`D`,`E`,`F`),~ifelse(is.na(.),0,.))) %>% mutate(total=rowSums(across(c(`0`,`A`,`B`,`C`,`D`,`E`,`F`)))) mod_ord <- drmOrdinal(levels = unique(dattab_new$y0),  weights=\"total\",dose = \"dose\", data = dat_ord, fct = LL.2()) plot(mod_ord) # uses ggplot bmdOrdinal(mod_ord, bmr = 0.5, backgType = \"modelBased\", def = \"excess\") #>           BMD     BMDL #> [1,] 16.32314 14.93955"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"rscabs-mqjt-and-other-testing-approaches","dir":"Articles","previous_headings":"","what":"RSCABS, MQJT and other testing approaches","title":"Example Ordinal Data Analysis","text":"Details RSCABS approach can find . Current implementation used Rao-Scott correction always, exact CA test possible, potential inflated type-error slices low occurences. High resolution scoring system (many categories) less powerful due violation monotonicity. MQJT another alternative procedure simplest solution using standard JT test Q50 alone. Jonckheere-test slices proportions (JTBS) can also applied similarly RSCABS. Non-parametric Dunnett Williams type procedure (F. Konietschke L. . Hothorn Stat. Biopharm. Res., 2012, 4, 14–27) used follwed regression modelling independent variable treated factors. testing approaches targeting NOEC certain injury level. default, testing approaches actually treat test rates concentrations study categorical variable, losing continuous property therefore ER50 directly calculated. However, NOEC medium injury level comparable ER50, always smaller ER50.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"simulation-study","dir":"Articles","previous_headings":"","what":"Simulation Study","title":"Example Ordinal Data Analysis","text":"Simulation studies show glm quasibinomial nonlinear log-logistic normal perfom similarly limited dose groups. observe full dose-response curve, quasibinomial less flexible adapting data.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"data-generated-using-the-logistic-cdf-","dir":"Articles","previous_headings":"Simulation Study","what":"Data generated using the logistic CDF.","title":"Example Ordinal Data Analysis","text":"data generated using cumulative function logistic distribution. Note logistic function just inverse logit (\\(\\log(p/(1-p))\\)) function R. code modified based blog post. \\[F(x;\\mu,s) = \\frac{1}{2} + \\frac{1}{2} \\tanh((x-\\mu)/2s) = \\frac{1}{1+e^{-(x-\\mu)/s}}\\] , \\(\\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)} = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\\), hyperbolic tangent function maps real numbers range -1 1. Quantile CDF \\(\\mu+s\\log(\\frac{p}{1-p})\\), therefore, EC50 \\(\\mu\\) \\(\\exp(\\mu)\\). Random noises added afterwards logistic distribution CDF. simulate \\(n\\) studies concentration \\(x\\), denoted, \\(X_{1}, X_{2}, …, X_{n}\\) \\(k\\) study \\(X=(x_{1}, x_{2}, …, x_{k})\\), \\(k\\) number different studies different \\(\\mu\\) \\(\\sigma\\). Let’s say \\(k=6\\) study groups following parameter sets, \\(\\mu = \\{9,2,3,5,7,5\\}\\) \\(s=\\{2,2,4,3,4,2\\}\\)   Nonlinear log-logistic modelling normal errors seem flexible dealing different curve shapes. also fits data generation process case.","code":"generate_logit_cdf <- function(mu, s,                                 sigma_y=0.1,                                 x=seq(-5,20,0.1)) {   x_ms <- (x-mu)/s   y    <- 0.5 + 0.5 * tanh(x_ms)     y    <- abs(y + rnorm(length(x), 0, sigma_y))   ix   <- which(y>=1.0)   if(length(ix)>=1) {      y[ix] <- 1.0   }   return(y) } tanh(0) #> [1] 0 set.seed(424242) x      <- seq(-5,15,0.025)  mu_vec <- c(1,2,3,5,7,8)   # 6 Studies idx <- sapply(mu_vec,function(mu) which(x==mu))  ## we just need to know which index to find the ER50 s_vec  <- c(2,2,4,3,4,2) # Synthetic Study ID studies_df<- mapply(generate_logit_cdf,                                mu_vec,                                s_vec,                                MoreArgs = list(x=x)) # Give them names colnames(studies_df) <- c(\"Study1\", \"Study2\", \"Study3\", \"Study4\", \"Study5\", \"Study6\")    dim(studies_df) #> [1] 801   6 library(ggplot2) theme_set(theme_bw()) library(tidyverse) df_all <- tidyr::pivot_longer(data.frame(x=(1:length(x))/10,studies_df),cols=2:7) true_ec50 <- ((1:length(x))/10)[idx] colnames(df_all) <- c(\"x\", \"study\", \"y\") df_all$study <- as.factor(df_all$study)  p_quasibinomial<- ggplot(df_all, aes(x=x, y=y, color=study)) +         geom_point(alpha=0.2)  +         scale_color_viridis_d()+         # scale_color_brewer(palette = \"Reds\") +          # #geom_smooth(method=\"loess\", se = FALSE, size=1.5) +         geom_smooth(aes(group=study),method=\"glm\", method.args=list(family=\"quasibinomial\"), formula=\"y ~ log(x)\",                        se =TRUE, size=1.5) +         xlab(\"Concentration\") +          ylab(\"% Injury / 100\") + ggtitle(\"Quasibinomial Fit\")  p_quasibinomial#+scale_x_log10() p_quasibinomial +facet_wrap(~study) library(drc) p_drc<- ggplot(df_all, aes(x=x, y=y, color=study)) +         geom_point(alpha=0.2)  +         scale_color_viridis_d()+         # scale_color_brewer(palette = \"Reds\") +          # #geom_smooth(method=\"loess\", se = FALSE, size=1.5) +         geom_smooth(aes(group=study),method=\"drm\", method.args=list(fct=LL.2()), formula=\"y ~ x\",                        se = FALSE, size=1.5) +         xlab(\"Concentration\") +          ylab(\"% Injury / 100\") + ggtitle(\"DRC nonlinear normal fit\") p_drc#+scale_x_log10() p_drc + facet_wrap(~study) df_nested <- df_all %>% group_by(study) %>% nest() dfres <- df_nested %>% mutate(modres=map(data,modelall)) #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 23.72221    0.13908 23.44921 23.99521 #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 27.53930    0.14351 27.25759 27.82100 #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 30.85168    0.20483 30.44961 31.25375 #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 39.35892    0.18648 38.99287 39.72498 #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 47.09152    0.20831 46.68262 47.50042 #>  #> Estimated effective doses #>  #>        Estimate Std. Error    Lower    Upper #> e:1:50 51.84412    0.14198 51.56541 52.12283 ec50 <- dfres %>% mutate(ec50=modres[[1]][1]) %>% dplyr::select(-c(data,modres)) %>% unnest(cols=c(ec50)) %>% ungroup() %>% mutate(TrueEC50 = rep(true_ec50,each=2)) knitr::kable(ec50) predres <- dfres %>% mutate(preds=modres[[1]][2]) %>% dplyr::select(-c(data,modres)) %>% unnest(cols=c(preds)) %>% ungroup() p_drc_qb <- ggplot(df_all, aes(x=x, y=y)) +         geom_point(alpha=0.1)  +         scale_color_viridis_d()+         # scale_color_brewer(palette = \"Reds\") +          # #geom_smooth(method=\"loess\", se = FALSE, size=1.5) +         geom_smooth(aes(group=study),method=\"drm\", method.args=list(fct=LL.2()), formula=\"y~x\",                        se = FALSE, size=1.5,col=scales::hue_pal()(2)[1]) +                        geom_smooth(aes(group=study),method=\"glm\", method.args=list(family=\"quasibinomial\"), formula=\"y~log(x)\",                        se = FALSE, size=1.5,lty=3,col=scales::hue_pal()(2)[2])+         xlab(\"Concentration\") +          ylab(\"% Injury / 100\")  + facet_wrap(~study)  p_drc_qb + geom_hline(yintercept=0.5,col=\"purple\") + geom_vline(data=ec50,aes(xintercept=TrueEC50),col=\"purple\")+ geom_ribbon(data=predres,aes(x=x,ymin=Lower,ymax=Upper,y=Prediction,fill=model),alpha=0.3) + ggtitle(\"drc and quasibinomial fit with CI\") + geom_vline(data=ec50,aes(xintercept=EC50,col=model))"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Ordinal-Data.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Example Ordinal Data Analysis","text":"Agresti, . (2002) Categorical Data Analysis, Second Edition. Hoboken, New Jersey: John Wiley & Sons, Inc. Harrell, F. E, (2001) Regression Modeling Strategies. New York: Springer-Verlag. http://www.sthda.com/english/articles/32-r-graphics-essentials/132-plot-grouped-data-box-plot-bar-plot--/ Chuang-Stein G, Agresti . review tests detecting monotone dose-response relationship ordinal response data. Stat Med. 1997 Nov 30;16(22):2599-618. doi: 10.1002/(sici)1097-0258(19971130)16:22<2599::aid-sim734>3.0.co;2-9. PMID: 9403959.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"an-example-dataset","dir":"Articles","previous_headings":"","what":"An example dataset","title":"Quantal Data","text":"","code":"library(rstatix) library(dplyr) library(tidyr)  set.seed(123) test_data <- data.frame(   treatment = c(rep(\"control\", 3), rep(\"low\", 3), rep(\"high\", 3)),   survived = c(9, 8, 10, 7, 6, 5, 3, 4, 2),   died = c(1, 2, 0, 3, 4, 5, 7, 6, 8) )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"fishers-exact-test-comparing-each-dose-to-control","dir":"Articles","previous_headings":"","what":"Fisher’s Exact Test (comparing each dose to control)","title":"Quantal Data","text":"Note just two groups also work. Note two groups, functions can used p_adjusted always equal original p-value.","code":"# Run the function result <- compare_to_control_fisher(test_data, \"treatment\", \"survived\", \"died\",                                     control_level = \"control\",p.adjust.method=\"holm\") result #>   treatment p_value odds_ratio ci_lower ci_upper p_adjusted #> 1       low  0.0153     5.8215   1.3182  36.6614     0.0153 #> 2      high  0.0000    19.6536   4.4429 126.9504     0.0000 ctab <- create_contingency_table(test_data,\"treatment\", \"survived\", \"died\") drcHelper::many_to_one_fisher_test(ctab,ref.group = \"treatment_control\",p.adjust.method = \"holm\") #> # A tibble: 2 × 6 #>   group1            group2             n          p      p.adj p.adj.signif #> * <chr>             <chr>          <dbl>      <dbl>      <dbl> <chr>        #> 1 treatment_control treatment_high    60 0.00000337 0.00000674 ****         #> 2 treatment_control treatment_low     60 0.0153     0.0153     * result <- compare_to_control_fisher(test_data%>%filter(treatment!=\"high\")%>%droplevels(.), \"treatment\", \"survived\", \"died\",control_level = \"control\") result #>   treatment p_value odds_ratio ci_lower ci_upper p_adjusted #> 1       low  0.0153     5.8215   1.3182  36.6614     0.0153 ctab <- create_contingency_table(test_data %>% filter(treatment!=\"high\") %>% droplevels(.),\"treatment\", \"survived\", \"died\") drcHelper::many_to_one_fisher_test(ctab,ref.group = \"treatment_control\",p.adjust.method = \"holm\") #> # A tibble: 1 × 6 #>   group1            group2            n      p  p.adj p.adj.signif #> * <chr>             <chr>         <dbl>  <dbl>  <dbl> <chr>        #> 1 treatment_control treatment_low    60 0.0153 0.0153 * fisher.test(ctab) #>  #>  Fisher's Exact Test for Count Data #>  #> data:  ctab #> p-value = 0.01533 #> alternative hypothesis: true odds ratio is not equal to 1 #> 95 percent confidence interval: #>   1.318207 36.661382 #> sample estimates: #> odds ratio  #>    5.82151 # CMH test cmh_result <- data_long %>%   group_by(dose, condition) %>%   summarise(n = sum(count)) %>%   stats::mantelhaen.test()  # Print results print(\"Fisher's Exact Test results (comparing each dose to control):\") print(fisher_results)  print(\"\\nCochran-Mantel-Haenszel Test result:\") print(cmh_result)  # Calculate NOEC noec <- max(fisher_results$dose[fisher_results$p_value > 0.05])"},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"cochran-mantel-haenszel-chi-squared-test-for-count-data","dir":"Articles","previous_headings":"Other types of tests not used in regulatory statistical analysis in ecotoxicology","what":"Cochran-Mantel-Haenszel Chi-Squared Test for Count Data","title":"Quantal Data","text":"extension Cochran-Mantel test used stratified matched categorical data.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"mcnemars-chi-squared-test-for-count-data","dir":"Articles","previous_headings":"Other types of tests not used in regulatory statistical analysis in ecotoxicology","what":"McNemar’s Chi-squared Test for Count Data","title":"Quantal Data","text":"McNemar’s test appropriate NOEC derivation ’s designed paired observations (/measurements).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"tarones-test","dir":"Articles","previous_headings":"","what":"Tarone’s Test","title":"Quantal Data","text":"","code":"mymatrix1 <- matrix(c(4,5,5,103),nrow=2,byrow=TRUE) colnames(mymatrix1) <- c(\"Disease\",\"Control\") rownames(mymatrix1) <- c(\"Exposure\",\"Unexposed\") mymatrix2 <- matrix(c(10,3,5,43),nrow=2,byrow=TRUE) colnames(mymatrix2) <- c(\"Disease\",\"Control\") rownames(mymatrix2) <- c(\"Exposure\",\"Unexposed\") mylist <- list(mymatrix1,mymatrix2) calcTaronesTest(mylist) #> [1] \"Pvalue for Tarone's test = 0.627420741721689\" #> $pval #> [1] 0.6274207 #>  #> $tarone #>  #> Equal-Effects Model (k = 2) #>  #> I^2 (total heterogeneity / total variability):  0.00% #> H^2 (total variability / sampling variability): 0.24 #>  #> Test for Heterogeneity:  #> Q(df = 1) = 0.2423, p-val = 0.6225 #>  #> Model Results (log scale): #>  #> estimate      se    zval    pval   ci.lb   ci.ub  #>   3.1355  0.5741  5.4613  <.0001  2.0102  4.2608  #>  #> Model Results (OR scale): #>  #> estimate   ci.lb    ci.ub  #>  23.0006  7.4652  70.8663  #>  #> Cochran-Mantel-Haenszel Test:    CMH = 36.6043, df = 1, p-val < 0.0001 #> Tarone's Test for Heterogeneity: X^2 =  0.2356, df = 1, p-val = 0.6274"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"trend-test","dir":"Articles","previous_headings":"","what":"Trend Test","title":"Quantal Data","text":"Cochran Armitage test trend binomial proportions across treament levels can performed prop.trend.test CochranArmitageTest DescTools use wrapper function prop_trend_test provided rstatix package. Step-procedures can performed using helper function package step_down_CA step_down_RSCA. Rao-Scott correction needed binomial data exhibits overdispersion, occurs observed variance data exceeds expected simple binomial model. common : Clustered data: observations within group (like organisms tank) similar organisms different groups Hierarchical experimental designs: multiple levels sampling (e.g., tanks within treatments, organisms within tanks) Longitudinal studies: subjects measured repeatedly time Ecological studies: environmental factors create additional variability beyond simple binomial model predicts Without Rao-Scott correction, possible underestimate standard errors, obtain artificially small p-values (Type errors). Dispersion can tested many approaches. : 1. Calculate dispersion parameter (\\(\\phi\\)) ratio Pearson chi-square statistic degrees freedom. 2. Compare binomial model quasi-binomial beta-binomial model. 3. Dean’s test overdispersion DHARMa package provides simulation-based overdispersion test. Note Rao-Scott correction used deal -dispersion clustered data. prop.trend.test uses \\(\\chi^2\\) statistic square \\(Z\\) statistic used drcHelper::cochranArmitageTrendTest DescTools::CochranArmitageTest. Also prop.trend.test gave two sided test p-values, whereas DescTools::CochranArmitageTest gives one-sided two-sided p-values allow specification direction. Note bit different independence_test package coin.","code":"library(DescTools) test_data <- matrix(c(10,9,10,7, 0,1,0,3), byrow=TRUE, nrow=2, dimnames=list(resp=0:1, dose=0:3)) ## DescTools::Desc(dose)  DescTools::CochranArmitageTest(test_data) #>  #>  Cochran-Armitage test for trend #>  #> data:  test_data #> Z = -1.8856, dim = 4, p-value = 0.05935 #> alternative hypothesis: two.sided stats::prop.trend.test(c(10,9,10,7),rep(10,4),0:3) #>  #>  Chi-squared Test for Trend in Proportions #>  #> data:  c(10, 9, 10, 7) out of rep(10, 4) , #>  using scores: 0 1 2 3 #> X-squared = 3.5556, df = 1, p-value = 0.05935 drcHelper::cochranArmitageTrendTest(c(10,9,10,7),rep(10,4),0:3) #>  #>  Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 1, 0.9, 1, 0.7 at doses 0, 1, 2, 3 #> = -1.8856, p-value = 0.05935 #> alternative hypothesis: two.sided DescTools::CochranArmitageTest(test_data,alternative = \"one.sided\") #>  #>  Cochran-Armitage test for trend #>  #> data:  test_data #> Z = -1.8856, dim = 4, p-value = 0.02967 #> alternative hypothesis: one.sided cochranArmitageTrendTest(c(10,9,10,7),rep(10,4),0:3,alternative = \"less\") #>  #>  Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 1, 0.9, 1, 0.7 at doses 0, 1, 2, 3 #> = -1.8856, p-value = 0.02967 #> alternative hypothesis: less cochranArmitageTrendTest(c(10,9,10,7),rep(10,4),0:3,alternative = \"greater\") #>  #>  Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 1, 0.9, 1, 0.7 at doses 0, 1, 2, 3 #> = -1.8856, p-value = 0.9703 #> alternative hypothesis: greater"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"an-example-with-clustered-data","dir":"Articles","previous_headings":"Trend Test","what":"An example with clustered data","title":"Quantal Data","text":"Visualize tank effects  plot upper left shows survival proportions tank (colored points) dose level. black diamonds represent mean survival proportion dose level, dashed line shows theoretical dose-response relationship without tank effects. variation among tanks dose level illustrates tank effect. plot upper right shows dispersion factor (\\(\\phi\\)) dose level, calculated ratio observed variance expected binomial variance. Values greater 1 indicate overdispersion. red dashed line \\(\\phi\\) = 1 represents expected pure binomial model tank effects. plot bottom left compares expected variance binomial model (green bars) observed variance (orange bars) dose level. difference values demonstrates additional variance introduced tank effects. plot bottom right shows actual random effects assigned tank simulation. Positive values increase survival probability, negative values decrease . visualization helps understand tank-specific conditions can influence results. plot, can see even dose level, ’s considerable variation survival proportions tanks, wouldn’t expected simple binomial model. dispersion factors (\\(\\phi\\)) consistently greater 1, indicating overdispersion accounted analysis. observed variance higher expected binomial model, particularly intermediate dose levels binomial variance naturally highest. standard Cochran-Armitage test produces smaller p-value Rao-Scott corrected version, potentially leading different conclusions significance dose-response relationship. example demonstrates Rao-Scott correction important analyzing clustered binomial data. Without accounting overdispersion caused tank effects, standard analysis underestimate uncertainty results potentially lead overly confident (incorrect) conclusions dose-response relationship.","code":"# Simulate a toxicity experiment with tank effects set.seed(123)  # Experimental design doses <- c(0, 1, 2, 5, 10)  # Dose levels tanks_per_dose <- 3         # Replicate tanks per dose organisms_per_tank <- 10    # Organisms per tank  # Create data frame experiment <- expand.grid(   dose = doses,   tank = 1:tanks_per_dose ) experiment$tank_id <- 1:nrow(experiment)  # Add random tank effect (creates correlation within tanks) # Higher ICC_tank values create stronger clustering ICC_tank <- 0.3  # Intraclass correlation coefficient for tank effect tank_effect <- rnorm(nrow(experiment), mean = 0, sd = sqrt(ICC_tank/(1-ICC_tank)))  # Generate survival data with dose-response relationship and tank effect generate_survival <- function(dose, tank_effect) {   # Base survival probability (decreases with dose)   p_base <- 0.9 - 0.08 * dose      # Apply tank effect on logit scale   logit_p <- log(p_base/(1-p_base)) + tank_effect   p_with_tank <- exp(logit_p)/(1+exp(logit_p))      # Generate binomial outcomes for each organism   rbinom(organisms_per_tank, size = 1, prob = p_with_tank) }  # Generate data for each tank tank_data <- lapply(1:nrow(experiment), function(i) {   survivors <- generate_survival(experiment$dose[i], tank_effect[i])   data.frame(     dose = experiment$dose[i],     tank_id = experiment$tank_id[i],     tank = experiment$tank[i],     organism = 1:organisms_per_tank,     survived = survivors   ) })  # Combine all data all_data <- do.call(rbind, tank_data)  # Summarize by tank (this is often how data is analyzed) tank_summary <- aggregate(survived ~ dose + tank_id, data = all_data,                           FUN = function(x) c(sum = sum(x), total = length(x))) tank_summary$successes <- tank_summary$survived[,\"sum\"] tank_summary$totals <- tank_summary$survived[,\"total\"]  # View the summarized data print(tank_summary[, c(\"dose\", \"tank_id\", \"successes\", \"totals\")]) #>    dose tank_id successes totals #> 1     0       1         8     10 #> 2     1       2         9     10 #> 3     2       3         9     10 #> 4     5       4         5     10 #> 5    10       5         0     10 #> 6     0       6         9     10 #> 7     1       7        10     10 #> 8     2       8         5     10 #> 9     5       9         4     10 #> 10   10      10         1     10 #> 11    0      11         9     10 #> 12    1      12        10     10 #> 13    2      13         9     10 #> 14    5      14         7     10 #> 15   10      15         0     10  # Aggregate by dose (ignoring tank structure - incorrect approach) dose_summary <- aggregate(cbind(successes, totals) ~ dose, data = tank_summary, FUN = sum) print(dose_summary) #>   dose successes totals #> 1    0        26     30 #> 2    1        29     30 #> 3    2        23     30 #> 4    5        16     30 #> 5   10         1     30  # Test for overdispersion using the aggregated data (by dose) simple_model <- glm(cbind(successes, totals - successes) ~ dose,                     family = binomial(), data = dose_summary) overdispersion_result <- test_overdispersion(dose_summary$successes, dose_summary$totals, simple_model) print(overdispersion_result) #> $dispersion #> [1] 1.671489 #>  #> $p_value #> [1] 0.170741 #>  #> $interpretation #> [1] \"Overdispersion detected\"  # Now compare standard Cochran-Armitage test vs. Rao-Scott corrected version library(drcHelper)  # Assuming your package is installed  # Standard test ca_test <- cochranArmitageTrendTest(   successes = dose_summary$successes,   totals = dose_summary$totals,   doses = dose_summary$dose )  # Rao-Scott corrected test ca_test_rs <- cochranArmitageTrendTest(   successes = dose_summary$successes,   totals = dose_summary$totals,   doses = dose_summary$dose,   rao_scott = TRUE ) #> Estimated phi = 17.871 using simple method with doses scoring  # Compare results print(ca_test) #>  #>  Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 0.867, 0.967, 0.767, 0.533, 0.033 at doses 0, 1, 2, 5, 10 #> = -8.3049, p-value < 2.2e-16 #> alternative hypothesis: two.sided print(ca_test_rs) #>  #>  Rao-Scott corrected Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 0.867, 0.967, 0.767, 0.533, 0.033 at doses 0, 1, 2, 5, 10 #> = -1.9646, p-value = 0.04947 #> alternative hypothesis: two.sided  # Step-down tests step_down <- stepDownTrendTestBinom(   successes = dose_summary$successes,   totals = dose_summary$totals,   doses = dose_summary$dose )  step_down_rs <- stepDownTrendTestBinom(   successes = dose_summary$successes,   totals = dose_summary$totals,   doses = dose_summary$dose,   rao_scott = TRUE ) #> Estimated phi = 17.871 using simple method with doses scoring  print(step_down) #>  #> Step-down Cochran-Armitage test for trend (doses scoring) (doses scoring)  #>  #> data: successes out of totals at doses 0, 1, 2, 5, 10 with doses scoring  #>  #> Step-down results: #>        Doses_Included Statistic      P_Value #> Step 1 0, 1, 2, 5, 10 -8.304949 9.986261e-17 #> Step 2     0, 1, 2, 5 -3.908588 9.283697e-05 #> Step 3        0, 1, 2 -1.139332 2.545648e-01 #> Step 4           0, 1  1.401298 1.611249e-01 #>  #> Alternative hypothesis: two.sided  #> NOEC: 2  #> LOEC: 5 print(step_down_rs) #>  #> Step-down Rao-Scott corrected Cochran-Armitage test for trend (doses scoring) (doses scoring)  #>  #> data: successes out of totals at doses 0, 1, 2, 5, 10 with doses scoring  #>  #> Step-down results: #>        Doses_Included  Statistic    P_Value #> Step 1 0, 1, 2, 5, 10 -1.9645577 0.04946545 #> Step 2     0, 1, 2, 5 -0.9245870 0.35518078 #> Step 3        0, 1, 2 -0.2695120 0.78753573 #> Step 4           0, 1  0.3314808 0.74028134 #>  #> Alternative hypothesis: two.sided  #> NOEC: 5  #> LOEC: 10 #> TableGrob (2 x 2) \"arrange\": 4 grobs #>   z     cells    name           grob #> 1 1 (1-1,1-1) arrange gtable[layout] #> 2 2 (1-1,2-2) arrange gtable[layout] #> 3 3 (2-2,1-1) arrange gtable[layout] #> 4 4 (2-2,2-2) arrange gtable[layout] # Run the Cochran-Armitage tests for comparison # Using the dose-level aggregated data (incorrect approach that ignores clustering) ca_test <- cochranArmitageTrendTest(   successes = dose_summary$total_successes,   totals = dose_summary$total_organisms,   doses = dose_summary$dose )  # With Rao-Scott correction ca_test_rs <- cochranArmitageTrendTest(   successes = dose_summary$total_successes,   totals = dose_summary$total_organisms,   doses = dose_summary$dose,   rao_scott = TRUE ) #> Estimated phi = 17.871 using simple method with doses scoring  # Print results cat(\"\\nStandard Cochran-Armitage Test:\\n\") #>  #> Standard Cochran-Armitage Test: print(ca_test) #>  #>  Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 0.867, 0.967, 0.767, 0.533, 0.033 at doses 0, 1, 2, 5, 10 #> = -8.3049, p-value < 2.2e-16 #> alternative hypothesis: two.sided  cat(\"\\nRao-Scott Corrected Cochran-Armitage Test:\\n\") #>  #> Rao-Scott Corrected Cochran-Armitage Test: print(ca_test_rs) #>  #>  Rao-Scott corrected Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 0.867, 0.967, 0.767, 0.533, 0.033 at doses 0, 1, 2, 5, 10 #> = -1.9646, p-value = 0.04947 #> alternative hypothesis: two.sided  # Calculate the estimated dispersion parameter phi_est <- mean(dose_summary$overdispersion, na.rm = TRUE) cat(\"\\nEstimated overall dispersion parameter:\", round(phi_est, 2), \"\\n\") #>  #> Estimated overall dispersion parameter: 3.77"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"modelling-approaches","dir":"Articles","previous_headings":"","what":"Modelling Approaches","title":"Quantal Data","text":"Instead nonparametric tests (options clustered binary multinomial data), regression modelling using test concentration categorical variable can also applied. fill section future.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Quantal-Data.html","id":"comparison-between-arcsin-approach-and-stepdown-approach","dir":"Articles","previous_headings":"","what":"Comparison between arcsin approach and stepdown approach","title":"Quantal Data","text":"","code":"##quantal_dat_nested <- readRDS(\"~/Projects/drcHelper/data-raw/quantal_dat_nested.rds\") data(quantal_dat_nested) second_arcsin_data <- quantal_dat_nested$data[[2]] %>% mutate(arcsin_prop = asin(sqrt(immob)),Treatment = factor(Treatment, levels = c(\"Control\", sort(as.numeric(unique(Treatment[Treatment != \"Control\"]))))) ) result_nors <- stepDownTrendTestBinom(successes = as.numeric(second_arcsin_data$Immobile), totals = second_arcsin_data$Total, doses = second_arcsin_data$Dose, rao_scott = FALSE) result_rs <- stepDownTrendTestBinom(successes = as.numeric(second_arcsin_data$Immobile), totals = second_arcsin_data$Total, doses = second_arcsin_data$Dose, rao_scott = TRUE) #> Estimated phi = 18.857 using simple method with doses scoring  result_nors #>  #> Step-down Cochran-Armitage test for trend (doses scoring) (doses scoring)  #>  #> data: successes out of totals at doses 0, 5, 10, 20, 40, 80 with doses scoring  #>  #> Step-down results: #>              Doses_Included Statistic      P_Value #> Step 1 0, 5, 10, 20, 40, 80  8.944886 3.723348e-19 #> Step 2     0, 5, 10, 20, 40  2.516835 1.184142e-02 #> Step 3         0, 5, 10, 20  0.000000 1.000000e+00 #> Step 4             0, 5, 10  0.000000 1.000000e+00 #> Step 5                 0, 5  0.000000 1.000000e+00 #>  #> Alternative hypothesis: two.sided  #> NOEC: 20  #> LOEC: 40 result_rs  #>  #> Step-down Rao-Scott corrected Cochran-Armitage test for trend (doses scoring) (doses scoring)  #>  #> data: successes out of totals at doses 0, 5, 10, 20, 40, 80 with doses scoring  #>  #> Step-down results: #>              Doses_Included Statistic    P_Value #> Step 1 0, 5, 10, 20, 40, 80 2.0598560 0.03941231 #> Step 2     0, 5, 10, 20, 40 0.5795846 0.56219478 #> Step 3         0, 5, 10, 20 0.0000000 1.00000000 #> Step 4             0, 5, 10 0.0000000 1.00000000 #> Step 5                 0, 5 0.0000000 1.00000000 #>  #> Alternative hypothesis: two.sided  #> NOEC: 40  #> LOEC: 80  second_arcsin_data_2 <- second_arcsin_data %>% filter(Dose < 80)  result <- cochranArmitageTrendTest(successes = as.numeric(second_arcsin_data_2$Immobile), totals = second_arcsin_data_2$Total, doses = second_arcsin_data_2$Dose,rao_scott = TRUE) #> Estimated phi = 2.027 using simple method with doses scoring result #>  #>  Rao-Scott corrected Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 0, 0, 0, 0, 0.067 at doses 0, 5, 10, 20, 40 #> = 1.7678, p-value = 0.0771 #> alternative hypothesis: two.sided  result <- cochranArmitageTrendTest(successes = as.numeric(second_arcsin_data_2$Immobile), totals = second_arcsin_data_2$Total, doses = second_arcsin_data_2$Dose,rao_scott = FALSE) result #>  #>  Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 0, 0, 0, 0, 0.067 at doses 0, 5, 10, 20, 40 #> = 2.5168, p-value = 0.01184 #> alternative hypothesis: two.sided"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/System_Testing.html","id":"purpose-of-testing","dir":"Articles","previous_headings":"","what":"Purpose of Testing","title":"System Testing","text":"testing phase ensure R package UI top meet user requirements (URS) behaves end users expect. tests fail, possible detect loopholes fix errors early development. Note access security scalability taken care V-COP environment. purpose testing limited functional requirements. Interfacing ability via API V-COP file management validated run environment designed tested manually. One important aspect testing verify functions used analysis supposed . many functions different R packages designed perform task, however, different assumptions behind. outcome may similar different, important understand details choose appropriate ones.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/System_Testing.html","id":"unit-testing-for-this-helper-package","dir":"Articles","previous_headings":"Structure of Testing","what":"Unit Testing for this Helper Package","title":"System Testing","text":"unit testing written using testthat can run via:","code":"devtools::test()"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/System_Testing.html","id":"unit-testing-for-other-r-functions-involved-in-the-analysis","dir":"Articles","previous_headings":"Structure of Testing","what":"Unit Testing for Other R functions involved in the Analysis","title":"System Testing","text":"Unit testing functions included package written directory: inst/SystemTesting/Verify_R_FS","code":"file_lists <- list.files(paste0(\"path0\",\"/inst/SystemTesting/Verify_R_FS\")) if(\"_snaps\" %in% file_lists) {file_lists <- file_lists[file_lists!=\"_snaps\"]} testResultsRaw_list <- lapply(file_lists,function(x)testthat::test_file(paste0(path0,\"/inst/SystemTesting/Verify_R_FS/\",x), reporter = testthat::ListReporter))"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/System_Testing.html","id":"system-testing","dir":"Articles","previous_headings":"Structure of Testing","what":"System Testing","title":"System Testing","text":"test cases designed Sarah Baumert Harold. inst/SystemTesting/Validate_TS","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"trimmed-spearman-karber-tsk-method","dir":"Articles","previous_headings":"","what":"Trimmed Spearman-Karber (TSK) Method","title":"TSK and Probit Models","text":"Trimmed Spearman-Karber (TSK) method statistical technique used primarily toxicology ecotoxicology estimate median effective dose/concentration/rate (ED50, EC50, ER50) median lethal concentration (LC50) dose-response data. builds original Spearman-Karber method, non-parametric approach calculating point 50% test subjects respond (e.g., dead symptom present). “trimmed” aspect, introduced Hamilton et al. 1977, enhances robustness excluding extreme data points response proportions near 0% 100%, reducing bias incomplete dose ranges.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"how-the-tsk-approach-works","dir":"Articles","previous_headings":"Trimmed Spearman-Karber (TSK) Method","what":"How the TSK Approach Works","title":"TSK and Probit Models","text":"TSK method approximates mean underlying tolerance distribution, assuming symmetric logarithmic scale (common concentrations). processes data several steps compute ED50 (referred mu provided code), variance, geometric standard deviation (GSD), confidence intervals. ’s breakdown based algorithm code standard descriptions: Inputs include: x (vector doses concentrations, must positive increasing), r (number responses, e.g., deaths), n (number subjects tested per dose), (trim level, 0 ≤ < 0.5, default 0), conf (confidence level, 0.5 < conf < 1, default 0.95). Doses log-transformed (base 10) symmetry. first dose 0 (control), ’s handled scaling responses issuing warnings non-zero. Proportions p = r/n calculated. example data set R package ecotoxicology. proportions monotonically increasing (can happen due sampling variability), adjacent non-increasing values averaged enforce monotonicity. prevents artifacts estimation. Proportions scaled: p_scaled = (p - ) / (1 - 2*) focus central response range (1-). Data points p ≤ p ≥ 1-trimmed. Linear interpolation adds virtual points exactly 0% 100% response needed, ensuring trimmed dataset spans 0 1. trimming avoids -reliance tails variability high data sparse. trimmed log-doses differences proportions (delp) used compute midpoint averages. log-median logmu = sum((x_i + x_{+1})/2 * delp_i), weighted average approximating mean log-tolerance distribution. median dose mu = 10^logmu. Variance calculated using specialized functions (V1 V6 code) based positions lower (L) upper (U) bounds around trim. account binomial variability proportions dose spacings, scaled (2 - 4*)^2. GSD = 10^sqrt(Var), representing dispersion. Confidence limits use inverse error function: left = mu * gsd^(-v), right = mu * gsd^v, v = sqrt(2) * erfinv(conf) approximate normality log scale. Returns mu, gsd, left, right. code includes plotting: response curve, median point, error bars confidence. method computationally simple, non-iterative, excels handling datasets full 0-100% response isn’t achieved.","code":"# Example data data <- data.frame(   x = c(15.54, 20.47, 27.92, 35.98, 55.52),   r = c(0, 0, 0, 1, 20),   n = c(20, 20, 20, 19, 20) ) # Load libraries for probit analyses library(MASS) library(drc)  # Compute TSK tsk_result_ecotox <- ecotoxicology::TSK(data$x, data$r, data$n, A = 0, conf = 0.95) print(\"TSK Results:\") #> [1] \"TSK Results:\" print(tsk_result_ecotox) #> $mu #> [1] 43.89339 #>  #> $gsd #>        x  #> 1.017763  #>  #> $left #>        x  #> 42.40451  #>  #> $right #>        x  #> 45.43455"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"validation-against-ecotoxicologytsk","dir":"Articles","previous_headings":"Trimmed Spearman-Karber (TSK) Method","what":"Validation against ecotoxicology::TSK","title":"TSK and Probit Models","text":"part validate tsk function included drcHelper function computes TSK estimate confidence intervals matching ecotoxicology::TSK.","code":"library(drcHelper) tsk_result_drc <- drcHelper::tsk(   x = data$x,   r = data$r,   n = data$n,   control = 0,   trim = 0,   conf.level = 0.95,   use.log.doses = TRUE ) print(\"TSK Results from drcHelper:\") #> [1] \"TSK Results from drcHelper:\" print(tsk_result_drc) #>  #> Trimmed Spearman-Karber method using 0 percent trim #>  #> Data was not smoothed #> Calculation done using the logs of the doses #> Estimated LD50: 43.89339 GSD of estimate: 1.017763 #> 95 percent confidence interval on LD50: #>  42.40451 45.43455 comparison_table <- data.frame(   Metric = c(\"LD50/Mu\", \"GSD\", \"CI Lower\", \"CI Upper\"),   ecotoxicology_TSK = c(tsk_result_ecotox$mu, tsk_result_ecotox$gsd, tsk_result_ecotox$left, tsk_result_ecotox$right),   drcHelper_tsk = c(tsk_result_drc$LD50, tsk_result_drc$gsd, tsk_result_drc$conf.int[1], tsk_result_drc$conf.int[2]),   Difference = abs(c(tsk_result_ecotox$mu - tsk_result_drc$LD50,                      tsk_result_ecotox$gsd - tsk_result_drc$gsd,                      tsk_result_ecotox$left - tsk_result_drc$conf.int[1],                      tsk_result_ecotox$right - tsk_result_drc$conf.int[2])),   Validated = abs(c(tsk_result_ecotox$mu - tsk_result_drc$LD50,                     tsk_result_ecotox$gsd - tsk_result_drc$gsd,                     tsk_result_ecotox$left - tsk_result_drc$conf.int[1],                     tsk_result_ecotox$right - tsk_result_drc$conf.int[2])) < 0.0001 ) library(kableExtra) kable(comparison_table) %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%   row_spec(which(!comparison_table$Validated), background = \"#FFCCCC\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"compare-with-probit-glm-and-drc","dir":"Articles","previous_headings":"Trimmed Spearman-Karber (TSK) Method","what":"Compare with Probit GLM and DRC","title":"TSK and Probit Models","text":"TSK DRC estimates close (43.89 vs. 40.34), suggesting robustness, GLM’s estimate (39.01) large SE (SE = 37.46047) indicates fitting issues (caused fitted probabilities numerically 0 1 occurred ). Given warning GLM, ’d trust TSK DRC dataset.","code":"# Probit GLM (binomial family) model_glm_log10 <- glm(cbind(r, n - r) ~ log10(x), family = binomial(link = \"probit\"), data = data) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred summary(model_glm_log10) #>  #> Call: #> glm(formula = cbind(r, n - r) ~ log10(x), family = binomial(link = \"probit\"),  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|) #> (Intercept)   -73.32   76403.95  -0.001    0.999 #> log10(x)       46.08   49100.87   0.001    0.999 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 9.4482e+01  on 4  degrees of freedom #> Residual deviance: 4.6395e-10  on 3  degrees of freedom #> AIC: 5.9464 #>  #> Number of Fisher Scoring iterations: 25 lc50_glm_log10 <- dose.p(model_glm_log10, cf = c(1,2), p = 0.5) print(\"GLM Probit LC50 (with SE):\") #> [1] \"GLM Probit LC50 (with SE):\" print(lc50_glm_log10) #>              Dose       SE #> p = 0.5: 1.591216 37.46047  lc50_glm_log10_val <- 10^lc50_glm_log10[1] lc50_glm_log10_val #> p = 0.5:  #> 39.01356 lc50_glm_log10_se <- attr(lc50_glm_log10, \"SE\")[1] a_glm_log10 <- coef(model_glm_log10)[1] b_glm_log10 <- coef(model_glm_log10)[2] lc50_glm_log10 == -a_glm_log10/b_glm_log10 #> p = 0.5:  #>     TRUE model_glm_log <- glm(cbind(r, n - r) ~ log(x), family = binomial(link = \"probit\"), data = data) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred lc50_glm_log <- dose.p(model_glm_log, cf = c(1, 2), p = 0.5) lc50_glm_log_val <- exp(lc50_glm_log[1]) lc50_glm_log_se <- attr(lc50_glm_log, \"SE\")[1] a_glm_log <- coef(model_glm_log)[1] b_glm_log <- coef(model_glm_log)[2] a_glm_log #> (Intercept)  #>   -73.32047 a_glm_log10 #> (Intercept)  #>   -73.32047 # Probit DRC (LN.2 with binomial) model_drc <- drm(r/n ~ x, fct = LN.2(), weight = n, type = \"binomial\", data = data) summary(model_drc) #>  #> Model fitted: Log-normal with lower limit at 0 and upper limit at 1 (2 parms) #>  #> Parameter estimates: #>  #>               Estimate Std. Error t-value p-value   #> b:(Intercept)   14.168     63.140  0.2244 0.82245   #> e:(Intercept)   40.338     20.573  1.9607 0.04991 * #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ed50_drc <- ED(model_drc, 50, interval = \"inv\") ## note. if here using delta, very wide CI.  #>  #> Estimated effective doses #>  #>        Estimate  Lower  Upper #> e:1:50   40.338 36.681 48.478 ED(model_drc, 50, interval = \"delta\") #>  #> Estimated effective doses #>  #>         Estimate Std. Error     Lower     Upper #> e:1:50 40.337797  20.572946  0.015564 80.660031 print(\"DRC Probit ED50/LC50 (with CI):\") #> [1] \"DRC Probit ED50/LC50 (with CI):\" print(ed50_drc) #>        Estimate    Lower    Upper #> e:1:50  40.3378 36.68111 48.47803 drc_lc50 <- ed50_drc[1, \"Estimate\"] drc_ci <- c(ed50_drc[1, \"Lower\"], ed50_drc[1, \"Upper\"])  model_drc_loge <- drm(r/n ~ log(x), fct = LN.2(), weight = n, type = \"binomial\", data = data) ED(model_drc_loge, 50, interval = \"delta\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:50  3.69711    0.32517 3.05979 4.33442 ED(model_drc_loge, 50, interval = \"fls\") #>  #> Estimated effective doses #>  #>        Estimate  Lower  Upper #> e:1:50   40.330 21.323 76.281 library(knitr) library(kableExtra)  comparison_table <- data.frame(   Method = c(\"Trimmed Spearman-Karber (TSK)\", \"Probit GLM (log10)\", \"Probit GLM (log)\", \"Probit DRC (LN.2, delta)\", \"Probit DRC (LN.2, inv)\"),   LC50 = c(43.89339, 39.01356, 39.01356, 40.3378,40.3378),   Lower_95_CI = c(42.40451, NA, NA, 0.015564,36.681),   Upper_95_CI = c(45.43455, NA, NA, 80.66003,48.478),   #SE = c(NA, 37.46047, lc50_glm_log_se, NA),   Notes = c(\"Non-parametric, robust to model fit issues\",             \"Fitting issues (probabilities 0 or 1 warning)\",             \"Fitting issues (probabilities 0 or 1 warning)\",             \"If using delta method, wide CI due to sparse data at high doses\",             \"robust to sparse data with inverse regression CI\") )  kable(comparison_table, format = \"markdown\", digits = 3) %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%   column_spec(5, width = \"4.5in\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"what-kind-of-data-should-be-used","dir":"Articles","previous_headings":"Trimmed Spearman-Karber (TSK) Method > Compare with Probit GLM and DRC","what":"What Kind of Data Should Be Used","title":"TSK and Probit Models","text":"TSK designed quantal (binary) bioassay data toxicity tests, acute lethality studies aquatic organisms (e.g., fish, Daphnia) dose-response experiments. Key characteristics: Doses (x): vector increasing positive concentrations (e.g., chemical levels mg/L). Zero-dose controls allowed handled specially. Responses (r): Counts affected subjects (e.g., dead organisms) dose. Sample sizes (n): Number subjects tested per dose (can constant vary). Proportions (p = r/n): ideally span near 0 near 1 across doses, trimming allows incomplete coverage adjusted. least one dose partial response (0 < p < 1) meaningful estimation. Doses strictly increasing order; responses non-negative ≤ n. Suitable small moderate sample sizes (e.g., n=10-20 per dose, 4-6 doses). Assumes logarithmic spacing symmetry, concentrations (logs) input. Typical Applications: Data experiments responses binomial (e.g., dead/alive) doses discrete. ’s robust irregular dose spacing doesn’t require normality assumptions. responses don’t cover 1-, code suggests increasing warns invalid trims.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"comparison-to-standard-probit-analysis","dir":"Articles","previous_headings":"","what":"Comparison to Standard Probit Analysis","title":"TSK and Probit Models","text":"wil compare tsk function drcHelper Probit GLM Probit DRC approaches estimating LC50 (ED50) values. ’ll also explain differences similarities among three methods provide details transforming results Probit GLM Probit DRC.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"overview-of-the-three-methods","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis","what":"Overview of the Three Methods","title":"TSK and Probit Models","text":"Trimmed Spearman-Karber (TSK) - drcHelper::tsk: Method: Trimmed Spearman-Karber method non-parametric approach estimating median lethal concentration (LC50) effective dose (ED50) dose-response data. calculates LC50 weighted average dose levels response transitions 50%, optional trimming extreme data points reduce influence outliers. Implementation: drcHelper::tsk, method uses logarithmic doses default (use.log.doses = TRUE) implements pool-adjacent-violators algorithm (PAVA) via isotone::gpava smooth non-monotonic responses. also calculates confidence intervals based variance lognormal distribution. Key Features: assumption specific dose-response model; robust model misspecification; handles non-monotonic data smoothing. Probit GLM (Generalized Linear Model Binomial Family): Method: parametric approach using generalized linear model binomial family probit link function. models probability response (e.g., mortality) function log-dose, assuming response follows normal distribution probit scale. Implementation: glm(cbind(r, n - r) ~ log10(x), family = binomial(link = \"probit\")) fits model, MASS::dose.p estimates LC50. model assumes linear relationship log-dose probit-transformed response probability. Key Features: Assumes specific (normal) distribution response; provides standard errors confidence intervals based asymptotic theory; sensitive model fit data distribution. Probit DRC (Dose-Response Curve drc Package, LN.2 Model): Method: also parametric approach uses drc package fit log-normal dose-response curve (LN.2 model) binomial response type. models dose-response relationship using two-parameter log-normal function, response bounded 0 1. Implementation: drm(r/n ~ x, fct = LN.2(), weight = n, type = \"binomial\") fits model, ED() estimates ED50 (LC50). uses log-dose internally fitting. Key Features: Similar Probit GLM specifically tailored dose-response analysis; assumes log-normal distribution; provides confidence intervals via delta method.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"similarities-among-the-three-methods","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis","what":"Similarities Among the Three Methods","title":"TSK and Probit Models","text":"Objective: three methods aim estimate LC50 (ED50), dose 50% population responds (e.g., mortality effect). Data Input: work binomial data (successes totals, e.g., number deaths total organisms) dose levels. Dose Transformation: Probit GLM TSK (default) use logarithmic transformations doses (log10(x) GLM, log10 internally tsk), DRC uses log-doses internally fitting. Confidence Intervals: methods provide form uncertainty estimate (confidence intervals standard errors) around LC50 estimate, though calculation methods differ.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"differences-among-the-three-methods","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis","what":"Differences Among the Three Methods","title":"TSK and Probit Models","text":"TSK: Non-parametric; assumption underlying dose-response curve shape beyond general monotonic trend (smoothed necessary). Probit GLM: Parametric; assumes linear relationship probit scale, implying normal distribution tolerance thresholds. Probit DRC (LN.2): Parametric; assumes log-normal dose-response curve, may better fit certain biological responses still imposes specific functional form. TSK: Uses trimming reduce impact extreme data points smoothing (PAVA) handle non-monotonic responses, making robust data irregularities. Probit GLM: Sensitive deviations normality probit scale; can fail converge give unreliable estimates data doesn’t fit model (seen warning fitted probabilities 0 1). Probit DRC: flexible GLM dose-response data due specific curve-fitting approach still assumes log-normal relationship. TSK: Directly estimates LC50 weighted midpoint doses, variance-based confidence intervals. Probit GLM: Estimates LC50 via inverse prediction fitted linear model probit scale; standard errors based model’s covariance matrix. Probit DRC: Estimates ED50 via fitted log-normal curve parameters, confidence intervals using delta method. TSK: robust model misspecification since doesn’t assume specific curve; suitable small datasets parametric assumptions questionable. Probit GLM: Less robust; can fail extreme data (e.g., complete separation warning) requires larger sample sizes reliable estimates. Probit DRC: Tailored dose-response, often robust GLM toxicological data still requires reasonable fit log-normal model. TSK (drcHelper::tsk): LC50 = 43.89339, CI = (42.40451, 45.43455) Probit GLM: LC50 = 39.01356, SE = 37.46047 (wide due fitting issues) Probit DRC (drc::LN.2): LC50 = 40.3378, CI = (0.015564, 80.66003) Observation: TSK DRC provide similar LC50 estimates (~40-43), GLM slightly lower (~39) huge SE, indicating fitting problems (likely due warning numerical probabilities 0 1). DRC’s wide CI suggests uncertainty upper bound, possibly due sparse data higher doses.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"transformation-between-probit-glm-and-probit-drc","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis","what":"Transformation Between Probit GLM and Probit DRC","title":"TSK and Probit Models","text":"Probit GLM Probit DRC model dose-response relationship transformed scale, differ functional forms parameterizations. ’s transform relate results :","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"probit-glm-to-probit-drc","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis > Transformation Between Probit GLM and Probit DRC","what":"1. Probit GLM to Probit DRC","title":"TSK and Probit Models","text":"Probit GLM Model: GLM probit link models probability response : \\[ \\mathrm{probit}(p) = + b \\cdot \\log_{10}(\\mathrm{dose}) \\] \\(p\\) proportion affected, \\(\\) intercept, \\(b\\) slope. LC50 (dose 50% affected) found solving dose \\(p = 0.5\\): \\[ \\mathrm{probit}(0.5) = 0 = + b \\cdot \\log_{10}(\\mathrm{LC}_{50}) \\] gives: \\[ \\log_{10}(\\mathrm{LC}_{50}) = -\\frac{}{b} \\] Probit DRC (LN.2): DRC model LN.2() fits log-normal curve, parameterized : \\[ p = \\Phi\\left( \\frac{\\log(\\mathrm{dose}) - \\log(e)}{1/b} \\right) \\] \\(e\\) ED50 (LC50) parameter, \\(b\\) slope, \\(\\Phi\\) standard normal CDF. , \\(\\log\\) denotes natural logarithm (\\(\\ln\\)), \\(\\log_{10}\\). Transformation: relate GLM DRC parameterizations, convert base-10 natural logarithm using \\(\\log(10) \\approx 2.302585\\): GLM gives: \\[ \\log_{10}(\\mathrm{LC}_{50}) = -\\frac{}{b} \\] : \\[ \\ln(\\mathrm{LC}_{50}) = \\log_{10}(\\mathrm{LC}_{50}) \\cdot \\log(10) = \\left(-\\frac{}{b}\\right) \\cdot 2.302585 \\] approximates DRC’s \\(\\log(e)\\) parameter. slope parameter transforms : \\[ b_{\\mathrm{DRC}} \\approx \\frac{1}{b_{\\mathrm{GLM}} \\cdot \\log(10)} \\] since DRC slope inversely related spread log scale. DRC LN.2 slope parameter natural log scale equal GLM (log) slope. Practical Note: Due different fitting algorithms assumptions, exact equivalence guaranteed. data, GLM’s LC50 (39.01356) DRC’s LC50 (40.3378) close identical, reflecting slight differences model fit.","code":"b_drc <- coef(model_drc)[1] -log(coef(model_drc)[2])*b_drc - a_glm_log #> e:(Intercept)  #>      20.93709 b_glm_log*log(10) - b_glm_log10 #>       log(x)  #> -8.05251e-10 b_drc #> b:(Intercept)  #>      14.16805 b_glm_log #>   log(x)  #> 20.01154 coef(model_drc_loge)[1] #> b:(Intercept)  #>      51.66112"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"probit-drc-to-probit-glm","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis > Transformation Between Probit GLM and Probit DRC","what":"2. Probit DRC to Probit GLM","title":"TSK and Probit Models","text":"Reverse Transformation: DRC gives \\(e\\) (LC50) original scale, compute: \\[ \\ln(e) \\] convert base-10 log : \\[ \\log_{10}(e) = \\frac{\\ln(e)}{\\log(10)} \\] example dataset: , approximate GLM parameters : \\[   b_{\\mathrm{GLM}} \\approx \\frac{1}{b_{\\mathrm{DRC}} \\cdot \\log(10)}   \\] \\[   a_{\\mathrm{GLM}} \\approx -b_{\\mathrm{GLM}} \\cdot \\log_{10}(e)   \\] , exact matches unlikely due fitting differences. Practical Note: Use \\(\\log_{10}(x)\\) GLM align DRC’s internal log-scale fitting, though DRC uses \\(\\ln\\) internally.","code":"-a_glm_log10/b_glm_log10*log(10)  #> (Intercept)  #>    3.663909 -a_glm_log/b_glm_log #> (Intercept)  #>    3.663909 log(coef(model_drc)[2]) #> e:(Intercept)  #>      3.697289"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"recommendations-and-conclusion","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis","what":"Recommendations and Conclusion","title":"TSK and Probit Models","text":"Use TSK (drcHelper::tsk) data sparse, non-monotonic, want non-parametric approach robust model misspecification. ’s ideal quick, reliable LC50 estimates without strong distributional assumptions. Use Probit GLM larger datasets normal tolerance distribution plausible need standard statistical inference (e.g., hypothesis testing coefficients). cautious convergence issues (warning). Use Probit DRC (LN.2) dose-response-specific analysis, especially log-normal model fits biological response better. ’s tailored toxicology GLM still assumes specific curve. Transformation Caveat: theoretical transformations GLM DRC possible, practical differences optimization model assumptions mean direct conversion isn’t exact. Use respective package functions (dose.p GLM, ED DRC) accurate estimates.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"example-where-results-agree","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis","what":"Example where results agree","title":"TSK and Probit Models","text":"differences parameter estimates probit GLM drc::LN.2 (even TSK) previous example dataset due extreme separation lack intermediate responses—doses either 0 100% response, one intermediate point. leads instability poor identifiability parametric models, saw huge standard errors odd parameter values. Let’s see happens “ideal” dataset, finney71 example, smooth, monotonic increase response good spread intermediate response rates: Note trim . TSK method assumes response curve monotonic intermediate responses (exactly 0 1) informative estimating median effective dose (LC50/EC50).","code":"finney71 <- data.frame(   dose = c(10.2, 7.7, 5.1, 3.8, 2.6, 0.0),   total = c(50, 49, 46, 48, 50, 49),   affected = c(44, 42, 24, 16, 6, 0) ) finney71$prop <- finney71$affected / finney71$total  # Probit GLM (log10) glm_log10 <- glm(cbind(affected, total - affected) ~ log10(dose), family = binomial(link = \"probit\"), data = finney71[finney71$dose > 0, ]) lc50_log10 <- MASS::dose.p(glm_log10, cf = c(1,2), p = 0.5) cat(\"GLM log10 LC50:\", 10^as.numeric(lc50_log10[1]), \"\\n\") #> GLM log10 LC50: 4.845492  # Probit GLM (log) glm_log <- glm(cbind(affected, total - affected) ~ log(dose), family = binomial(link = \"probit\"), data = finney71[finney71$dose > 0, ]) lc50_log <- MASS::dose.p(glm_log, cf = c(1,2), p = 0.5) cat(\"GLM log LC50:\", exp(as.numeric(lc50_log[1])), \"\\n\") #> GLM log LC50: 4.845492  # Probit DRC (LN.2) library(drc) drc_mod <- drm(affected/total ~ dose, weights = total, fct = LN.2(), type = \"binomial\", data = finney71) ed50_drc <- ED(drc_mod, 50, interval = \"delta\") #>  #> Estimated effective doses #>  #>        Estimate Std. Error   Lower   Upper #> e:1:50  4.84550    0.24654 4.36229 5.32871 cat(\"DRC LN.2 LC50:\", ed50_drc[1, \"Estimate\"], \"\\n\") #> DRC LN.2 LC50: 4.845502  # TSK finney71 <- finney71[order(finney71$dose),] tsk_res <- drcHelper::tsk(   x = finney71$dose,   r = finney71$affected,   n = finney71$total,   control = 0,   trim = 0.12,  # as suggested by the error   conf.level = 0.95,   use.log.doses = TRUE ) cat(\"TSK LC50:\", tsk_res$LD50, \"\\n\") #> TSK LC50: 4.779998 #ecotoxicology::TSK(finney71$dose, finney71$affected, finney71$total, A = 0.12, conf = 0.95)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"results-table","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis","what":"Results Table","title":"TSK and Probit Models","text":"","code":"comparison <- data.frame(   Method = c(\"Probit GLM (log10)\", \"Probit GLM (log)\", \"Probit DRC (LN.2)\", \"TSK (trim = 0.12)\"),   LC50 = c(4.845492, 4.845492, 4.845502, 4.779998),   CI_Lower = c(NA, NA, 4.36229, NA),   CI_Upper = c(NA, NA, 5.32871, NA),   Std_Error = c(NA, NA, 0.24654, NA),   Notes = c(     \"Identical to log, see below\",     \"Identical to log10\",     \"Nearly identical to GLM\",     \"Robust nonparametric method\"   ) ) knitr::kable(comparison, digits = 5) coef(drc_mod)[1]  #> b:(Intercept)  #>      1.829697 coef(glm_log)[2] #> log(dose)  #>  1.829768 coef(glm_log10)[2]/log(10) #> log10(dose)  #>    1.829768"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK-and-Probit-Models.html","id":"why-do-they-agree-here","dir":"Articles","previous_headings":"Comparison to Standard Probit Analysis > Results Table","what":"Why do they agree here?","title":"TSK and Probit Models","text":"data smooth, monotonic, sigmoidal dose-response several intermediate response rates (just 0% 100%). “complete separation” (.e., 0s 1s), GLM DRC models can estimate slope intercept reliably. TSK method, nonparametric, also yield similar LC50 empirical response curve monotonic well-behaved. Summary: well-behaved, monotonic dose-response data intermediate responses, methods (parametric nonparametric) yield nearly identical LC50 estimates. demonstrates reliability methods data meet assumptions. Differences become pronounced sparse, non-monotonic, extreme datasets.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK_method.html","id":"backaground","dir":"Articles","previous_headings":"","what":"Backaground","title":" Spearman-Karber method","text":"Spearman-Karber method still use regulatory Ecotox endpoints derivation. common approach derive EC50 interpolation smoothing line.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK_method.html","id":"method","dir":"Articles","previous_headings":"","what":"Method","title":" Spearman-Karber method","text":"Two commonly used methods calculating 50% endpoint using serial dilutions Spearman-Karber method Reed Muench method. original paper written Kärber published 1931 German [Kärber, G. Archiv f. experiment. Pathol. u. Pharmakol (1931) 162: 480-483 doi:10.1007/BF01863914].","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK_method.html","id":"reed-and-muench-method","dir":"Articles","previous_headings":"Method","what":"Reed and Muench method","title":" Spearman-Karber method","text":"log10 50% end point dilution = log10 dilution showing mortality next 50% - (difference logarithms × logarithm dilution factor). Generally, following formula used calculate “difference logarithms” (difference logarithms also known “proportionate distance” “interpolated value”): Difference logarithms = [(mortality dilution next 50%)-50%]/[(mortality next 50%)-(mortality next 50%)].","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK_method.html","id":"spearman-karber-method","dir":"Articles","previous_headings":"Method","what":"Spearman-Karber method","title":" Spearman-Karber method","text":"log10 50% end point dilution = \\(- (x_0 - d/2 + d \\sum r_i/n_i)\\) \\(x_0\\) = log10 reciprocal highest dilution (lowest concentration) animals positive; \\(d\\) = log10 dilution factor; \\(n_i\\) = number animals used individual dilution (discounting accidental deaths); \\(r_i\\) = number positive animals (\\(n_i\\)). Summation started dilution \\(x_0\\). Newly proposed method Formula 1: log10 50% end point dilution = -[(total number animals died/number animals inoculated per dilution) + 0.5] × log dilution factor. Formula 2 (accidental death occurred): log10 50% end point dilution = -(total death score + 0.5) × log dilution factor.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK_method.html","id":"some-notes","dir":"Articles","previous_headings":"","what":"Some Notes","title":" Spearman-Karber method","text":"tsk function comes R package. Since single function without dependencies, bundled helper package purpose validation verification. original goal R package replicate results DOS program used provided EPA perform trimmed Spearman-Karber method. list “expected” contains results DOS program run data Hamilton et al. NA EPA program didn’t return result. EPA program uses confidence 2*pnorm(2)-1=0.9544997 (, exactly two sigmas sides).","code":"## install.packages(\"isotone\") ## devtools::install_github(repo=\"brsr/tsk\")  library(drcHelper) #> Loading required package: drc #> Loading required package: MASS #> Loading required package: drcData #>  #> 'drc' has been loaded. #> Please cite R and 'drc' if used for a publication, #> for references type 'citation()' and 'citation('drc')'. #>  #> Attaching package: 'drc' #> The following objects are masked from 'package:stats': #>  #>     gaussian, getInitial ## library(tsk) tsk(c(1, 10, 100, 1000), 20, c(0, 3, 17, 20)) #>  #> Trimmed Spearman-Karber method using 0 percent trim #>  #> Data was not smoothed #> Calculation done using the logs of the doses #> Estimated LD50: 31.62278 GSD of estimate: 1.296928 #> 95 percent confidence interval on LD50: #>  18.99717 52.63942  data(hamilton)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/TSK_method.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":" Spearman-Karber method","text":"https://www.cureffi.org/2015/09/20/-math-behind-spearman-karber-analysis/ Hamilton, M. .; Russo, R. C.; Thurston, R. V. Trimmed Spearman-Karber Method Estimating Median Lethal Concentrations Toxicity Bioassays. Enviro. Sci. Tech. 1977, 11 (7), 714-719. http://dx.doi.org/10.1021/es60130a004 Ibid, 1978, 12 (4), 417. http://dx.doi.org/10.1021/es60140a017","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Trend-Testing.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Trend Testing","text":"trend test trend test used detect monotonic trend across ordered groups. ’s particularly useful dose-response studies identify whether increasing doses lead systematic change response. prerequisite trend test relationship monotonic, either consistently increasing decreasing. trend tests specifically designed detect trends, making bit powerful general tests trend exists. disadvantage consider magnitude change across ordered groups, leading unexpected identification significance also less informative even give counter-intuitive results relationship monotonic groups naturally ordered.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Trend-Testing.html","id":"some-concerns","dir":"Articles","previous_headings":"","what":"Some concerns","title":"Trend Testing","text":"lots decision flowcharts, step trend test performed monotonicity test passes, logically strange, since monotonicity test also type trend test. example, jonckeehre terpstra test linear contrast significant monotonicity test quadratic contrast significant monotonicity test.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Trend-Testing.html","id":"trend-test-by-testing-linear-and-quadratic-contrasts","dir":"Articles","previous_headings":"","what":"Trend Test by Testing Linear and Quadratic Contrasts","title":"Trend Testing","text":"Generate mock data testing","code":"library(ggplot2) mock_data <- data.frame(   treatment_var = factor(rep(c(\"Control\", \"Dose1\", \"Dose2\", \"Dose3\"), each = 10)),   response_var = c(rnorm(10, mean = 5), rnorm(10, mean = 7), rnorm(10, mean = 8), rnorm(10, mean = 10)) ) ggplot(mock_data,aes(x=treatment_var,y=response_var))+geom_point() result <- monotonicityTest(mock_data, \"treatment_var\", \"response_var\") result #>        Test t value Pr(>|t|) Significance #> 1    Linear   11.16  <0.0001          *** #> 2 Quadratic   -0.10   0.9196            ."},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Trend-Testing.html","id":"step-down-trend-test","dir":"Articles","previous_headings":"","what":"Step-Down Trend Test","title":"Trend Testing","text":"step-trend test sequential testing procedure used identify lowest dose level significant trend begins. process works follows: Start dose groups test trend. significant, remove highest dose group test . test longer significant, indicating ’ve found lowest effective dose two groups remain (typically control lowest dose) approach helps identify Observed Effect Concentration (NOEC) Lowest Observed Effect Concentration (LOEC) dose-response studies. function PMCMRplus::stepDownTrendTest PMCMRplus implements strategy continuous data using various trend tests. binomial survival data, adapt approach using Cochran-Armitage test, specifically designed binary outcomes across ordered groups, function performing step-CA called drcHelper::stepDownTrendTestBinom. also drcHelper::step_down_RSCABS drcHelper::stepDownRSCABS oridinal data. Please refere relevant data page usage demo explanations.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Validation_MCP_tests.html","id":"multiple-comparison-tests","dir":"Articles","previous_headings":"","what":"Multiple Comparison Tests","title":"Verification and Validation of NOEC Derivation by MCP","text":"article compare different functions various packages perform task, demonstrating differences similarities. implemented function combine_multiple_comparisons comparing different results. implementation provides comprehensive set functions standardizing combining multiple comparison test results dose response data analysis. functions handle various test implementations provide consistent output formats easy comparison. Note trend tests, null hypotheses different many--one pairwise comparisons. Direct comparison fair. However, NOEC calculation can based trend tests many--one pairwise tests.","code":"library(drcHelper) #> Loading required package: drc #> Loading required package: MASS #> Loading required package: drcData #>  #> 'drc' has been loaded. #> Please cite R and 'drc' if used for a publication, #> for references type 'citation()' and 'citation('drc')'. #>  #> Attaching package: 'drc' #> The following objects are masked from 'package:stats': #>  #>     gaussian, getInitial source(\"../knitr-setup.R\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Validation_MCP_tests.html","id":"dunnetts-test","dir":"Articles","previous_headings":"","what":"Dunnett’s Test","title":"Verification and Validation of NOEC Derivation by MCP","text":"glht pulls P-values multivariate t distribution. mvtnorm::pmvt called observed t statistics correlation matrix (actual code ). DescTools::DunnettTest roughly . emmeans uses close approximation Dunnett adjustment.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Validation_MCP_tests.html","id":"williams-test","dir":"Articles","previous_headings":"","what":"Williams’ Test","title":"Verification and Validation of NOEC Derivation by MCP","text":"PMCMRplus::williamsTest produces accurate results since based isotonic regression. functions use tabulated critical values provided Williams (=0.05). williamsTest function PMCMRplus produces results williamsTest_JG general. However, williamsTest function PMCMRplus use multivariate t distribution calculate p-values.","code":"x <- c(106, 114, 116, 127, 145,110, 125, 143, 148, 151, 136, 139, 149, 160, 174) g <- gl(3,5) levels(g) <- c(\"0\", \"I\", \"II\") res1 <- PMCMRplus::williamsTest(x ~ g) summaryZG(res1) #>                t'-value df t'-crit decision alpha #> mu1 - ctr <= 0    1.357 12   1.782   accept  0.05 #> mu2 - ctr <= 0    2.950 12   1.873   reject  0.05 williamsTest_JG(data.frame(treatment_var = g,response_var=x),\"response_var\",\"treatment_var\",direction=\"increasing\") #>   treatment_var Y.Tilde    Y0 Se.Diff DF  Will TCrit Signif #> 2            II   151.6 121.6   10.17 12 2.950 1.873      * #> 1             I   135.4 121.6   10.17 12 1.357 1.782      ."},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Validation_MCP_tests.html","id":"tips","dir":"Articles","previous_headings":"","what":"Tips","title":"Verification and Validation of NOEC Derivation by MCP","text":"Note install “PMCMRplus” properly ubuntu (Platform: x86_64-pc-linux-gnu), need probably install libmpfr-dev first.","code":"sudo apt-get install libmpfr-dev"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Validation_MCP_tests.html","id":"other-packages","dir":"Articles","previous_headings":"","what":"Other packages","title":"Verification and Validation of NOEC Derivation by MCP","text":"analysis, also use rstatix often, provide workflow tidy evaluations, unlike packages.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Verification_CA_test.html","id":"comparison-cochran-armitage-test-implementation-vs-prop-trend-test","dir":"Articles","previous_headings":"","what":"Comparison: Cochran-Armitage Test Implementation vs prop.trend.test","title":"Verification CA Test Implementation","text":"implementation drcHelper prop.trend.test mathematically equivalent use different computational approaches. particular, drcHelper implementation uses actual dose values default scoring, adds overdispersion handling Rao-Scott correction clustered data, grouping doses done automatically, uses intuitive Z-statistic. comprehensive cleaner interface dose-response studies. ’s detailed comparison:","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Verification_CA_test.html","id":"mathematical-relationship","dir":"Articles","previous_headings":"","what":"Mathematical Relationship","title":"Verification CA Test Implementation","text":"relationship two approaches: Z-statistic: \\(Z = \\frac{\\sum n_i(s_i - \\bar{s})p_i}{\\sqrt{p(1-p)\\sum n_i(s_i - \\bar{s})^2}}\\) prop.trend.test Chi-squared: \\(\\chi^2 = Z^2\\) \\(p(\\chi^2) = 2 \\times p(|Z|)\\) two-sided tests.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Verification_CA_test.html","id":"verification-example","dir":"Articles","previous_headings":"","what":"Verification Example ✅","title":"Verification CA Test Implementation","text":"","code":"# Test data successes <- c(83, 90, 129, 70) totals <- c(86, 93, 136, 82)  # R's function (default scores: 1,2,3,4) result_r <- prop.trend.test(successes, totals) result_r #>  #>  Chi-squared Test for Trend in Proportions #>  #> data:  successes out of totals , #>  using scores: 1 2 3 4 #> X-squared = 8.2249, df = 1, p-value = 0.004132 # drcHelper function (after correction, using doses = 1,2,3,4) result <- cochranArmitageTrendTest(successes, totals, doses = 1:4) result #>  #>  Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 0.965, 0.968, 0.949, 0.854 at doses 1, 2, 3, 4 #> = -2.8679, p-value = 0.004132 #> alternative hypothesis: two.sided # Should give: sqrt(result_r$statistic) ≈ abs(result_yours$statistic) sqrt(result_r$statistic) - abs(result$statistic) #>    X-squared  #> 6.217249e-15"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Verification_which_JT.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Verification: Which Jonckeere Terpstra Test to Use","text":"Jonckheere’s test Kendall’s tau) closely related. software implementations, two test produce identical p-values. JtTest npordtests cor.test method “kendall”. function actually performs kendall test treat dose column numeric. hand PMCMRplus::jonckheereTest DescTools::JonckheereTerpstraTest similar things.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Verification_which_JT.html","id":"data-from-jonckheere-1954","dir":"Articles","previous_headings":"","what":"Data from Jonckheere (1954)","title":"Verification: Which Jonckeere Terpstra Test to Use","text":"","code":"data(jdata)  prelimPlot3(jdata,dose_col = \"X\",response_col = \"Y\") dunnett_test(jdata,\"Y\",\"X\",include_random_effect = FALSE) #> Dunnett Test Results #> ------------------- #> Model type: Fixed model with homoscedastic errors  #> Control level: 1  #> Alpha level: 0.05  #>  #> Results Table: #>  comparison estimate std.error statistic   p.value  conf.low conf.high significant #>       2 - 1    15.50  34.05051 0.4552061 0.9401315 -75.78264  106.7826       FALSE #>       3 - 1    39.75  34.05051 1.1673833 0.5307511 -51.53264  131.0326       FALSE #>       4 - 1    60.25  34.05051 1.7694300 0.2322884 -31.03264  151.5326       FALSE #>  #> NOEC Determination: #> No significant effects detected at any dose. NOEC is at or above the highest tested dose. library(npordtests) res1 <- JtTest(Y~X,jdata) #> ---------------------------------------------------------  #>   Test : Jonckheere-Terpstra Test  #>   data : Y and X  #>  #>   Statistic = 71  #>   Mean = 48  #>   Variance = 114.6667  #>   Z = 2.147876  #>   Asymp. p-value = 0.0158618  #>  #>   Result : Null hypothesis is rejected.  #> --------------------------------------------------------- res1$p.value *2 #> [1] 0.03172359 res2 <- DescTools::JonckheereTerpstraTest(Y~X,jdata) res2 #>  #>  Jonckheere-Terpstra test #>  #> data:  Y by X #> JT = 71, p-value = 0.03368 #> alternative hypothesis: two.sided res2$statistic == res1$statistic #>   JT  #> TRUE res3 <- PMCMRplus::jonckheereTest(Y~X,jdata) res3$statistic=res2$statistic res3$p.value -  res2$p.value #> [1] -0.001960184 res4 <- cor.test(as.numeric(jdata$X),as.numeric(jdata$Y),method=\"kendall\") res4$statistic #>        z  #> 2.147876 res4$p.value #> [1] 0.03172359 data(lehmann) res <- JtTest(Values~Group,lehmann) #> ---------------------------------------------------------  #>   Test : Jonckheere-Terpstra Test  #>   data : Values and Group  #>  #>   Statistic = 1159  #>   Mean = 857.5  #>   Variance = 9305.917  #>   Z = 3.125415  #>   Asymp. p-value = 0.0008877709  #>  #>   Result : Null hypothesis is rejected.  #> --------------------------------------------------------- res4$p.value - 2*res1$p.value #> [1] 1.387779e-17"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/Verification_which_JT.html","id":"data-from-lehmann-1975","dir":"Articles","previous_headings":"","what":"Data from Lehmann (1975)","title":"Verification: Which Jonckeere Terpstra Test to Use","text":"","code":"data(\"lehmann\") DescTools::JonckheereTerpstraTest(Values~Group,lehmann) #>  #>  Jonckheere-Terpstra test #>  #> data:  Values by Group #> JT = 1159, p-value = 0.001776 #> alternative hypothesis: two.sided PMCMRplus::jonckheereTest(Values~Group,lehmann) #>  #>  Jonckheere-Terpstra test #>  #> data:  Values by Group #> z = 3.1337, p-value = 0.001726 #> alternative hypothesis: two.sided #> sample estimates: #>   JT  #> 1159"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/advanced_topics.html","id":"available-topics","dir":"Articles","previous_headings":"","what":"Available Topics","title":"Advanced Statistical Topics","text":"Normality Check Extra Binomial Variance Trend Test Equivalence Testing","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/alternative_methods.html","id":"available-methods","dir":"Articles","previous_headings":"","what":"Available Methods","title":"Alternative Methods","text":"NLS Approaches Using drda Package TSK Method MQJT Analysis Advanced Model Fitting","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/core_statistical_methods.html","id":"available-methods","dir":"Articles","previous_headings":"","what":"Available Methods","title":"Core Statistical Methods","text":"Quantal Data Ordinal Data Count Data Understanding Mixed Models","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"preliminary-summary","dir":"Articles","previous_headings":"","what":"Preliminary Summary","title":"drcHelper","text":"","code":"data(\"dat_medium\") dat_medium <- dat_medium %>% mutate(Treatment=factor(Dose,levels=unique(Dose)))  dat_medium$Response[dat_medium$Response < 0] <- 0 prelimPlot3(dat_medium) prelimSummary(dat_medium) %>% knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"fitting-multiple-models-and-rank-them-","dir":"Articles","previous_headings":"","what":"Fitting multiple models and rank them.","title":"drcHelper","text":"","code":"mod <- drm(Response~Dose,data=dat_medium,fct=LL.3()) fctList <- list(LN.4(),LL.4(),W1.3(),LL2.2()) # plot(mod,type=\"all\") res <- mselect.plus(mod,fctList = fctList ) modList <- res$modList res$Comparison #>          logLik        IC  Lack of fit    Res var #> LN.4  -14.65361  39.30722 6.118094e-01  0.2382532 #> LL.4  -14.94568  39.89136 5.241523e-01  0.2441232 #> LL.3  -19.24379  46.48759 6.848925e-02  0.3326394 #> W1.3  -20.46060  48.92121 3.233853e-02  0.3681387 #> LL2.2 -70.78500 147.57000 5.059273e-17 23.2867452  drcCompare(modRes=res) #>          logLik        IC  Lack of fit    Res var Certainty_Protection #> LN.4  -14.65361  39.30722 6.118094e-01  0.2382532                 High #> LL.4  -14.94568  39.89136 5.241523e-01  0.2441232                 High #> LL.3  -19.24379  46.48759 6.848925e-02  0.3326394                 High #> W1.3  -20.46060  48.92121 3.233853e-02  0.3681387               Medium #> LL2.2 -70.78500 147.57000 5.059273e-17 23.2867452                  Low #>       Steepness No Effect p-val #> LN.4     Medium               0 #> LL.4     Medium               0 #> LL.3     Medium               0 #> W1.3     Medium               0 #> LL2.2     Steep               1 library(purrr) edResTab <- mselect.ED(modList = modList,respLev = c(10,20,50),trend=\"Decrease\",CI=\"inv\") edResTab #>      .id Estimate Std. Error    Lower    Upper        NW      Rating    EC #> 1   LN.4 1.700984         NA 1.473332 1.981769 0.2989078        Good EC 10 #> 2   LN.4 2.067640         NA 1.826100 2.313691 0.2358199        Good EC 20 #> 3   LN.4 3.032169         NA 2.791669 3.273468 0.1588960   Excellent EC 50 #> 4   LL.4 1.684437         NA 1.432457 2.010475 0.3431521        Good EC 10 #> 5   LL.4 2.085759         NA 1.822344 2.363961 0.2596737        Good EC 20 #> 6   LL.4 3.037357         NA 2.775132 3.288824 0.1691246   Excellent EC 50 #> 7   LL.3 1.577783         NA 1.284085 1.961887 0.4295911        Good EC 10 #> 8   LL.3 2.019241         NA 1.705807 2.342361 0.3152440        Good EC 20 #> 9   LL.3 3.078550         NA 2.783875 3.366535 0.1892644   Excellent EC 50 #> 10  W1.3 1.588648         NA 1.208777 2.089897 0.5546347        Fair EC 10 #> 11  W1.3 2.092308         NA 1.688186 2.490045 0.3832417        Good EC 20 #> 12  W1.3 3.171490         NA 2.862468 3.435822 0.1807837   Excellent EC 50 #> 13 LL2.2       NA         NA       NA       NA        NA Not defined EC 10 #> 14 LL2.2       NA         NA       NA       NA        NA Not defined EC 20 #> 15 LL2.2       NA         NA       NA       NA        NA Not defined EC 50"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"plot-multiple-models-together","dir":"Articles","previous_headings":"","what":"Plot multiple models together","title":"drcHelper","text":"","code":"p <- plot.modList(modList[1:3]) p"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"adding-ecx-and-ecx-cis-to-the-plots","dir":"Articles","previous_headings":"","what":"Adding ECx and ECx CI’s to the plots","title":"drcHelper","text":"","code":"p1 <- plot.modList(modList[1]) addECxCI(p1,object=modList[[1]],EDres=NULL,trend=\"Decrease\",endpoint=\"EC\", respLev=c(10,20,50),                      textAjust.x=0.01,textAjust.y=0.3,useObsCtr=FALSE,d0=NULL,textsize = 4,lineheight = 0.5,xmin=0.012)+ ylab(\"Response Variable [unit]\") + xlab(\"Concentration [µg a.s./L]\") ## addECxCI(p)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"report-ecx","dir":"Articles","previous_headings":"","what":"Report ECx","title":"drcHelper","text":"Response Variable day N Calculate specific ECx:","code":"resED <- t(edResTab[1:3, c(2,4,5,6)]) colnames(resED) <- paste(\"EC\", c(10,20,50)) knitr::kable(resED,caption = \"Response Variable at day N\",digits = 3) mod <-modList[[1]] edres <- ED.plus(mod,c(5,10,20,50),trend=\"Decrease\") edres%>%knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"model-output","dir":"Articles","previous_headings":"","what":"Model Output","title":"drcHelper","text":"","code":"modsum <- summary(mod) knitr::kable(coef(modsum),digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"additional-notes","dir":"Articles","previous_headings":"","what":"Additional Notes","title":"drcHelper","text":"written","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/drcHelper.html","id":"dependencies","dir":"Articles","previous_headings":"Additional Notes","what":"Dependencies","title":"drcHelper","text":"","code":"library(drcHelper) library(DependenciesGraphs) dep <- funDependencies(\"package:drcHelper\",\"ED.plus\") plot(dep) dep <- funDependencies(\"package:drcHelper\",\"mselect.ED\") plot(dep)  #dep <- funDependencies(\"package:drcHelper\",\"mselect.plus\") #plot(dep)  dep <- envirDependencies('package:drcHelper') plot(dep)"},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/val_ED_plus.html","id":"the-root-cause","dir":"Articles","previous_headings":"Understanding EC Value Calculations in addECxCI()","what":"The Root Cause","title":"Validation ED.plus","text":"key difference addECxCI() uses ED.plus() internally, transforms response levels follow regulatory definitions ecotoxicology, drc:::ED.drc() uses raw mathematical definitions percentages. Let explain exactly ED.plus() transforms response levels:","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/val_ED_plus.html","id":"transformation-in-ed-plus-function","dir":"Articles","previous_headings":"Understanding EC Value Calculations in addECxCI()","what":"Transformation in ED.plus() Function","title":"Validation ED.plus","text":"Looking code drcHelper package, ED.plus() contains crucial transformation decreasing trends: : - d upper limit parameter (typically representing control response) - cVal lower limit parameter - respLev input response level (e.g., 10, 20, 50) transformed x.relative value passed underlying ED() function drc package.","code":"if (trend == \"Decrease\") {   x.relative <- d * respLev / (d - cVal) }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/val_ED_plus.html","id":"difference-in-interpretation","dir":"Articles","previous_headings":"Understanding EC Value Calculations in addECxCI()","what":"Difference in Interpretation","title":"Validation ED.plus","text":"50% means “halfway upper lower asymptotes” Purely mathematical definition based curve parameters 50% means “50% reduction compared control” Follows regulatory ecotoxicology definitions (e.g., OECD guidelines)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/val_ED_plus.html","id":"printing-the-transformed-values","dir":"Articles","previous_headings":"Understanding EC Value Calculations in addECxCI()","what":"Printing the Transformed Values","title":"Validation ED.plus","text":"want see exactly transformed values addECxCI() using, ’s function retrieve :","code":"show_transformed_EC_levels <- function(object, respLev, trend = \"Decrease\") {   # Get model parameters   coefs <- coef(object)   if (\"c:(Intercept)\" %in% names(coefs)) cVal <- coefs[\"c:(Intercept)\"] else cVal <- 0   if (\"d:(Intercept)\" %in% names(coefs)) d <- coefs[\"d:(Intercept)\"] else d <- 1      # Calculate the transformed values   if (trend == \"Decrease\") {     x.relative <- d * respLev / (d - cVal)   } else {     x.relative <- (respLev - cVal * 100) / (d - cVal)   }      # Return the original and transformed values   return(data.frame(     original_respLev = respLev,     transformed_x.relative = x.relative   )) }  # Use it with your model: model <- drm(Response ~ Dose, data = dat_medium, fct = LN.4()) show_transformed_EC_levels(model, c(10, 20, 50)) #>   original_respLev transformed_x.relative #> 1               10               10.73966 #> 2               20               21.47933 #> 3               50               53.69832"},{"path":"https://bayer-group.github.io/drcHelper/index.html/articles/val_ED_plus.html","id":"which-one-should-you-use","dir":"Articles","previous_headings":"Understanding EC Value Calculations in addECxCI()","what":"Which One Should You Use?","title":"Validation ED.plus","text":"Use drcHelper::ED.plus() addECxCI() need EC values comply regulatory definitions (percent reduction relative control) Use drc::ED() directly want EC values based raw percentages fitted curve range transformation intentional represents standard approach ecotoxicology “x% effect” defined x% reduction control, rather x% way minimum maximum response.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"define authors actively maintaining code base, contributors made significant contribution past. acknowledgements, see section Home Page. Zhenglei Gao. Author, maintainer. Sean Ryan. Author.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gao Z, Ryan S (2025). drcHelper: Collection verification helper functions dose-response analysis. R package version 0.0.4.9000, https://bayer-group.github.io/drcHelper/index.html.","code":"@Manual{,   title = {drcHelper: Collection and verification of helper functions for dose-response analysis},   author = {Zhenglei Gao and Sean Ryan},   year = {2025},   note = {R package version 0.0.4.9000},   url = {https://bayer-group.github.io/drcHelper/index.html}, }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"drchelper","dir":"","previous_headings":"","what":"Collection and verification of helper functions for dose-response analysis","title":"Collection and verification of helper functions for dose-response analysis","text":"goal drcHelper assist routine dose-response analysis providing collection helper functions standalone functions generic may useful beyond organization. part GLP stat pilot project, package serves cornerstone second use case, EFX Statistics. streamline GLP statistical analyses various dose-response studies test assays within registration data package. ensures analyses remain current, state---art, flexible enough adapt new regulatory requirements complying GLP standards. package also includes test cases examples help regulatory statistical community understand reasons behind different outcomes. instance, point estimations p-values may vary depending parties involved, functions used, packages selected. aims promote harmonized understanding methodologies provide foundation standardized practices regulatory statistics field plant protection product registration. Additionally, hoped project contribute ongoing OECD 54 revision process. functions adapted archived packages single functions bigger package loaded namespace big small calculations. functions included testing validation purposes. third-party code different license specified relevant source files license name relevant copyright texts. package open source, contributions improvements, especially documentation side, welcome. Please note documentation website package currently development. articles still placeholders, many way. However, ongoing development website impact usage R package.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Collection and verification of helper functions for dose-response analysis","text":"can install development version drcHelper GitHub : ","code":"# install.packages(\"devtools\") devtools::install_github(\"Bayer-Group/drcHelper\") # install.packages(\"pak\") pak::pak(\"Bayer-Group/drcHelper\")"},{"path":[]},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"preliminary-summary","dir":"","previous_headings":"","what":"Preliminary Summary","title":"Collection and verification of helper functions for dose-response analysis","text":"","code":"library(drcHelper) data(\"dat_medium\") dat_medium <- dat_medium %>% mutate(Treatment=factor(Dose,levels=unique(Dose)))  dat_medium$Response[dat_medium$Response < 0] <- 0 prelimPlot3(dat_medium) prelimSummary(dat_medium) %>% knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"fitting-multiple-models-and-rank-them","dir":"","previous_headings":"","what":"Fitting multiple models and rank them.","title":"Collection and verification of helper functions for dose-response analysis","text":"","code":"mod <- drm(Response~Dose,data=dat_medium,fct=LL.3()) fctList <- list(LN.4(),LL.4(),W1.3(),LL2.2()) # plot(mod,type=\"all\") res <- mselect.plus(mod,fctList = fctList ) modList <- res$modList res$Comparison #>          logLik        IC  Lack of fit    Res var #> LN.4  -15.45496  40.90992 5.893537e-01  0.2547068 #> LL.4  -15.69685  41.39370 5.180082e-01  0.2598931 #> LL.3  -19.24379  46.48759 6.848925e-02  0.3326394 #> W1.3  -20.55410  49.10820 4.800972e-02  0.3710183 #> LL2.2 -70.79793 147.59586 8.398391e-17 23.3118491  drcCompare(modRes=res) #>          logLik        IC  Lack of fit    Res var Certainty_Protection #> LN.4  -15.45496  40.90992 5.893537e-01  0.2547068                 High #> LL.4  -15.69685  41.39370 5.180082e-01  0.2598931                 High #> LL.3  -19.24379  46.48759 6.848925e-02  0.3326394                 High #> W1.3  -20.55410  49.10820 4.800972e-02  0.3710183               Medium #> LL2.2 -70.79793 147.59586 8.398391e-17 23.3118491                  Low #>       Steepness No Effect p-val #> LN.4     Medium               0 #> LL.4     Medium               0 #> LL.3     Medium               0 #> W1.3     Medium               0 #> LL2.2     Steep               1 library(purrr) edResTab <- mselect.ED(modList = modList,respLev = c(10,20,50),trend=\"Decrease\",CI=\"inv\") edResTab #>      .id Estimate Std. Error    Lower    Upper        NW      Rating    EC #> 1   LN.4 1.699273         NA 1.464617 1.990240 0.3093219        Good EC 10 #> 2   LN.4 2.067034         NA 1.817202 2.321445 0.2439457        Good EC 20 #> 3   LN.4 3.034117         NA 2.785528 3.283618 0.1641632   Excellent EC 50 #> 4   LL.4 1.680896         NA 1.421435 2.018155 0.3550014        Good EC 10 #> 5   LL.4 2.084252         NA 1.812372 2.371154 0.2680974        Good EC 20 #> 6   LL.4 3.040373         NA 2.770313 3.299156 0.1739402   Excellent EC 50 #> 7   LL.3 1.577783         NA 1.284085 1.961887 0.4295911        Good EC 10 #> 8   LL.3 2.019241         NA 1.705807 2.342361 0.3152440        Good EC 20 #> 9   LL.3 3.078550         NA 2.783875 3.366535 0.1892644   Excellent EC 50 #> 10  W1.3 1.588627         NA 1.207649 2.091723 0.5565024        Fair EC 10 #> 11  W1.3 2.092288         NA 1.686784 2.491398 0.3845617        Good EC 20 #> 12  W1.3 3.171479         NA 2.861093 3.436843 0.1815399   Excellent EC 50 #> 13 LL2.2       NA         NA       NA       NA        NA Not defined EC 10 #> 14 LL2.2       NA         NA       NA       NA        NA Not defined EC 20 #> 15 LL2.2       NA         NA       NA       NA        NA Not defined EC 50"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"plot-multiple-models-together","dir":"","previous_headings":"","what":"Plot multiple models together","title":"Collection and verification of helper functions for dose-response analysis","text":"","code":"p <- plot.modList(modList[1:3]) p"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"adding-ecx-and-ecx-cis-to-the-plots","dir":"","previous_headings":"","what":"Adding ECx and ECx CI’s to the plots","title":"Collection and verification of helper functions for dose-response analysis","text":"","code":"p1 <- plot.modList(modList[1]) addECxCI(p1,object=modList[[1]],EDres=NULL,trend=\"Decrease\",endpoint=\"EC\", respLev=c(10,20,50),                      textAjust.x=0.01,textAjust.y=0.3,useObsCtr=FALSE,d0=NULL,textsize = 4,lineheight = 0.5,xmin=0.012)+ ylab(\"Response Variable [unit]\") + xlab(\"Concentration [µg a.s./L]\") ## addECxCI(p)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"report-ecx","dir":"","previous_headings":"","what":"Report ECx","title":"Collection and verification of helper functions for dose-response analysis","text":"Response Variable day N Calculate specific ECx:","code":"resED <- t(edResTab[1:3, c(2,4,5,6)]) colnames(resED) <- paste(\"EC\", c(10,20,50)) knitr::kable(resED,caption = \"Response Variable at day N\",digits = 3) mod <-modList[[1]] edres <- ED.plus(mod,c(5,10,20,50),trend=\"Decrease\") edres%>%knitr::kable(.,digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"model-output","dir":"","previous_headings":"","what":"Model Output","title":"Collection and verification of helper functions for dose-response analysis","text":"","code":"modsum <- summary(mod) knitr::kable(coef(modsum),digits = 3)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"todo","dir":"","previous_headings":"","what":"ToDo","title":"Collection and verification of helper functions for dose-response analysis","text":"Develop test cases NOEC functions Prepare templates standard outputs . Update documentation.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"contribution-notes","dir":"","previous_headings":"","what":"Contribution Notes","title":"Collection and verification of helper functions for dose-response analysis","text":"Please create pull request contribute development packages. Note source branch branch currently working run gh pr create command. use pkgdown github workflow, vignettes need pre-knit pushing remote github repository extra packages needed don’s want add workflow. example given .","code":"gh pr create --title \"Title of the pull request\" --body \"Description of the pull request\" gh pr create --title \"Title of the pull request\" --body \"Description of the pull request\" --base develop knitr::knit(\"vignettes/drcHelper.Rmd.orig\", output = \"vignettes/drcHelper.Rmd\",fi)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"Collection and verification of helper functions for dose-response analysis","text":"work supported Bayer Environment Effects team members, especially Andreas Solga Daniela Jans. Mesocosm colleagues Sarah Baumert Harald Schulz supported verification validation extensive examples scripts SAS / VB validated calculations.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/DixonQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Dixon's outlier test critical Q table — DixonQ","title":"Dixon's outlier test critical Q table — DixonQ","text":"Dixon's outlier test critical Q table","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/DixonQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dixon's outlier test critical Q table — DixonQ","text":"","code":"DixonQ"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/DixonQ.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dixon's outlier test critical Q table — DixonQ","text":"object class data.frame 14 rows 2 columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/DixonQ.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dixon's outlier test critical Q table — DixonQ","text":"DIXON, W. J. (1950) Analysis extreme values. Ann. Math. Stat. 21, 488–506. DEAN, R. B., DIXON, W. J. (1951) Simplified statistics small numbers observation. Anal. Chem. 23, 636–638.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/DixonQ.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dixon's outlier test critical Q table — DixonQ","text":"Zhenglei Gao","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ECx_rating.html","id":null,"dir":"Reference","previous_headings":"","what":"Rate Effect Concentration Estimates Based on Normalized Width — ECx_rating","title":"Rate Effect Concentration Estimates Based on Normalized Width — ECx_rating","text":"Assigns qualitative ratings normalized width values confidence intervals based predefined thresholds.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ECx_rating.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rate Effect Concentration Estimates Based on Normalized Width — ECx_rating","text":"","code":"ECx_rating(x)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ECx_rating.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rate Effect Concentration Estimates Based on Normalized Width — ECx_rating","text":"x Numeric vector normalized width values rated","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ECx_rating.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rate Effect Concentration Estimates Based on Normalized Width — ECx_rating","text":"Character vector ratings following categories: \"Excellent\" NW < 0.2 \"Good\" 0.2 <= NW < 0.5 \"Fair\" 0.5 <= NW < 1 \"Poor\" 1 <= NW < 2 \"Bad\" NW >= 2 \"defined\" NA NaN values","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ECx_rating.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rate Effect Concentration Estimates Based on Normalized Width — ECx_rating","text":"","code":"# Basic examples ECx_rating(c(0.1, 0.3, 0.7, 1.5, 2.5, NA)) #> [1] \"Excellent\"   \"Good\"        \"Fair\"        \"Poor\"        \"Bad\"         #> [6] \"Not defined\"  # Example with typical normalized widths nw_values <- c(0.15, 0.45, 0.95, 1.8, 2.5) ECx_rating(nw_values) #> [1] \"Excellent\" \"Good\"      \"Fair\"      \"Poor\"      \"Bad\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ED.plus.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculating ED following the regulatory ED definition. — ED.plus","title":"Calculating ED following the regulatory ED definition. — ED.plus","text":"Calculating ED following regulatory ED definition. Deprecated helper function ED calculation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ED.plus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculating ED following the regulatory ED definition. — ED.plus","text":"","code":"# S3 method for class 'plus' ED(   object,   respLev,   maxEff = TRUE,   trend = \"Increase\",   range = \"Percentage\",   CI = c(\"delta\", \"inv\", \"bmd-inv\"),   ... )  # S3 method for class 'ZG' ED(...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ED.plus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculating ED following the regulatory ED definition. — ED.plus","text":"object fitted model using drc::drm respLev response level, x ECx. maxEff used now. maximum effect. trend Increase Decrease, whether dose response decreasing increasing compared control. range using Percentage, used now. CI methods calculate confidence intervals, either \"inv\", \"bmd-inv\",(bmd) \"delta\" \"fls\". ... parameters ED function","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ED.plus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculating ED following the regulatory ED definition. — ED.plus","text":"Back calculated regulatory ECx","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ED.plus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculating ED following the regulatory ED definition. — ED.plus","text":"Due old ECxHelper development ED.plus defined ED.ZG","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/ED.plus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculating ED following the regulatory ED definition. — ED.plus","text":"","code":"if (FALSE) { # \\dontrun{ data(\"dat_medium\") dat_medium <- dat_medium %>% mutate(Treatment=factor(Dose,levels=unique(Dose))) dat_medium$Response[dat_medium$Response < 0] <- 0 mod <- drm(Response~Dose,data=dat_medium,fct=LL.3()) fctList <- list(LN.4(),LL.4(),W1.3(),LL2.2()) res <- mselect.plus(mod,fctList = fctList ) modList <- res$modList mod <-modList[[1]] edres <- ED.plus(mod,c(10,50),trend=\"Decrease\") } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTA_Ar_ext_mortality_expected.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected outcome of pre-processing NTA_Ar_ext mortality — NTA_Ar_ext_mortality_expected","title":"Expected outcome of pre-processing NTA_Ar_ext mortality — NTA_Ar_ext_mortality_expected","text":"Expected outcome pre-processing NTA_Ar_ext mortality","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTA_Ar_ext_mortality_expected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected outcome of pre-processing NTA_Ar_ext mortality — NTA_Ar_ext_mortality_expected","text":"","code":"NTA_Ar_ext_mortality_expected"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTA_Ar_ext_mortality_expected.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Expected outcome of pre-processing NTA_Ar_ext mortality — NTA_Ar_ext_mortality_expected","text":"object class grouped_df (inherits tbl_df, tbl, data.frame) 7 rows 7 columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example.html","id":null,"dir":"Reference","previous_headings":"","what":"NTP_example data — NTP_example","title":"NTP_example data — NTP_example","text":"NTP_example data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NTP_example data — NTP_example","text":"","code":"NTP_example"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NTP_example data — NTP_example","text":"NTP example data corrected uncorrected emergence, survival, reduction.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected processed data from the NTP_example — NTP_example_rate","title":"Expected processed data from the NTP_example — NTP_example_rate","text":"Expected processed data NTP_example","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected processed data from the NTP_example — NTP_example_rate","text":"","code":"NTP_example_rate"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example_rate.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Expected processed data from the NTP_example — NTP_example_rate","text":"NTP example rate data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example_rate_expected.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected outcome of NTP — NTP_example_rate_expected","title":"Expected outcome of NTP — NTP_example_rate_expected","text":"Expected outcome NTP","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example_rate_expected.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected outcome of NTP — NTP_example_rate_expected","text":"","code":"NTP_example_rate_expected"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/NTP_example_rate_expected.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Expected outcome of NTP — NTP_example_rate_expected","text":"object class tbl_df (inherits tbl, data.frame) 8 rows 8 columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/RSCABK.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs the kth slice of RSCABS — RSCABK","title":"Runs the kth slice of RSCABS — RSCABK","text":"Runs kth slice RSCABS","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/RSCABK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs the kth slice of RSCABS — RSCABK","text":"","code":"RSCABK(x.i.j, n.i.j, m.i, TestK, test.type)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/RSCABK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs the kth slice of RSCABS — RSCABK","text":"x..j matrix containing number observed \"successes\" replicate treatment j. n..j matrix containing number observations replicate treatment j. m.matrix number units treatment/replicate combination. TestK kth severity score tested. test.type Indicate type  analysis performed. Use \"RS\" select Rao-Scott adjustment Cochran-Armitage test \"CA\" ignore adjustment.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/RSCABK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs the kth slice of RSCABS — RSCABK","text":"Returns list following values: Response endpoint tested. Treatment treatment level. R-Score severity score histology. Statistic test statistic corresponding row's endpoint treatment level R-Score. P-Value corresponding p-value Signif significance flag cutoffs stars dot 0, 1e-04, 0.001, 0.01,0.05,1.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/RSCABK.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Runs the kth slice of RSCABS — RSCABK","text":"Joe Swintek","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Tarone's Z Test — Tarone.test","title":"Tarone's Z Test — Tarone.test","text":"Tests goodness fit binomial distribution.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tarone's Z Test — Tarone.test","text":"","code":"Tarone.test(N, M)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tarone's Z Test — Tarone.test","text":"N Trials M Counts","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tarone's Z Test — Tarone.test","text":"htest object","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tarone's Z Test — Tarone.test","text":"https://stats.stackexchange.com//410376/6378 R. E. TARONE, Testing goodness fit binomial distribution, Biometrika, Volume 66, Issue 3, December 1979, Pages 585–590, https://doi.org/10.1093/biomet/66.3.585","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Tarone's Z Test — Tarone.test","text":"Ben O'Neill","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tarone's Z Test — Tarone.test","text":"","code":"#Generate example data N <- c(30, 32, 40, 28, 29, 35, 30, 34, 31, 39) M <- c( 9, 10, 22, 15,  8, 19, 16, 19, 15, 10) Tarone.test(N, M) #>  #> \tTarone's Z test #>  #> data:  M successes from N trials #> z = 2.5988, p-value = 0.009355 #> alternative hypothesis: true dispersion parameter is greater than 0 #> sample estimates: #> proportion parameter  #>            0.4359756  #>"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.trend.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Tarone's test for overdispersion accounting for trend — Tarone.trend.test","title":"Tarone's test for overdispersion accounting for trend — Tarone.trend.test","text":"Tarone's test overdispersion accounting trend","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.trend.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tarone's test for overdispersion accounting for trend — Tarone.trend.test","text":"","code":"Tarone.trend.test(   successes,   totals,   doses,   scoring = c(\"doses\", \"ranks\", \"log_doses\", \"equal_spaced\"),   include_groupwise_tarone = TRUE )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.trend.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tarone's test for overdispersion accounting for trend — Tarone.trend.test","text":"successes Vector success counts totals Vector total trials doses Vector dose levels scoring Method defining trend: \"doses\", \"ranks\", \"log_doses\", \"equal_spaced\" include_groupwise_tarone Logical, whether include groupwise Tarone tests","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/Tarone.trend.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tarone's test for overdispersion accounting for trend — Tarone.trend.test","text":"List containing test results","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/addECxCI.html","id":null,"dir":"Reference","previous_headings":"","what":"adding ECx estimation and interval to the model output plot — addECxCI","title":"adding ECx estimation and interval to the model output plot — addECxCI","text":"adding ECx estimation interval model output plot","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/addECxCI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"adding ECx estimation and interval to the model output plot — addECxCI","text":"","code":"addECxCI(   p = NULL,   object,   EDres = NULL,   trend = \"Decrease\",   endpoint = \"ErC\",   respLev = c(10, 20, 50),   textAjust.x = 0.1,   textAjust.y = 0.05,   useObsCtr = FALSE,   d0 = NULL,   textsize = 2,   lineheight = 1,   xmin = 0.05,   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/addECxCI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"adding ECx estimation and interval to the model output plot — addECxCI","text":"p model plot ggplot2 output object fitted drc object EDres EDresults corresponding respLev trend \"Decrease\" \"Increase\" endpoint ErC EbC EyC EC LD respLev reponse levels textAjust.x label ECx textAjust.y label ECx useObsCtr whether use observed control mean d0 used control mean. textsize label text size lineheight errorbar height xmin confidence intervals wide including even negative values. ... additional inputs passed ED functions.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/addECxCI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"adding ECx estimation and interval to the model output plot — addECxCI","text":"ggplot object added ECx CIs.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/addECxCI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"adding ECx estimation and interval to the model output plot — addECxCI","text":"","code":"if (FALSE) { # \\dontrun{ data(\"dat_medium\") dat_medium <- dat_medium %>% mutate(Treatment=factor(Dose,levels=unique(Dose))) dat_medium$Response[dat_medium$Response < 0] <- 0 mod <- drm(Response~Dose,data=dat_medium,fct=LN.4()) p1 <- plot.modList(list(mod)) addECxCI(p1,object=mod,EDres=NULL,trend=\"Decrease\",endpoint=\"EC\", respLev=c(10,20,50), textAjust.x=0.01,textAjust.y=0.3,useObsCtr=FALSE,d0=NULL,textsize = 4,lineheight = 0.5,xmin=0.012)+ ylab(\"Response Variable [unit]\") + xlab(\"Concentration [µg a.s./L]\") } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_simple.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate Individual Fish Records to Summarized Format (simple without tidyverse version) — aggregate_from_individual_simple","title":"Aggregate Individual Fish Records to Summarized Format (simple without tidyverse version) — aggregate_from_individual_simple","text":"Aggregate Individual Fish Records Summarized Format (simple without tidyverse version)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_simple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate Individual Fish Records to Summarized Format (simple without tidyverse version) — aggregate_from_individual_simple","text":"","code":"aggregate_from_individual_simple(   data,   treatment_col = \"tmt\",   replicate_col = \"tank\",   score_col = \"score\",   total_col = \"total\",   all_scores = NULL )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_simple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate Individual Fish Records to Summarized Format (simple without tidyverse version) — aggregate_from_individual_simple","text":"data data frame containing individual fish records treatment_col Name column containing treatment groups (default: \"tmt\") replicate_col Name column containing tank/replicate IDs (default: \"tank\") score_col Name column containing scores (default: \"score\") total_col Name column created total counts (default: \"total\") all_scores Optional vector score categories include result, even zero occurrences (default: NULL, uses unique values data)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_simple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate Individual Fish Records to Summarized Format (simple without tidyverse version) — aggregate_from_individual_simple","text":"data frame aggregated counts per replicate","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate Individual Fish Records to Summarized Format (tidyverse version) — aggregate_from_individual_tidy","title":"Aggregate Individual Fish Records to Summarized Format (tidyverse version) — aggregate_from_individual_tidy","text":"Aggregate Individual Fish Records Summarized Format (tidyverse version)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate Individual Fish Records to Summarized Format (tidyverse version) — aggregate_from_individual_tidy","text":"","code":"aggregate_from_individual_tidy(   data,   treatment_col = \"tmt\",   replicate_col = \"tank\",   score_col = \"score\",   total_col = \"total\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate Individual Fish Records to Summarized Format (tidyverse version) — aggregate_from_individual_tidy","text":"data data frame containing individual fish records treatment_col Name column containing treatment groups (default: \"tmt\") replicate_col Name column containing tank/replicate IDs (default: \"tank\") score_col Name column containing scores (default: \"score\") total_col Name column created total counts (default: \"total\")","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/aggregate_from_individual_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate Individual Fish Records to Summarized Format (tidyverse version) — aggregate_from_individual_tidy","text":"data frame aggregated counts per replicate","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/backCalcSE.html","id":null,"dir":"Reference","previous_headings":"","what":"Back Calculate Standard Error from Lognormal Parameters — backCalcSE","title":"Back Calculate Standard Error from Lognormal Parameters — backCalcSE","text":"function calculates standard error (SE) lognormally distributed variable based mean (mu) standard error logarithm (se).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/backCalcSE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Back Calculate Standard Error from Lognormal Parameters — backCalcSE","text":"","code":"backCalcSE(se, mu, approximate = FALSE)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/backCalcSE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Back Calculate Standard Error from Lognormal Parameters — backCalcSE","text":"se standard error logarithm. mu mean logarithm. approximate Logical. TRUE, uses approximation; otherwise, calculates based variance lognormal distribution.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/backCalcSE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Back Calculate Standard Error from Lognormal Parameters — backCalcSE","text":"back-calculated standard error.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/backCalcSE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Back Calculate Standard Error from Lognormal Parameters — backCalcSE","text":"","code":"backCalcSE(se = 0.1, mu = 0) #> [1] 0.100753 backCalcSE(se = 0.1, mu = 0, approximate = TRUE) #> [1] 0.1"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_dunnett.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize Dunnett Test Results — broom_dunnett","title":"Standardize Dunnett Test Results — broom_dunnett","text":"function creates standardized output different Dunnett test implementations.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_dunnett.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize Dunnett Test Results — broom_dunnett","text":"","code":"broom_dunnett(   x,   method = c(\"Dunnett_multcomp\", \"Dunnett_DescTools\", \"Dunnett_PMCMRplus\"),   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_dunnett.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize Dunnett Test Results — broom_dunnett","text":"x formula object specifying response variable factor test performed, object class 'aov' 'lm'. method Character string specifying implementation Dunnett test use: \"Dunnett_multcomp\" (default) multcomp implementation, \"Dunnett_DescTools\" DescTools implementation, \"Dunnett_PMCMRplus\" PMCMRplus implementation, use one general return complete information. ... Additional arguments passed underlying test functions.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_dunnett.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize Dunnett Test Results — broom_dunnett","text":"data frame standardized test results containing: comparison comparison made estimate estimated difference groups p.value p-value test conf.low Lower bound confidence interval conf.high Upper bound confidence interval method method used test","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_williams.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize Williams Test Results — broom_williams","title":"Standardize Williams Test Results — broom_williams","text":"function creates standardized output different Williams test implementations.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_williams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize Williams Test Results — broom_williams","text":"","code":"broom_williams(x, method = c(\"Williams_PMCMRplus\", \"Williams_JG\"), ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_williams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize Williams Test Results — broom_williams","text":"x formula object specifying response variable factor test performed, object class 'aov' 'lm'. method Character string specifying implementation Williams test use: \"Williams_PMCMRplus\" (default) PMCMRplus implementation \"Williams_JG\" drcHelper custom implementation. ... Additional arguments passed underlying test functions.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_williams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize Williams Test Results — broom_williams","text":"data frame standardized test results containing: comparison comparison made estimate estimated difference groups p.value p-value test conf.low Lower bound confidence interval conf.high Upper bound confidence interval method method used test","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/broom_williams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize Williams Test Results — broom_williams","text":"","code":"# Create example data set.seed(123) test_data <- data.frame(   dose = factor(rep(c(0, 1, 5, 10), each = 5)),   response = c(rnorm(5, 100, 10), rnorm(5, 90, 10),                rnorm(5, 80, 10), rnorm(5, 70, 10)) )  # Apply Williams test result <- broom_williams(response ~ dose, data = test_data) print(result) #> # A tibble: 3 × 6 #>   comparison   estimate `t'-stat` `t'-crit` decision method             #>   <chr>           <dbl>     <dbl>     <dbl> <chr>    <chr>              #> 1 1 - 0  <= 0     -12.4     -1.86      1.75 accept   Williams_PMCMRplus #> 2 5 - 0  <= 0     -18.9     -2.84      1.83 accept   Williams_PMCMRplus #> 3 10 - 0  <= 0    -30.8     -4.64      1.86 accept   Williams_PMCMRplus"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcNW.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Normalized Width for Effect Concentration Estimates — calcNW","title":"Calculate Normalized Width for Effect Concentration Estimates — calcNW","text":"Calculates normalized width confidence intervals effect concentration (EC) estimates dividing interval width estimate value. Also provides rating calculated normalized width.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcNW.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Normalized Width for Effect Concentration Estimates — calcNW","text":"","code":"calcNW(x, ED = \"ZG\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcNW.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Normalized Width for Effect Concentration Estimates — calcNW","text":"x data frame containing EC estimates, typically output ED function. Must contain columns 'Upper', 'Lower', 'Estimate'. ED Character string indicating source EC estimates. Must either \"ZG\" (default) \"drc\".","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcNW.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Normalized Width for Effect Concentration Estimates — calcNW","text":"data frame two columns: NW: Normalized width calculated (Upper - Lower) / Estimate Rating: Categorical rating normalized width Row names preserved input \"ZG\" modified \"EC_x\" format \"drc\".","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcNW.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Normalized Width for Effect Concentration Estimates — calcNW","text":"","code":"# Example with ZG format ec_data <- data.frame(   Lower = c(1.2, 2.3),   Upper = c(1.8, 3.1),   Estimate = c(1.5, 2.7),   row.names = c(\"EC10\", \"EC50\") ) calcNW(ec_data, ED = \"ZG\") #>             NW Rating #> EC10 0.4000000   Good #> EC50 0.2962963   Good  # Example with drc format drc_data <- data.frame(   Lower = c(1.2, 2.3),   Upper = c(1.8, 3.1),   Estimate = c(1.5, 2.7),   row.names = c(\"Dose:1:10\", \"Dose:1:50\") ) calcNW(drc_data, ED = \"drc\") #>              NW Rating #> EC_10 0.4000000   Good #> EC_50 0.2962963   Good"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcSteepnessOverlap.html","id":null,"dir":"Reference","previous_headings":"","what":"Steepness and overlap calcuation — calcSteepnessOverlap","title":"Steepness and overlap calcuation — calcSteepnessOverlap","text":"Steepness overlap calcuation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcSteepnessOverlap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Steepness and overlap calcuation — calcSteepnessOverlap","text":"","code":"calcSteepnessOverlap(   mod = NULL,   obj = NULL,   trend = \"Decrease\",   CI = \"inv\",   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcSteepnessOverlap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Steepness and overlap calcuation — calcSteepnessOverlap","text":"mod fitted object drm model fitting obj Calculated ED 10, 20, 50 object available. mod set NULL case trend \"Decrease\" \"Increase\" CI method calculate CI, either \"inv\" (bmd) \"delta\" \"fls\". ... parameters passed ED.plus","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcSteepnessOverlap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Steepness and overlap calcuation — calcSteepnessOverlap","text":"table certainty potection level steepness models","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcSteepnessOverlap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Steepness and overlap calcuation — calcSteepnessOverlap","text":"","code":"if (FALSE) { # \\dontrun{  datTn<- subset(oecd201,Time==72)  mod <- drm(Yield~Concentration,data=datTn,fct=LL.3())  calcSteepnessOverlap(mod = mod, trend = \"Decrease\") } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcTaronesTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Tarones test for Stratified OR (ClinStats version) — calcTaronesTest","title":"Tarones test for Stratified OR (ClinStats version) — calcTaronesTest","text":"calcTaronesTest used test whether different strata different. integrated https://github.com/the8thday/ClinStats/blob/master/R/Tarones.R). original MIT license included source code. function included validation purpose. Please use updated function ClinStats package related calculation non-GLP environment.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcTaronesTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tarones test for Stratified OR (ClinStats version) — calcTaronesTest","text":"","code":"calcTaronesTest(mylist, referencerow = 2)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcTaronesTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tarones test for Stratified OR (ClinStats version) — calcTaronesTest","text":"mylist list matrix Stratified Variable referencerow Unexposed row","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcTaronesTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tarones test for Stratified OR (ClinStats version) — calcTaronesTest","text":"string list p-values","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcTaronesTest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tarones test for Stratified OR (ClinStats version) — calcTaronesTest","text":"modified output return p-values, need metafor package run. function really used GLP calculations designed ecotox studies usually one control included. However, useful refinement analyses.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calcTaronesTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tarones test for Stratified OR (ClinStats version) — calcTaronesTest","text":"","code":"mymatrix1 <- matrix(c(4,5,5,103),nrow=2,byrow=TRUE) colnames(mymatrix1) <- c(\"Disease\",\"Control\") rownames(mymatrix1) <- c(\"Exposure\",\"Unexposed\") mymatrix2 <- matrix(c(10,3,5,43),nrow=2,byrow=TRUE) colnames(mymatrix2) <- c(\"Disease\",\"Control\") rownames(mymatrix2) <- c(\"Exposure\",\"Unexposed\") mylist <- list(mymatrix1,mymatrix2) calcTaronesTest(mylist) #> [1] \"Pvalue for Tarone's test = 0.627420741721689\" #> $pval #> [1] 0.6274207 #>  #> $tarone #>  #> Equal-Effects Model (k = 2) #>  #> I^2 (total heterogeneity / total variability):  0.00% #> H^2 (total variability / sampling variability): 0.24 #>  #> Test for Heterogeneity:  #> Q(df = 1) = 0.2423, p-val = 0.6225 #>  #> Model Results (log scale): #>  #> estimate      se    zval    pval   ci.lb   ci.ub  #>   3.1355  0.5741  5.4613  <.0001  2.0102  4.2608  #>  #> Model Results (OR scale): #>  #> estimate   ci.lb    ci.ub  #>  23.0006  7.4652  70.8663  #>  #> Cochran-Mantel-Haenszel Test:    CMH = 36.6043, df = 1, p-val < 0.0001 #> Tarone's Test for Heterogeneity: X^2 =  0.2356, df = 1, p-val = 0.6274 #>  #>  if (FALSE) { # \\dontrun{ calcTaronesTest(mymatrix1) } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calculate_noec_rstatix.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate NOEC Using Many-to-one Pairwise Tests — calculate_noec_rstatix","title":"Calculate NOEC Using Many-to-one Pairwise Tests — calculate_noec_rstatix","text":"function calculates Observed Effect Concentration (NOEC) dose response data using pairwise comparison tests rstatix package.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calculate_noec_rstatix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate NOEC Using Many-to-one Pairwise Tests — calculate_noec_rstatix","text":"","code":"calculate_noec_rstatix(   data,   response,   dose,   control = \"0\",   test = c(\"t.test\", \"wilcox.test\"),   p_adjust_method = \"holm\",   alternative = \"two.sided\",   alpha = 0.05 )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calculate_noec_rstatix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate NOEC Using Many-to-one Pairwise Tests — calculate_noec_rstatix","text":"data data frame containing dose response data response name response variable (unquoted) dose name dose variable (unquoted) control level dose variable used control test statistical test use: \"t.test\" \"wilcox.test\" p_adjust_method Method p-value adjustment multiple comparisons alternative Direction alternative hypothesis: \"two.sided\", \"greater\", \"less\" alpha Significance level (default: 0.05)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calculate_noec_rstatix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate NOEC Using Many-to-one Pairwise Tests — calculate_noec_rstatix","text":"list containing NOEC value full test results","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calpha.test.html","id":null,"dir":"Reference","previous_headings":"","what":"C(alpha) test from the epiphy package. — calpha.test","title":"C(alpha) test from the epiphy package. — calpha.test","text":"C(alpha) test test binomial distribution alternative beta-binomial distribution. Note exported package namespace kept internal. license MIT COPYRIGHT HOLDER: Christophe Gigot YEAR: 2023 (included source code). function included validation purpose. Please use epiphy package related calculation non-GLP environment.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calpha.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"C(alpha) test from the epiphy package. — calpha.test","text":"","code":"calpha.test(x, ...)  # S3 method for class 'fisher' calpha.test(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calpha.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"C(alpha) test from the epiphy package. — calpha.test","text":"x output agg_index function method = \"fisher\" parameter. ... yet implemented.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calpha.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"C(alpha) test from the epiphy package. — calpha.test","text":"kind object one returns stats chisq.test function example.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calpha.test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"C(alpha) test from the epiphy package. — calpha.test","text":"based calculation test statistic, z, asymptotic standard normal distribution null hypothesis. one-sided (way alternative aggregation, just \"non-randomness\"), thus confidence level 95%, null hypothesis rejected z > 1.64. sampling units contain total number individuals, n, test statistic calculated : z = (n(N - 1)- Nn)/(2Nn(n - 1))^(1/2) N number sampling units, , Fisher's index aggregation incidence data.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calpha.test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"C(alpha) test from the epiphy package. — calpha.test","text":"Neyman J. 1959. Optimal asymptotic tests composite statistical hypotheses. : Probability Statistics, 213-234. Wiley, New York. Tarone RE. 1979. Testing goodness fit binomial distribution. Biometrika, 66(3): 585-590.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/calpha.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"C(alpha) test from the epiphy package. — calpha.test","text":"","code":"# For incidence data: # my_incidence <- epiphy::incidence(epiphy::tobacco_viruses) # my_fisher <- epiphy::agg_index(my_incidence, method = \"fisher\") my_fisher <- structure(list(index = 3.14396182555326, name = \"Fisher's index of dispersion\", flavor = \"incidence\", N = 75L, n = 40L), class = c(\"fisher\", \"agg_index\")) drcHelper:::calpha.test(my_fisher) #>  #> \tC(alpha) test #>  #> data:  my_fisher #> z = 13.036, p-value < 2.2e-16 #>"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/cochranArmitageTrendTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Cochran-Armitage Trend Test for Binomial Data — cochranArmitageTrendTest","title":"Cochran-Armitage Trend Test for Binomial Data — cochranArmitageTrendTest","text":"Performs Cochran-Armitage test trend binomial proportions across ordered groups, optional Rao-Scott correction overdispersion.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/cochranArmitageTrendTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cochran-Armitage Trend Test for Binomial Data — cochranArmitageTrendTest","text":"","code":"cochranArmitageTrendTest(   successes,   totals,   doses,   scoring = c(\"doses\", \"ranks\", \"log_doses\", \"equal_spaced\"),   alternative = c(\"two.sided\", \"greater\", \"less\"),   rao_scott = FALSE,   phi = NULL,   phi_method = c(\"simple\", \"trend_adjusted\") )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/cochranArmitageTrendTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cochran-Armitage Trend Test for Binomial Data — cochranArmitageTrendTest","text":"successes Numeric vector successes (e.g., number survivors). totals Numeric vector total observations (e.g., total organisms). doses Numeric vector dose levels scores corresponding observation. scoring Method defining trend alternative Character string specifying alternative hypothesis. Must one \"two.sided\" (default), \"greater\", \"less\". rao_scott Logical indicating whether apply Rao-Scott correction overdispersion (default: FALSE). phi Overdispersion parameter Rao-Scott correction. NULL (default), estimated data. phi_method simple without trend adjustment trend_adjusted.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/cochranArmitageTrendTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cochran-Armitage Trend Test for Binomial Data — cochranArmitageTrendTest","text":"list containing: statistic Test statistic (Z score) p.value P-value test method Description test performed alternative alternative hypothesis data.name Description data phi Overdispersion parameter (rao_scott = TRUE)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/cochranArmitageTrendTest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cochran-Armitage Trend Test for Binomial Data — cochranArmitageTrendTest","text":"Cochran-Armitage test used detect trends binomial proportions across ordered groups. test statistic follows standard normal distribution null hypothesis trend. rao_scott = TRUE, function applies correction overdispersion, often present clustered binomial data. correction divides test statistic square root estimated dispersion parameter.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/cochranArmitageTrendTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cochran-Armitage Trend Test for Binomial Data — cochranArmitageTrendTest","text":"","code":"# Example with simulated data successes <- c(20, 18, 15, 10, 5) totals <- rep(20, 5) doses <- c(0, 1, 2, 5, 10)  # Standard Cochran-Armitage test result <- cochranArmitageTrendTest(successes, totals, doses) print(result) #>  #> \tCochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 1, 0.9, 0.75, 0.5, 0.25 at doses 0, 1, 2, 5, 10 #> = -5.7465, p-value = 9.108e-09 #> alternative hypothesis: two.sided #>   # With Rao-Scott correction result_rs <- cochranArmitageTrendTest(successes, totals, doses, rao_scott = TRUE) #> Estimated phi = 8.571 using simple method with doses scoring print(result_rs) #>  #> \tRao-Scott corrected Cochran-Armitage test for trend (doses scoring) #>  #> data:  proportions 1, 0.9, 0.75, 0.5, 0.25 at doses 0, 1, 2, 5, 10 #> = -1.9629, p-value = 0.04966 #> alternative hypothesis: two.sided #>"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/collembola_juveniles.html","id":null,"dir":"Reference","previous_headings":"","what":"Fake data from collembola juveniles — collembola_juveniles","title":"Fake data from collembola juveniles — collembola_juveniles","text":"Fake data collembola juveniles","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/collembola_juveniles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fake data from collembola juveniles — collembola_juveniles","text":"","code":"collembola_juveniles"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/collembola_juveniles.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fake data from collembola juveniles — collembola_juveniles","text":"collembola_juveniles wide format","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_phi_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare phi estimation methods (FIXED) — compare_phi_methods","title":"Compare phi estimation methods (FIXED) — compare_phi_methods","text":"Compare phi estimation methods (FIXED)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_phi_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare phi estimation methods (FIXED) — compare_phi_methods","text":"","code":"compare_phi_methods(successes, totals, doses, scoring = \"doses\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_phi_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare phi estimation methods (FIXED) — compare_phi_methods","text":"successes Vector success counts totals Vector total trials doses Vector dose levels scoring Scoring method","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_tarone_scoring.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Tarone trend tests across different scoring methods — compare_tarone_scoring","title":"Compare Tarone trend tests across different scoring methods — compare_tarone_scoring","text":"Compare Tarone trend tests across different scoring methods","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_tarone_scoring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Tarone trend tests across different scoring methods — compare_tarone_scoring","text":"","code":"compare_tarone_scoring(   successes,   totals,   doses,   scoring_methods = c(\"doses\", \"ranks\", \"log_doses\", \"equal_spaced\") )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_tarone_scoring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Tarone trend tests across different scoring methods — compare_tarone_scoring","text":"successes Vector success counts totals Vector total trials doses Vector dose levels scoring_methods Vector scoring methods compare","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_tarone_scoring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Tarone trend tests across different scoring methods — compare_tarone_scoring","text":"List results comparison table","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_to_control_fisher.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Fisher's Exact Test Comparing Each Level to Control — compare_to_control_fisher","title":"Perform Fisher's Exact Test Comparing Each Level to Control — compare_to_control_fisher","text":"function performs Fisher's exact test comparing level factor control level, using counts success failure.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_to_control_fisher.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Fisher's Exact Test Comparing Each Level to Control — compare_to_control_fisher","text":"","code":"compare_to_control_fisher(   data,   factor_col,   success_col,   failure_col,   control_level = NULL,   alternative = \"two.sided\",   conf.level = 0.95,   p.adjust.method = \"holm\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_to_control_fisher.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Fisher's Exact Test Comparing Each Level to Control — compare_to_control_fisher","text":"data data frame containing data factor_col String name column containing factor (e.g., \"dose\") success_col String name column containing success counts (e.g., \"alive\") failure_col String name column containing failure counts (e.g., \"dead\") control_level level use control (default: first level data) alternative Direction alternative hypothesis (\"two.sided\", \"less\", \"greater\") conf.level Confidence level returned confidence interval p.adjust.method p-value adjustment method, passing stats function.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_to_control_fisher.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Fisher's Exact Test Comparing Each Level to Control — compare_to_control_fisher","text":"data frame factor levels corresponding p-values","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/compare_to_control_fisher.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Fisher's Exact Test Comparing Each Level to Control — compare_to_control_fisher","text":"","code":"# Generate example data set.seed(123) doses <- c(0, 0.1, 1, 10, 50, 100) reps <- 4 data <- data.frame(   dose = rep(doses, each = reps),   replicate = rep(1:reps, times = length(doses)) ) data$alive <- sapply(data$dose, function(x) rbinom(1, 10, prob = exp(-0.02 * x))) data$dead <- 10 - data$alive  # Run Fisher's exact test compare_to_control_fisher(data, \"dose\", \"alive\", \"dead\", control_level = 0) #>    dose p_value odds_ratio ci_lower ci_upper p_adjusted #> 1   0.1  1.0000          0   0.0000      Inf     1.0000 #> 2   1.0  0.4937        Inf   0.1886      Inf     0.9873 #> 3  10.0  0.0010        Inf   2.6809      Inf     0.0031 #> 4  50.0  0.0000        Inf  12.5317      Inf     0.0000 #> 5 100.0  0.0000        Inf  47.0319      Inf     0.0000"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/complete_trend_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform complete overdispersion and trend analysis (CORRECTED) — complete_trend_analysis","title":"Perform complete overdispersion and trend analysis (CORRECTED) — complete_trend_analysis","text":"Perform complete overdispersion trend analysis (CORRECTED)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/complete_trend_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform complete overdispersion and trend analysis (CORRECTED) — complete_trend_analysis","text":"","code":"complete_trend_analysis(   successes,   totals,   doses,   scoring = c(\"doses\", \"ranks\", \"log_doses\", \"equal_spaced\"),   alternative = c(\"two.sided\", \"greater\", \"less\"),   phi_method = c(\"trend_adjusted\", \"simple\") )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/complete_trend_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform complete overdispersion and trend analysis (CORRECTED) — complete_trend_analysis","text":"successes Vector success counts totals Vector total trials doses Vector dose levels scoring Scoring method use consistently alternative Direction trend test phi_method Method phi estimation using Rao-Scott","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/complete_trend_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform complete overdispersion and trend analysis (CORRECTED) — complete_trend_analysis","text":"List Tarone step-results","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/comprehensive_phi_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare phi estimates across different scoring methods and estimation methods — comprehensive_phi_comparison","title":"Compare phi estimates across different scoring methods and estimation methods — comprehensive_phi_comparison","text":"Compare phi estimates across different scoring methods estimation methods","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/comprehensive_phi_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare phi estimates across different scoring methods and estimation methods — comprehensive_phi_comparison","text":"","code":"comprehensive_phi_comparison(successes, totals, doses)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/comprehensive_phi_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare phi estimates across different scoring methods and estimation methods — comprehensive_phi_comparison","text":"successes Vector success counts totals Vector total trials doses Vector dose levels","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/contEndpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"get Endpoint for continuous data according to results of a series of tests — contEndpoint","title":"get Endpoint for continuous data according to results of a series of tests — contEndpoint","text":"get Endpoint continuous data according results series tests","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/contEndpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get Endpoint for continuous data according to results of a series of tests — contEndpoint","text":"","code":"contEndpoint(   paov,   pks,   pnormal,   phomogeneity,   monotonicity,   william,   dunnett,   dunn,   jonckheere,   procedure = \"stepDown\",   doses = c(\"A\", \"B\", \"C\", \"D\") )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/contEndpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get Endpoint for continuous data according to results of a series of tests — contEndpoint","text":"paov Anova p-value pks Kolmogorov-Smirnov test p-value pnormal Normal test p-value phomogeneity Homogeneity variance test p-value monotonicity Monotonicity test p-value william Williams' test p-value dunnett Dunnett's test p-value dunn Dunn's test p-value jonckheere Jonckheere-Tepstra test p-value procedure step doses tested doses","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/contEndpoint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get Endpoint for continuous data according to results of a series of tests — contEndpoint","text":"NOEC along attribute indicating test used.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/contEndpoint.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"get Endpoint for continuous data according to results of a series of tests — contEndpoint","text":"Purpose: contEndpoint function computes Observed Effect Concentration (NOEC) based results various statistical tests. evaluates tests' p-values determine statistical analysis appropriate.function first checks significance monotonicity test. Depending results, selects appropriate p-value relevant test (Dunnett, Dunn, Williams, Jonckheere) compute NOEC. function returns NOEC along attribute indicating test used. Original function used directly williams' test dunnett's test objects input, can cause conflicts using different functions get pvals.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/contEndpoint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get Endpoint for continuous data according to results of a series of tests — contEndpoint","text":"","code":"contEndpoint(paov = 0.01, pks = 0.03, pnormal = 0.06, phomogeneity = 0.07, monotonicity = c(0.1,0.2), william = c(0.07, 0.06, 0.03, 0.01), dunnett = c(0.07, 0.06, 0.03, 0.01), dunn = c(0.07, 0.06, 0.03, 0.01), jonckheere = c(0.07, 0.06, 0.03, 0.01), procedure = \"stepDown\", doses = c(\"Control\",\"A\", \"B\", \"C\", \"D\")) #> [1] \"B\" #> attr(,\"test\") #> [1] \"Williams\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert2Score.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Values to Scores — convert2Score","title":"Convert Values to Scores — convert2Score","text":"Converts non-positive numbers NA.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert2Score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Values to Scores — convert2Score","text":"","code":"convert2Score(Dvec)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert2Score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Values to Scores — convert2Score","text":"Dvec numeric vector converted.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert2Score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Values to Scores — convert2Score","text":"numeric vector non-positive values set NA.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert_fish_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Between Aggregated and Individual Fish Data — convert_fish_data","title":"Convert Between Aggregated and Individual Fish Data — convert_fish_data","text":"function provides complete workflow converting aggregated fish data individual fish records, ensuring score categories preserved.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert_fish_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Between Aggregated and Individual Fish Data — convert_fish_data","text":"","code":"convert_fish_data(   data,   direction,   treatment_col = \"tmt\",   replicate_col = \"tank\",   score_prefix = \"S\",   score_col = \"score\",   total_col = \"total\",   all_scores = NULL )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert_fish_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Between Aggregated and Individual Fish Data — convert_fish_data","text":"data data frame containing either aggregated individual fish data direction Either \"to_individual\" \"to_aggregated\" treatment_col Name column containing treatment groups (default: \"tmt\") replicate_col Name column containing tank/replicate IDs (default: \"tank\") score_prefix Prefix used score columns direction \"to_individual\" (default: \"S\") score_col Name column containing scores direction \"to_aggregated\" (default: \"score\") total_col Name column containing/total counts (default: \"total\") all_scores Optional vector score categories include direction \"to_aggregated\"","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/convert_fish_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Between Aggregated and Individual Fish Data — convert_fish_data","text":"data frame converted data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_contingency_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Contingency Table from Count Data — create_contingency_table","title":"Create Contingency Table from Count Data — create_contingency_table","text":"function creates contingency table aggregating counts based grouping variable.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_contingency_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Contingency Table from Count Data — create_contingency_table","text":"","code":"create_contingency_table(   data,   group_col,   success_col,   failure_col,   prefix = NULL,   col_names = NULL )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_contingency_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Contingency Table from Count Data — create_contingency_table","text":"data data frame containing data group_col String name column group (e.g., \"dose\") success_col String name column containing success counts (e.g., \"alive\") failure_col String name column containing failure counts (e.g., \"dead\") prefix String prefix add row names (default: group column name followed \"_\") col_names Character vector length 2 column names (default: c(\"success\", \"failure\"))","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_contingency_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Contingency Table from Count Data — create_contingency_table","text":"matrix rows represent groups columns represent success/failure counts","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_contingency_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Contingency Table from Count Data — create_contingency_table","text":"","code":"# Generate example data set.seed(123) data <- data.frame(   dose = rep(c(0, 1, 10), each = 3),   alive = c(9, 8, 10, 7, 6, 5, 3, 4, 2),   dead = c(1, 2, 0, 3, 4, 5, 7, 6, 8) )  # Create contingency table create_contingency_table(data, \"dose\", \"alive\", \"dead\") #>         success failure #> dose_0       27       3 #> dose_1       18      12 #> dose_10       9      21"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_summary_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a summary table for manuscript/report — create_summary_table","title":"Create a summary table for manuscript/report — create_summary_table","text":"Create summary table manuscript/report","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_summary_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a summary table for manuscript/report — create_summary_table","text":"","code":"create_summary_table(comparison_results)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/create_summary_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a summary table for manuscript/report — create_summary_table","text":"comparison_results Output compare_tarone_scoring","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dat_bcs1.html","id":null,"dir":"Reference","previous_headings":"","what":"Fake data as an example of PVI data — dat_bcs1","title":"Fake data as an example of PVI data — dat_bcs1","text":"Fake data example PVI data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dat_bcs1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fake data as an example of PVI data — dat_bcs1","text":"","code":"dat_bcs1"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dat_bcs1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fake data as an example of PVI data — dat_bcs1","text":"pvi data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dose.p.glmmPQL.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Dose Probability for GLMM using PQL — dose.p.glmmPQL","title":"Calculate Dose Probability for GLMM using PQL — dose.p.glmmPQL","text":"function calculates dose probability generalized linear mixed model (GLMM) using Penalized Quasi-Likelihood (PQL).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dose.p.glmmPQL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Dose Probability for GLMM using PQL — dose.p.glmmPQL","text":"","code":"dose.p.glmmPQL(obj, cf = 1:2, p = 0.5)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dose.p.glmmPQL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Dose Probability for GLMM using PQL — dose.p.glmmPQL","text":"obj fitted GLMM object class \"glmmPQL\". cf numeric vector specifying coefficients used calculation (default 1:2). p numeric value representing probability level (default 0.5).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dose.p.glmmPQL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Dose Probability for GLMM using PQL — dose.p.glmmPQL","text":"structured object class \"glm.dose\" containing estimated dose probability standard error.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dose.p.glmmPQL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Dose Probability for GLMM using PQL — dose.p.glmmPQL","text":"","code":"# Assuming `glmm_model` is a fitted glmmPQL model ## library(MASS) glmm_model <- MASS::glmmPQL(yt ~ dose,random= ~1 | Obs,family= quasibinomial(link=\"logit\"), data=pvi_example) #> iteration 1 #> iteration 2 #> iteration 3 #> iteration 4 #> iteration 5 #> iteration 6 #> iteration 7 #> iteration 8 #> iteration 9 #> iteration 10 dose_result <- dose.p.glmmPQL(glmm_model) print(dose_result) #>              Dose       SE #> p = 0.5: 21.22061 1.455262"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcCompare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Dose-Response Models Using Multiple Criteria — drcCompare","title":"Compare Dose-Response Models Using Multiple Criteria — drcCompare","text":"Performs comprehensive comparison dose-response models using multiple criteria including model fit, certainty protection, steepness.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcCompare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Dose-Response Models Using Multiple Criteria — drcCompare","text":"","code":"drcCompare(   modRes = NULL,   modList = NULL,   trend = \"Decrease\",   CI = c(\"delta\", \"inv\", \"bmd-inv\"),   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcCompare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Dose-Response Models Using Multiple Criteria — drcCompare","text":"modRes Optional. Result object containing model comparison information. provided, modList parameter ignored. modList Optional. List fitted dose-response models compare. Required modRes NULL. trend Character string specifying expected trend direction. Must \"Decrease\" \"Increase\". CI Character string specifying confidence interval method. One \"delta\", \"inv\", \"bmd-inv\". Defaults \"delta\". ... Additional arguments passed internal functions","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcCompare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Dose-Response Models Using Multiple Criteria — drcCompare","text":"data frame containing model comparison results columns: Original comparison metrics Certainty_Protection: Measure protection certainty Steepness: Model steepness evaluation Effect p-val: P-value test -effect model","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcCompare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare Dose-Response Models Using Multiple Criteria — drcCompare","text":"","code":"if (FALSE) { # \\dontrun{ data(\"dat_medium\") dat_medium <- dat_medium %>% mutate(Treatment=factor(Dose,levels=unique(Dose))) dat_medium$Response[dat_medium$Response < 0] <- 0 mod <- drm(Response~Dose,data=dat_medium,fct=LL.3()) fctList <- list(LN.4(),LL.4(),W1.3(),LL2.2()) res <- mselect.plus(mod,fctList = fctList ) modList <- res$modList  # Compare models using existing comparison results drcCompare(modRes = res, trend = \"Decrease\") } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcHelper-package.html","id":null,"dir":"Reference","previous_headings":"","what":"drcHelper: Collection and verification of helper functions for dose-response analysis — drcHelper-package","title":"drcHelper: Collection and verification of helper functions for dose-response analysis — drcHelper-package","text":"Helper functions drc package dose-response analysis functions.","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcHelper-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"drcHelper: Collection and verification of helper functions for dose-response analysis — drcHelper-package","text":"Maintainer: Zhenglei Gao zhenglei.gao@bayer.com (ORCID) Authors: Sean Ryan sryan@exponent.com","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcHelper_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Williams Test Lookup Table — williamsTestLookUpTable","title":"Williams Test Lookup Table — williamsTestLookUpTable","text":"Williams Test Lookup Table test_cases_data validation purpose test_cases_res validation purpose example data shallow dose-response example data steep dose-response example data medium dose-response example data ED 50 response","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcHelper_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Williams Test Lookup Table — williamsTestLookUpTable","text":"","code":"williamsTestLookUpTable  test_cases_data  test_cases_res  dat_shallow  dat_steep  dat_medium  dat_noED50"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/drcHelper_datasets.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Williams Test Lookup Table — williamsTestLookUpTable","text":"object class data.frame 119 rows 19 columns. object class tbl_df (inherits tbl, data.frame) 768 rows 17 columns. object class tbl_df (inherits tbl, data.frame) 5950 rows 15 columns. object class data.frame 50 rows 2 columns. object class data.frame 24 rows 2 columns. object class data.frame 24 rows 2 columns. object class data.frame 24 rows 2 columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dunnett_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Conduct Dunnett Test with Various Model Specifications — dunnett_test","title":"Conduct Dunnett Test with Various Model Specifications — dunnett_test","text":"function performs Dunnett's test comparing multiple treatment levels control using various model specifications, including options random effects variance structures.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dunnett_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conduct Dunnett Test with Various Model Specifications — dunnett_test","text":"","code":"dunnett_test(   data,   response_var = \"Response\",   dose_var = \"Dose\",   tank_var = \"Tank\",   control_level = NULL,   include_random_effect = TRUE,   variance_structure = c(\"homoscedastic\", \"heteroscedastic\"),   alpha = 0.05,   conf_level = 0.95,   return_model = FALSE,   alternative = c(\"two.sided\", \"greater\", \"less\") )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dunnett_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conduct Dunnett Test with Various Model Specifications — dunnett_test","text":"data data frame containing dose-response data response_var Name response variable column dose_var Name dose/treatment variable column tank_var Name blocking/tank variable column (optional) control_level level dose_var use control (default minimum dose) include_random_effect Logical, whether include random effects blocks/tanks variance_structure Character, specifying variance structure: \"homoscedastic\" (default) \"heteroscedastic\" alpha Significance level determining NOEC (default = 0.05) conf_level Confidence level intervals (default = 0.95) return_model Logical, whether return fitted model object (default = FALSE) alternative character string specifying alternative hypothesis, must one '\"two.sided\"' (default), '\"greater\"' '\"less\"'.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/dunnett_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conduct Dunnett Test with Various Model Specifications — dunnett_test","text":"list containing Dunnett test results, NOEC value, optionally model object","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/estimate_phi_with_scoring.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate overdispersion parameter using consistent scoring (CORRECTED) — estimate_phi_with_scoring","title":"Estimate overdispersion parameter using consistent scoring (CORRECTED) — estimate_phi_with_scoring","text":"Estimate overdispersion parameter using consistent scoring (CORRECTED)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/estimate_phi_with_scoring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate overdispersion parameter using consistent scoring (CORRECTED) — estimate_phi_with_scoring","text":"","code":"estimate_phi_with_scoring(   successes,   totals,   doses,   scoring,   method = c(\"trend_adjusted\", \"simple\") )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/estimate_phi_with_scoring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate overdispersion parameter using consistent scoring (CORRECTED) — estimate_phi_with_scoring","text":"successes Vector success counts totals Vector total trials doses Vector dose levels scoring Scoring method use method Method phi estimation: \"trend_adjusted\" \"simple\"","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/exampleHistData.html","id":null,"dir":"Reference","previous_headings":"","what":"exampleHistData from StatCharrms — exampleHistData","title":"exampleHistData from StatCharrms — exampleHistData","text":"exampleHistData StatCharrms","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/exampleHistData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"exampleHistData from StatCharrms — exampleHistData","text":"","code":"exampleHistData"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/exampleHistData.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"exampleHistData from StatCharrms — exampleHistData","text":"object class data.frame 671 rows 56 columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_simple.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand Aggregated Fish Data to Individual Records (simple without tidyverse version) — expand_to_individual_simple","title":"Expand Aggregated Fish Data to Individual Records (simple without tidyverse version) — expand_to_individual_simple","text":"Expand Aggregated Fish Data Individual Records (simple without tidyverse version)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_simple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand Aggregated Fish Data to Individual Records (simple without tidyverse version) — expand_to_individual_simple","text":"","code":"expand_to_individual_simple(   data,   treatment_col = \"tmt\",   replicate_col = \"tank\",   score_prefix = \"S\",   total_col = \"total\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_simple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand Aggregated Fish Data to Individual Records (simple without tidyverse version) — expand_to_individual_simple","text":"data data frame containing aggregated fish data treatment_col Name column containing treatment groups (default: \"tmt\") replicate_col Name column containing tank/replicate IDs (default: \"tank\") score_prefix Prefix used score columns (default: \"S\") total_col Name column containing total counts (default: \"total\")","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_simple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand Aggregated Fish Data to Individual Records (simple without tidyverse version) — expand_to_individual_simple","text":"list containing: data: data frame individual fish records score_columns: Vector score column names original data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand Aggregated Fish Data to Individual Records (tidyverse version) — expand_to_individual_tidy","title":"Expand Aggregated Fish Data to Individual Records (tidyverse version) — expand_to_individual_tidy","text":"Expand Aggregated Fish Data Individual Records (tidyverse version)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand Aggregated Fish Data to Individual Records (tidyverse version) — expand_to_individual_tidy","text":"","code":"expand_to_individual_tidy(   data,   treatment_col = \"tmt\",   replicate_col = \"tank\",   score_prefix = \"S\",   total_col = \"total\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_tidy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand Aggregated Fish Data to Individual Records (tidyverse version) — expand_to_individual_tidy","text":"data data frame containing aggregated fish data treatment_col Name column containing treatment groups (default: \"tmt\") replicate_col Name column containing tank/replicate IDs (default: \"tank\") score_prefix Prefix used score columns (default: \"S\") total_col Name column containing total counts (default: \"total\")","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/expand_to_individual_tidy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand Aggregated Fish Data to Individual Records (tidyverse version) — expand_to_individual_tidy","text":"data frame individual fish records","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getComparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to get the comparison groups for Williams test or other. — getComparison","title":"Function to get the comparison groups for Williams test or other. — getComparison","text":"Function get comparison groups Williams test .","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getComparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to get the comparison groups for Williams test or other. — getComparison","text":"","code":"getComparison(object, test = c(\"trend\", \"many-to-one\"))"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getComparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to get the comparison groups for Williams test or other. — getComparison","text":"object test result different type tests test test used, either trend test many--one test","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEC50.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the EC50 Estimate from a Model — getEC50","title":"Get the EC50 Estimate from a Model — getEC50","text":"function calculates EC50 (dose 50% maximum effect observed) fitted model. supports generalized linear models (GLMs) generalized linear mixed models (GLMMs).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEC50.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the EC50 Estimate from a Model — getEC50","text":"","code":"getEC50(mod, approximate = FALSE)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEC50.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the EC50 Estimate from a Model — getEC50","text":"mod fitted model object. can class \"glm\" \"glmmPQL\", models compatible ED function. approximate logical, passing backCalcSE","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEC50.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the EC50 Estimate from a Model — getEC50","text":"data frame containing following columns: EC50 estimated EC50 value. lower lower bound 95% confidence interval EC50. upper upper bound 95% confidence interval EC50. se standard error EC50 estimate.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEC50.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the EC50 Estimate from a Model — getEC50","text":"","code":"# Assuming `fit` is a fitted glm model fit <- glm(yt ~ log(dose),family= quasibinomial(link=\"logit\"),data=pvi_example) ec50_result <- getEC50(fit) print(ec50_result) #>       EC50    lower    upper       se #> 1 12.91593 11.03755 15.11396 1.040638"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEndpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain Endpoint (NOEC) according to a series of p-values — getEndpoint","title":"Obtain Endpoint (NOEC) according to a series of p-values — getEndpoint","text":"Obtain Endpoint (NOEC) according series p-values","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEndpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain Endpoint (NOEC) according to a series of p-values — getEndpoint","text":"","code":"getEndpoint(pvals, doses = c(\"Control\", \"B\", \"C\", \"D\"), procedure = \"stepDown\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEndpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain Endpoint (NOEC) according to a series of p-values — getEndpoint","text":"pvals pvals tests doses corresponding doses procedure procedure obtain NOEC","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEndpoint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain Endpoint (NOEC) according to a series of p-values — getEndpoint","text":"NOEC","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEndpoint.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Obtain Endpoint (NOEC) according to a series of p-values — getEndpoint","text":"p-values NA, initializes zeros. fewer p-values doses, pads p-values zeros.checks doses significant comparing p-values threshold (0.05).Depending specified procedure, either steps highest dose find NOEC steps lowest dose..","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getEndpoint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain Endpoint (NOEC) according to a series of p-values — getEndpoint","text":"","code":"pvals <- c(0.01, 0.03, 0.07) doses <- c(\"Control\", \"B\", \"C\", \"D\") getEndpoint(pvals, doses) #> [1] \"D\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getLineContrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Linear Contrast for Treatment Levels — getLineContrast","title":"Calculate Linear Contrast for Treatment Levels — getLineContrast","text":"function calculates contrast coefficients used test linear relationship across treatment levels.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getLineContrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Linear Contrast for Treatment Levels — getLineContrast","text":"","code":"getLineContrast(Data, Treatment)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getLineContrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Linear Contrast for Treatment Levels — getLineContrast","text":"Data data frame containing treatment variable Treatment name treatment variable data frame","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getLineContrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Linear Contrast for Treatment Levels — getLineContrast","text":"numeric vector contrast coefficients linear trend testing","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getLineContrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Linear Contrast for Treatment Levels — getLineContrast","text":"","code":"test_data <- data.frame(Dose = factor(c(0, 1, 2, 3, 0, 1, 2, 3))) getLineContrast(test_data, \"Dose\") #> [1] -3 -1  1  3"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getModelName.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Model Name and Description — getModelName","title":"Get Model Name and Description — getModelName","text":"Returns model name description one fitted model names.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getModelName.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Model Name and Description — getModelName","text":"","code":"getModelName(fname = NULL)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getModelName.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Model Name and Description — getModelName","text":"fname Character vector model names (e.g., \"LL.2\", \"LN.4\"). NULL, returns available model names descriptions.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getModelName.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Model Name and Description — getModelName","text":"Character vector model names descriptions. NULL, returns available models. vector input, returns corresponding descriptions name. Special handling LN.* LL.* models.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getModelName.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Model Name and Description — getModelName","text":"","code":"getModelName() # Returns all available model names and descriptions #> Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1  #> (2 parameters)  #> In 'drc':  LL.2  #>  #> Log-logistic (ED50 as parameter) with lower limit at 0  #> (3 parameters)  #> In 'drc':  LL.3  #>  #> Log-logistic (ED50 as parameter) with upper limit at 1  #> (3 parameters)  #> In 'drc':  LL.3u  #>  #> Log-logistic (ED50 as parameter)  #> (4 parameters)  #> In 'drc':  LL.4  #>  #> Generalized log-logistic (ED50 as parameter)  #> (5 parameters)  #> In 'drc':  LL.5  #>  #> Weibull (type 1) with lower limit at 0 and upper limit at 1  #> (2 parameters)  #> In 'drc':  W1.2  #>  #> Weibull (type 1) with lower limit at 0  #> (3 parameters)  #> In 'drc':  W1.3  #>  #> Weibull (type 1)  #> (4 parameters)  #> In 'drc':  W1.4  #>  #> Weibull (type 2) with lower limit at 0 and upper limit at 1  #> (2 parameters)  #> In 'drc':  W2.2  #>  #> Weibull (type 2) with lower limit at 0  #> (3 parameters)  #> In 'drc':  W2.3  #>  #> Weibull (type 2)  #> (4 parameters)  #> In 'drc':  W2.4  #>  #> Brain-Cousens (hormesis) with lower limit fixed at 0  #> (4 parameters)  #> In 'drc':  BC.4  #>  #> Brain-Cousens (hormesis)  #> (5 parameters)  #> In 'drc':  BC.5  #>  #> Log-logistic (log(ED50) as parameter) with lower limit at 0 and upper limit at 1  #> (2 parameters)  #> In 'drc':  LL2.2  #>  #> Log-logistic (log(ED50) as parameter) with lower limit at 0  #> (3 parameters)  #> In 'drc':  LL2.3  #>  #> Log-logistic (log(ED50) as parameter) with upper limit at 1  #> (3 parameters)  #> In 'drc':  LL2.3u  #>  #> Log-logistic (log(ED50) as parameter)  #> (4 parameters)  #> In 'drc':  LL2.4  #>  #> Generalised log-logistic (log(ED50) as parameter)  #> (5 parameters)  #> In 'drc':  LL2.5  #>  #> Asymptotic regression with lower limit at 0  #> (2 parameters)  #> In 'drc':  AR.2  #>  #> Shifted asymptotic regression  #> (3 parameters)  #> In 'drc':  AR.3  #>  #> Michaelis-Menten  #> (2 parameters)  #> In 'drc':  MM.2  #>  #> Shifted Michaelis-Menten  #> (3 parameters)  #> In 'drc':  MM.3  #>  #>  [1] \"LL.2: Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1\"       #>  [2] \"LL.3: Log-logistic (ED50 as parameter) with lower limit at 0\"                            #>  [3] \"LL.3u: Log-logistic (ED50 as parameter) with upper limit at 1\"                           #>  [4] \"LL.4: Log-logistic (ED50 as parameter)\"                                                  #>  [5] \"LL.5: Generalized log-logistic (ED50 as parameter)\"                                      #>  [6] \"W1.2: Weibull (type 1) with lower limit at 0 and upper limit at 1\"                       #>  [7] \"W1.3: Weibull (type 1) with lower limit at 0\"                                            #>  [8] \"W1.4: Weibull (type 1)\"                                                                  #>  [9] \"W2.2: Weibull (type 2) with lower limit at 0 and upper limit at 1\"                       #> [10] \"W2.3: Weibull (type 2) with lower limit at 0\"                                            #> [11] \"W2.4: Weibull (type 2)\"                                                                  #> [12] \"BC.4: Brain-Cousens (hormesis) with lower limit fixed at 0\"                              #> [13] \"BC.5: Brain-Cousens (hormesis)\"                                                          #> [14] \"LL2.2: Log-logistic (log(ED50) as parameter) with lower limit at 0 and upper limit at 1\" #> [15] \"LL2.3: Log-logistic (log(ED50) as parameter) with lower limit at 0\"                      #> [16] \"LL2.3u: Log-logistic (log(ED50) as parameter) with upper limit at 1\"                     #> [17] \"LL2.4: Log-logistic (log(ED50) as parameter)\"                                            #> [18] \"LL2.5: Generalised log-logistic (log(ED50) as parameter)\"                                #> [19] \"AR.2: Asymptotic regression with lower limit at 0\"                                       #> [20] \"AR.3: Shifted asymptotic regression\"                                                     #> [21] \"MM.2: Michaelis-Menten\"                                                                  #> [22] \"MM.3: Shifted Michaelis-Menten\"                                                          getModelName(\"LL.2\") # Returns description for LL.2 #> [1] \"LL.2: 2-parameter Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1\" getModelName(c(\"LL.2\", \"LN.4\")) # Returns descriptions for multiple models #> [1] \"LL.2: 2-parameter Log-logistic (ED50 as parameter) with lower limit at 0 and upper limit at 1\" #> [2] \"LN.4: 4-parameter log-normal\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getQuadContrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Quadratic Contrast for Treatment Levels — getQuadContrast","title":"Calculate Quadratic Contrast for Treatment Levels — getQuadContrast","text":"function calculates contrast coefficients used test quadratic relationship across treatment levels.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getQuadContrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Quadratic Contrast for Treatment Levels — getQuadContrast","text":"","code":"getQuadContrast(Data, Treatment)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getQuadContrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Quadratic Contrast for Treatment Levels — getQuadContrast","text":"Data data frame containing treatment variable Treatment name treatment variable data frame","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getQuadContrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Quadratic Contrast for Treatment Levels — getQuadContrast","text":"numeric vector contrast coefficients quadratic trend testing","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getQuadContrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Quadratic Contrast for Treatment Levels — getQuadContrast","text":"","code":"test_data <- data.frame(Dose = factor(c(0, 1, 2, 3, 0, 1, 2, 3))) getQuadContrast(test_data, \"Dose\") #> [1]  1 -1 -1  1"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_CA_Z.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","title":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","text":"function calculates Z-statistic Cochran-Armitage trend test using adjusted counts sample sizes.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_CA_Z.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","text":"","code":"get_CA_Z(adj_x, adj_n)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_CA_Z.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","text":"adj_x Vector adjusted affected counts treatment group adj_n Vector adjusted sample sizes treatment group","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_CA_Z.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","text":"Z-statistic Cochran-Armitage trend test","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_CA_Z.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","text":"Cochran-Armitage trend test examines whether linear trend proportions across ordered categories (treatment groups). implementation uses adjusted values account clustering data. function assigns scores (1, 2, 3, ...) treatment groups calculates Z-statistic using formula: \\deqn{Z = [sum(adj_x*d) - N*p_bar*d_bar] / sqrt[p_bar*(1-p_bar)*(sum(adj_n*d^2) - N*d_bar^2)] : d scores (1, 2, 3, ...) N total adjusted sample size d_bar weighted average scores p_bar overall proportion affected subjects","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_CA_Z.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","text":"Originally Allen Olmstead","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_CA_Z.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Cochran-Armitage Trend Test Z-Statistic — get_CA_Z","text":"","code":"# Get adjusted values data(dat_bcs1) adj_vals <- get_RS_adj_val(   dat_bcs1$tmt,   dat_bcs1$tank,   dat_bcs1$S1 + dat_bcs1$S2 + dat_bcs1$S3,   dat_bcs1$total ) # Calculate Z-statistic Z <- get_CA_Z(adj_vals$x_tilde, adj_vals$n_tilde)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_RS_adj_val.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Rao-Scott Adjusted Values for Clustered Binary Data — get_RS_adj_val","title":"Calculate Rao-Scott Adjusted Values for Clustered Binary Data — get_RS_adj_val","text":"function calculates Rao-Scott adjustment clustered binary data account intra-cluster correlation analyzing dose-response relationships.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_RS_adj_val.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Rao-Scott Adjusted Values for Clustered Binary Data — get_RS_adj_val","text":"","code":"get_RS_adj_val(group, replicate, affected, total)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_RS_adj_val.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Rao-Scott Adjusted Values for Clustered Binary Data — get_RS_adj_val","text":"group Vector treatment group identifiers replicate Vector replicate/tank identifiers within treatment groups affected Vector counts affected subjects (fish injuries) replicate total Vector total subjects (fish) replicate","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_RS_adj_val.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Rao-Scott Adjusted Values for Clustered Binary Data — get_RS_adj_val","text":"tibble containing following columns: grp Treatment group identifier x Total number affected subjects treatment group n Total number subjects treatment group m Number replicates treatment group p_hat Estimated proportion affected subjects treatment group b Binomial variance p_hat v Estimated variance accounting clustering D Design effect (ratio cluster-adjusted variance binomial variance) n_tilde Adjusted sample size accounting clustering x_tilde Adjusted number affected subjects accounting clustering","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_RS_adj_val.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Rao-Scott Adjusted Values for Clustered Binary Data — get_RS_adj_val","text":"function modified based function written Allen Olmstead. first aggregates data treatment group calculate overall proportions. computes variance within treatment group accounting clustering, calculates design effect (D) ratio cluster-adjusted variance binomial variance. sample size affected counts adjusted dividing design effect.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/get_RS_adj_val.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate Rao-Scott Adjusted Values for Clustered Binary Data — get_RS_adj_val","text":"Allen Olmstead","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getwilliamRes.html","id":null,"dir":"Reference","previous_headings":"","what":"get from william res accept/reject — getwilliamRes","title":"get from william res accept/reject — getwilliamRes","text":"get william res accept/reject","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getwilliamRes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get from william res accept/reject — getwilliamRes","text":"","code":"getwilliamRes(william, n = NULL)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getwilliamRes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get from william res accept/reject — getwilliamRes","text":"william william test results n number hypotheses tested. description","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getwilliamRes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get from william res accept/reject — getwilliamRes","text":"vector accept rejects.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/getwilliamRes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get from william res accept/reject — getwilliamRes","text":"","code":"## Example from Sachs (1997, p. 402) x <- c(106, 114, 116, 127, 145,        110, 125, 143, 148, 151,        136, 139, 149, 160, 174) g <- gl(3,5) levels(g) <- c(\"0\", \"I\", \"II\")  ## Williams Test res <- PMCMRplus::williamsTest(x ~ g) getwilliamRes(res) #> [1] \"accept\" \"reject\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/hamilton.html","id":null,"dir":"Reference","previous_headings":"","what":"This is hamilton data — hamilton","title":"This is hamilton data — hamilton","text":"Example dose-response data given Hamilton (1977). Note , per Hamilton (1978), confidence intervals given Hamilton (1977) data sets incorrect. Example dose-response data given Hamilton (1977). Note , per Hamilton (1978), confidence intervals given Hamilton (1977) data sets incorrect.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/hamilton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This is hamilton data — hamilton","text":"","code":"hamilton  hamilton"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/hamilton.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"This is hamilton data — hamilton","text":"list containing ten data frames: dr1a, dr1b, dr1c, dr1d, dr1e, dr4a, dr4b, dr4c, dr4d, dr4e, list containing ten data frames: dr1a, dr1b, dr1c, dr1d, dr1e, dr4a, dr4b, dr4c, dr4d, dr4e","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/hamilton.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"This is hamilton data — hamilton","text":"Hamilton, 1977. Hamilton, 1977.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/hamilton.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"This is hamilton data — hamilton","text":"https://github.com/brsr/tsk https://github.com/brsr/tsk","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/hamilton.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"This is hamilton data — hamilton","text":"B R S Recht","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/invlogxp.html","id":null,"dir":"Reference","previous_headings":"","what":"inverse transformation of logxp — invlogxp","title":"inverse transformation of logxp — invlogxp","text":"inverse transformation logxp","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/invlogxp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"inverse transformation of logxp — invlogxp","text":"","code":"invlogxp(x, a)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/invlogxp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"inverse transformation of logxp — invlogxp","text":"x numeric vector numeric vector","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/invlogxp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"inverse transformation of logxp — invlogxp","text":"inverse log x ","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/invlogxp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"inverse transformation of logxp — invlogxp","text":"","code":"invlogxp(3, 1) #> [1] 19.08554"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/log_message.html","id":null,"dir":"Reference","previous_headings":"","what":"Adding detailed logging — log_message","title":"Adding detailed logging — log_message","text":"Adding detailed logging","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/log_message.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adding detailed logging — log_message","text":"","code":"log_message(message, log_file = \"simulation_log.txt\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/log_message.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adding detailed logging — log_message","text":"message message written log_file file appended ","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/log_message.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adding detailed logging — log_message","text":"log_file series messages specified simulation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/logxp.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for scaling x-axis — logxp","title":"Helper function for scaling x-axis — logxp","text":"Helper function scaling x-axis","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/logxp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for scaling x-axis — logxp","text":"","code":"logxp(x, a)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/logxp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for scaling x-axis — logxp","text":"x vector numeric vector nummeric","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/logxp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function for scaling x-axis — logxp","text":"log(x+)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/logxp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function for scaling x-axis — logxp","text":"","code":"logxp(0, 1) #> [1] 0"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/many_to_one_fisher_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Many-to-One Pairwise Fisher's Exact Test — many_to_one_fisher_test","title":"Many-to-One Pairwise Fisher's Exact Test — many_to_one_fisher_test","text":"Performs Fisher's exact test comparing group reference group, modified based rstatix pairwise implementation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/many_to_one_fisher_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Many-to-One Pairwise Fisher's Exact Test — many_to_one_fisher_test","text":"","code":"many_to_one_fisher_test(   xtab,   ref.group = NULL,   p.adjust.method = \"holm\",   detailed = FALSE,   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/many_to_one_fisher_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Many-to-One Pairwise Fisher's Exact Test — many_to_one_fisher_test","text":"xtab contingency table matrix data frame ref.group Character string specifying reference group (must match one row names xtab) p.adjust.method Method adjusting p-values multiple comparisons detailed Logical indicating whether return detailed results ... Additional arguments passed fisher.test()","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/many_to_one_fisher_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Many-to-One Pairwise Fisher's Exact Test — many_to_one_fisher_test","text":"data frame containing results Fisher's exact tests","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/many_to_one_fisher_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Many-to-One Pairwise Fisher's Exact Test — many_to_one_fisher_test","text":"","code":"if (FALSE) { # \\dontrun{ # Create contingency table ctable <- create_contingency_table(data) # Run many-to-one Fisher's test with dose_0 as reference many_to_one_fisher_test(ctable, ref.group = \"dose_0\") } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/metaldata.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from heavy metal mixture experiments (drcData) — metaldata","title":"Data from heavy metal mixture experiments (drcData) — metaldata","text":"Data study response cyanobacterial self-luminescent metallothionein-based whole-cell biosensor Synechoccocus elongatus PCC 7942 pBG2120 binary mixtures 6 heavy metals (Zn, Cu, Cd, Ag, Co Hg).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/metaldata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data from heavy metal mixture experiments (drcData) — metaldata","text":"","code":"metaldata"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/metaldata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data from heavy metal mixture experiments (drcData) — metaldata","text":"object class data.frame 543 rows 3 columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/monotonicityTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Testing Monotonicity — monotonicityTest","title":"Testing Monotonicity — monotonicityTest","text":"function adapted archived version StatCharrms developed Joe Swintek et al CC0 license. updated anymore included validation purpose. ways perform trend test. function tests whether dose-response relationship follows monotonic trend (consistently increasing decreasing) analyzing linear quadratic components relationship.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/monotonicityTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Testing Monotonicity — monotonicityTest","text":"","code":"monotonicityTest(Data, Treatment, Response)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/monotonicityTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Testing Monotonicity — monotonicityTest","text":"Data Data frame Treatment name treatment variable Response name response variable","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/monotonicityTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Testing Monotonicity — monotonicityTest","text":"monotonicity table","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/monotonicityTest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Testing Monotonicity — monotonicityTest","text":"test first applies rank transformation response variable using rankTransform function, implements Blom's method (equivalent SAS PROC RANK NORMAL=BLOM). Next creates linear quadratic contrasts using getLineContrast getQuadContrast functions. fits ANOVA model using transformed response variable extracts summary statistics ANOVA model. Interpretations: linear component significant: Strong evidence monotonicity. linear quadratic components significant: relationship monotonic curvature. quadratic component significant: relationship likely non-monotonic (e.g., U-shaped). neither component significant: clear dose-response relationship detected Note contrasts<- need imported stats.function used set contrasts factors.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/monotonicityTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Testing Monotonicity — monotonicityTest","text":"","code":"if (FALSE) { # \\dontrun{ x <- c(106, 114, 116, 127, 145,110, 125, 143, 148, 151, 136, 139, 149, 160, 174) g <- gl(3,5) levels(g) <- c(\"0\", \"I\", \"II\") monotonicityTest(data.frame(treatment_var = g,response_var=x), \"treatment_var\", \"response_var\") mock_data <- data.frame( treatment_var = factor(rep(c(\"Control\", \"Dose1\", \"Dose2\", \"Dose3\"), each = 10)), response_var = c(rnorm(10, mean = 5), rnorm(10, mean = 7), rnorm(10, mean = 8), rnorm(10, mean = 10)) ) monotonicityTest(mock_data, \"treatment_var\", \"response_var\") } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.ED.html","id":null,"dir":"Reference","previous_headings":"","what":"ECx calculation together with normalized width proposed by EFSA SO. — mselect.ED","title":"ECx calculation together with normalized width proposed by EFSA SO. — mselect.ED","text":"ECx calculation together normalized width proposed EFSA .","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.ED.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ECx calculation together with normalized width proposed by EFSA SO. — mselect.ED","text":"","code":"mselect.ED(modList, respLev = c(10, 20, 50), trend = \"Decrease\", ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.ED.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ECx calculation together with normalized width proposed by EFSA SO. — mselect.ED","text":"modList list models respLev response levels ECx example, 10, 20, 50 trend \"Decrease\" \"Incrrease\". ... optional pass ED function.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.ED.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ECx calculation together with normalized width proposed by EFSA SO. — mselect.ED","text":"ED result table","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.plus.html","id":null,"dir":"Reference","previous_headings":"","what":"added functionality for mselect — mselect.plus","title":"added functionality for mselect — mselect.plus","text":"added functionality mselect Deprecated helper function mselect","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.plus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"added functionality for mselect — mselect.plus","text":"","code":"mselect.plus(   object = NULL,   fctList = NULL,   nested = FALSE,   sorted = c(\"IC\", \"Res var\", \"Lack of fit\", \"no\"),   linreg = FALSE,   icfct = AIC,   respCol = \"effect\",   doseCol = \"dose\",   data = NULL,   type = \"continuous\",   additionalReliability = c(\"EFSA\") )  mselect.ZG(   object = NULL,   fctList = NULL,   nested = FALSE,   sorted = c(\"IC\", \"Res var\", \"Lack of fit\", \"no\"),   linreg = FALSE,   icfct = AIC,   respCol = \"effect\",   doseCol = \"dose\",   data = NULL,   type = \"continuous\",   additionalReliability = c(\"EFSA\") )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.plus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"added functionality for mselect — mselect.plus","text":"object fitted object class 'drc'. fctList list dose-response functions compared. nested logical. TRUE results F tests adjacent models ('fctList'). sensible nested models. sorted character string determining according criterion model fits ranked, default IC. linreg logical indicating whether additionally polynomial regression models (linear, quadratic, cubic models) fitted (useful kind informal lack--test consideration models specified, capturing unexpected departures). icfct function supplying information criterion used. AIC BIC two options. respCol name response column doseCol name dose column data data used type type models, binomial, continuous, etc. additionalReliability additional reliability need calculated","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.plus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"added functionality for mselect — mselect.plus","text":"model comparison object class drcComp","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.plus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"added functionality for mselect — mselect.plus","text":"Due old ECxHelper development mselect.plus defined mselect.ZG","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/mselect.plus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"added functionality for mselect — mselect.plus","text":"","code":"if (FALSE) { # \\dontrun{ data(\"dat_medium\") dat_medium <- dat_medium %>% mutate(Treatment=factor(Dose,levels=unique(Dose))) dat_medium$Response[dat_medium$Response < 0] <- 0 mod <- drm(Response~Dose,data=dat_medium,fct=LL.3()) fctList <- list(LN.4(),LL.4(),W1.3(),LL2.2()) res <- mselect.plus(mod,fctList = fctList ) modList <- res$modList } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oecd201.html","id":null,"dir":"Reference","previous_headings":"","what":"An example dataset from study type OECD 201 — oecd201","title":"An example dataset from study type OECD 201 — oecd201","text":"example dataset study type OECD 201","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oecd201.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An example dataset from study type OECD 201 — oecd201","text":"data frame 112 rows 14 columns","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oecd201.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"An example dataset from study type OECD 201 — oecd201","text":"data originally provided Ecotox colleague Andreas preprocessed GrowthRate included.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oecd201.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An example dataset from study type OECD 201 — oecd201","text":"OECD Test . 201: Freshwater Alga Cyanobacteria, Growth Inhibition Test https://www.oecd.org/en/publications/test--201-alga-growth-inhibition-test_9789264069923-en.html","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oecd201.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An example dataset from study type OECD 201 — oecd201","text":"BCS","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oscillating_response.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Oscillating Response Pattern — oscillating_response","title":"Generate Oscillating Response Pattern — oscillating_response","text":"function creates response pattern oscillates around baseline, doses showing increases others showing decreases.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oscillating_response.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Oscillating Response Pattern — oscillating_response","text":"","code":"oscillating_response(   doses,   max_effect = 20,   frequency = 1,   baseline = 100,   dose_range = c(0, 20) )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oscillating_response.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Oscillating Response Pattern — oscillating_response","text":"doses Vector dose values max_effect Maximum magnitude effect (positive negative) frequency many complete oscillations across dose range baseline Baseline response value dose_range range doses concentrations","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/oscillating_response.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Oscillating Response Pattern — oscillating_response","text":"Vector response values","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pavaMean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Means Using the Pool Adjacent Violators Algorithm (PAVA) — pavaMean","title":"Calculate Means Using the Pool Adjacent Violators Algorithm (PAVA) — pavaMean","text":"function computes adjusted means standard errors groups defined factor variable using Pool Adjacent Violators Algorithm (PAVA).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pavaMean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Means Using the Pool Adjacent Violators Algorithm (PAVA) — pavaMean","text":"","code":"pavaMean(x, g, alternative = \"greater\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pavaMean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Means Using the Pool Adjacent Violators Algorithm (PAVA) — pavaMean","text":"x numeric vector observations. g factor variable defines groups calculate means. alternative character string specifying alternative hypothesis. Options \"greater\" (default) \"less\".","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pavaMean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Means Using the Pool Adjacent Violators Algorithm (PAVA) — pavaMean","text":"data frame containing following columns: pavaMean adjusted means group. SE.diff standard errors differences.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pavaMean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Means Using the Pool Adjacent Violators Algorithm (PAVA) — pavaMean","text":"","code":"# Example usage: x <- c(1, 2, 3, 4, 5, 6) g <- factor(c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\")) result <- pavaMean(x, g) print(result) #>   pavaMean   SE.diff #> A      1.5 0.7071068 #> B      3.5 0.7071068 #> C      5.5 0.7071068 x <- c(106, 114, 116, 127, 145,        110, 125, 143, 148, 151,        136, 139, 149, 160, 174) g <- gl(3,5) levels(g) <- c(\"0\", \"I\", \"II\") pavaMean(x,g) #>    pavaMean SE.diff #> 0     121.6 10.1712 #> I     135.4 10.1712 #> II    151.6 10.1712"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/perform_groupwise_tarone.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Tarone test within each dose group — perform_groupwise_tarone","title":"Perform Tarone test within each dose group — perform_groupwise_tarone","text":"Perform Tarone test within dose group","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/perform_groupwise_tarone.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Tarone test within each dose group — perform_groupwise_tarone","text":"","code":"perform_groupwise_tarone(data)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/perform_groupwise_tarone.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Tarone test within each dose group — perform_groupwise_tarone","text":"data Data frame successes, totals, doses","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.StepDownRSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for StepDownRSCABS objects — plot.StepDownRSCABS","title":"Plot method for StepDownRSCABS objects — plot.StepDownRSCABS","text":"Plot method StepDownRSCABS objects","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.StepDownRSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for StepDownRSCABS objects — plot.StepDownRSCABS","text":"","code":"# S3 method for class 'StepDownRSCABS' plot(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.StepDownRSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for StepDownRSCABS objects — plot.StepDownRSCABS","text":"x StepDownRSCABS object ... Additional arguments (used)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.StepDownRSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for StepDownRSCABS objects — plot.StepDownRSCABS","text":"ggplot object","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.dunnett_test_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for dunnett_test_result objects — plot.dunnett_test_result","title":"Plot method for dunnett_test_result objects — plot.dunnett_test_result","text":"Plot method dunnett_test_result objects","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.dunnett_test_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for dunnett_test_result objects — plot.dunnett_test_result","text":"","code":"# S3 method for class 'dunnett_test_result' plot(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.dunnett_test_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for dunnett_test_result objects — plot.dunnett_test_result","text":"x dunnett_test_result object ... Additional arguments passed plot methods","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.modList.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a list of models together. — plot.modList","title":"Plot a list of models together. — plot.modList","text":"Plot list models together.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.modList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a list of models together. — plot.modList","text":"","code":"# S3 method for class 'modList' plot(   x,   respLev = NULL,   data = NULL,   xmin,   xmax,   scale = c(\"logx\", \"logy\", \"logxy\", \"orig\"),   npts = 100,   plot_respLev = FALSE,   xbreaks = NULL,   ymin = NULL,   ymax = NULL,   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.modList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a list of models together. — plot.modList","text":"x list drc models modList class. respLev calculated ECx levels, example, c(10,20,50). data data used fit set models xmin minimum value xaxis, greater 0 fit log scale. xmax maximum value xaxis, can missing. scale \"logx\", \"logy\", \"logxy\", \"orig\". npts number points used plotting prediction confidence bands plot_respLev logical, whether add estimated ECx CIs xbreaks breaks x-axis labeling ymin minimum y ymax max y ... addition parameters passed plotting functions user input use want use data provided modList","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.modList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a list of models together. — plot.modList","text":"ggplot object","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot.modList.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a list of models together. — plot.modList","text":"","code":"if (FALSE) { # \\dontrun{ data(\"dat_medium\") dat_medium <- dat_medium %>% mutate(Treatment=factor(Dose,levels=unique(Dose))) dat_medium$Response[dat_medium$Response < 0] <- 0 mod <- drm(Response~Dose,data=dat_medium,fct=LL.3()) fctList <- list(LN.4(),LL.4(),W1.3(),LL2.2()) res <- mselect.plus(mod,fctList = fctList ) modList <- res$modList p <- plot.modList(modList[1:3]) p } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot_edList.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the ECx estimation and confidence intervals from the list of models. — plot_edList","title":"Plot the ECx estimation and confidence intervals from the list of models. — plot_edList","text":"Plot ECx estimation confidence intervals list models.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot_edList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the ECx estimation and confidence intervals from the list of models. — plot_edList","text":"","code":"plot_edList(edList, fctNames, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot_edList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the ECx estimation and confidence intervals from the list of models. — plot_edList","text":"edList ECx lists fitted set models fctNames fct function names ... additional parameters","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/plot_edList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the ECx estimation and confidence intervals from the list of models. — plot_edList","text":"ggplot object","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot1.html","id":null,"dir":"Reference","previous_headings":"","what":"Preliminary Plot 1 for Dose Response Data — prelimPlot1","title":"Preliminary Plot 1 for Dose Response Data — prelimPlot1","text":"function generates scatter plot response nominal dose.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preliminary Plot 1 for Dose Response Data — prelimPlot1","text":"","code":"prelimPlot1(   testdata,   dose_col = \"Dose\",   response_col = \"Response\",   ylab = \"Response\",   xlab = \"Test Concentration [nominal, mg a.s./L]\",   title = \"Measured Variable\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preliminary Plot 1 for Dose Response Data — prelimPlot1","text":"testdata data frame containing dose response data. dose_col name dose column, default \"Dose\". response_col name response column. ylab string y-axis label. Default \"Response\". xlab string x-axis label. Default \"Test Concentration [nominal, mg .s./L]\". title string plot title. Default \"Measured Variable\".","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preliminary Plot 1 for Dose Response Data — prelimPlot1","text":"ggplot object.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot2.html","id":null,"dir":"Reference","previous_headings":"","what":"Preliminary Plot 2 for Dose Response Data, with x continuous. — prelimPlot2","title":"Preliminary Plot 2 for Dose Response Data, with x continuous. — prelimPlot2","text":"function generates scatter plot response dose log1p scale.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preliminary Plot 2 for Dose Response Data, with x continuous. — prelimPlot2","text":"","code":"prelimPlot2(   testdata,   ylab = \"Response\",   xlab = \"Test Concentration [nominal, mg a.s./L]\",   title = \"Measured Variable\",   dose_col = \"Dose\",   response_col = \"Response\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preliminary Plot 2 for Dose Response Data, with x continuous. — prelimPlot2","text":"testdata data frame containing dose response data. ylab string y-axis label. Default \"Response\". xlab string x-axis label. Default \"Test Concentration [nominal, mg .s./L]\". title string plot title. Default \"Measured Variable\". dose_col name dose column, default \"Dose\". response_col name response column.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preliminary Plot 2 for Dose Response Data, with x continuous. — prelimPlot2","text":"ggplot object.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot3.html","id":null,"dir":"Reference","previous_headings":"","what":"Preliminary Plot 3 for Dose Response Data — prelimPlot3","title":"Preliminary Plot 3 for Dose Response Data — prelimPlot3","text":"function generates scatter plot response nominal dose.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preliminary Plot 3 for Dose Response Data — prelimPlot3","text":"","code":"prelimPlot3(   testdata,   ylab = \"Response\",   xlab = \"Test Concentration [nominal, mg a.s./L]\",   title = \"Measured Variable\",   a = 1.96,   dose_col = \"Dose\",   response_col = \"Response\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preliminary Plot 3 for Dose Response Data — prelimPlot3","text":"testdata data frame containing dose response data. ylab string y-axis label. Default \"Response\". xlab string x-axis label. Default \"Test Concentration [nominal, mg .s./L]\". title string plot title. Default \"Measured Variable\". quantile corresponding CI mean. default qnorm(0.975). dose_col name dose column, default \"Dose\". response_col name response column.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimPlot3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preliminary Plot 3 for Dose Response Data — prelimPlot3","text":"ggplot object.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Preliminary Summary of Dose Response Data — prelimSummary","title":"Preliminary Summary of Dose Response Data — prelimSummary","text":"function calculates mean response, standard deviation, percent inhibition, coefficient variation dose level.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preliminary Summary of Dose Response Data — prelimSummary","text":"","code":"prelimSummary(testdata, dose_col = \"Dose\", response_col = \"Response\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preliminary Summary of Dose Response Data — prelimSummary","text":"testdata data frame containing dose response data. dose_col name dose column, default \"Dose\". response_col name response column.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preliminary Summary of Dose Response Data — prelimSummary","text":"data frame summarizing mean, standard deviation, percent inhibition, coefficient variation dose.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prelimSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preliminary Summary of Dose Response Data — prelimSummary","text":"","code":"# Sample data frame testdata <- data.frame(Dose = c(0, 1, 2, 3, 0, 1, 2, 3),                       Response = c(10, 20, 30, 40, 12, 22, 32, 42))  # Create the summary summary_result <- prelimSummary(testdata, dose_col = \"Dose\", response_col = \"Response\") print(summary_result) #> # A tibble: 4 × 5 #>    Dose  Mean    SD `% Inhibition`    CV #>   <dbl> <dbl> <dbl>          <dbl> <dbl> #> 1     0    11  1.41            0   12.9  #> 2     1    21  1.41          -90.9  6.73 #> 3     2    31  1.41         -182.   4.56 #> 4     3    41  1.41         -273.   3.45"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prepDataRSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepares data for an RSCABS analysis — prepDataRSCABS","title":"Prepares data for an RSCABS analysis — prepDataRSCABS","text":"Prepares data RSCABS analysis","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prepDataRSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepares data for an RSCABS analysis — prepDataRSCABS","text":"","code":"prepDataRSCABS(   Effect = \"\",   Data = {  },   Treatment = \"\",   Replicate = \"\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prepDataRSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepares data for an RSCABS analysis — prepDataRSCABS","text":"Effect endpoint converted. Data tall formatted data set. Treatment name treatment variable. Replicate name replicate variable.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prepDataRSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepares data for an RSCABS analysis — prepDataRSCABS","text":"Returns list containing: x..j matrix containing number observed \"successes\" replicate treatment j. n..j matrix containing number observations replicate treatment j. m.matrix number replicates treatment-replicate combination. K.max maximum severity score endpoint.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/prepDataRSCABS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepares data for an RSCABS analysis — prepDataRSCABS","text":"Joe Swintek","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.RSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing method for run_all_threshold_tests results — print.RSCABS","title":"Printing method for run_all_threshold_tests results — print.RSCABS","text":"Printing method run_all_threshold_tests results","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.RSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing method for run_all_threshold_tests results — print.RSCABS","text":"","code":"# S3 method for class 'RSCABS' print(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.RSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing method for run_all_threshold_tests results — print.RSCABS","text":"x object run_all_threshold_tests class RSCABS ... print generic function signature function(x, ...).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.RSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing method for run_all_threshold_tests results — print.RSCABS","text":"printed results run_all_threshold_tests","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.StepDownRSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for StepDownRSCABS objects — print.StepDownRSCABS","title":"Print method for StepDownRSCABS objects — print.StepDownRSCABS","text":"Print method StepDownRSCABS objects","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.StepDownRSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for StepDownRSCABS objects — print.StepDownRSCABS","text":"","code":"# S3 method for class 'StepDownRSCABS' print(x, printLowest = FALSE, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.StepDownRSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for StepDownRSCABS objects — print.StepDownRSCABS","text":"x StepDownRSCABS object printLowest whether print lowest treatment level significant findings. ... Additional arguments (used) generic print method.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.StepDownRSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for StepDownRSCABS objects — print.StepDownRSCABS","text":"Invisibly returns object","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.TaroneTrendTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for TaroneTrendTest with tabular output — print.TaroneTrendTest","title":"Print method for TaroneTrendTest with tabular output — print.TaroneTrendTest","text":"Print method TaroneTrendTest tabular output","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.TaroneTrendTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for TaroneTrendTest with tabular output — print.TaroneTrendTest","text":"","code":"# S3 method for class 'TaroneTrendTest' print(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.TaroneTrendTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for TaroneTrendTest with tabular output — print.TaroneTrendTest","text":"x TaroneTrendTest object ... Additional arguments","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.completeTrendAnalysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for complete trend analysis (UPDATED) — print.completeTrendAnalysis","title":"Print method for complete trend analysis (UPDATED) — print.completeTrendAnalysis","text":"Print method complete trend analysis (UPDATED)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.completeTrendAnalysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for complete trend analysis (UPDATED) — print.completeTrendAnalysis","text":"","code":"# S3 method for class 'completeTrendAnalysis' print(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.completeTrendAnalysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for complete trend analysis (UPDATED) — print.completeTrendAnalysis","text":"x completeTrendAnalysis results ... additional arguments","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.drcComp.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for drcComp Objects — print.drcComp","title":"Print Method for drcComp Objects — print.drcComp","text":"function provides custom print method objects class drcComp. prints Comparison EFSA components object.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.drcComp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for drcComp Objects — print.drcComp","text":"","code":"# S3 method for class 'drcComp' print(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.drcComp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for drcComp Objects — print.drcComp","text":"x object class drcComp. ... Additional arguments (currently used).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.drcComp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for drcComp Objects — print.drcComp","text":"function prints Comparison EFSA components object default.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.dunnett_test_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for dunnett_test_result objects — print.dunnett_test_result","title":"Print method for dunnett_test_result objects — print.dunnett_test_result","text":"Print method dunnett_test_result objects","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.dunnett_test_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for dunnett_test_result objects — print.dunnett_test_result","text":"","code":"# S3 method for class 'dunnett_test_result' print(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.dunnett_test_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for dunnett_test_result objects — print.dunnett_test_result","text":"x dunnett_test_result object ... Additional arguments passed print methods","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.stepDownTrendBinom.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for stepDownTrendBinom Objects — print.stepDownTrendBinom","title":"Print Method for stepDownTrendBinom Objects — print.stepDownTrendBinom","text":"Print Method stepDownTrendBinom Objects","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.stepDownTrendBinom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for stepDownTrendBinom Objects — print.stepDownTrendBinom","text":"","code":"# S3 method for class 'stepDownTrendBinom' print(x, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.stepDownTrendBinom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for stepDownTrendBinom Objects — print.stepDownTrendBinom","text":"x object class \"stepDownTrendBinom\" ... Additional arguments passed print","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/print.stepDownTrendBinom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for stepDownTrendBinom Objects — print.stepDownTrendBinom","text":"Invisibly returns input object","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pvi_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Fake data as an example of PVI data — pvi_example","title":"Fake data as an example of PVI data — pvi_example","text":"Fake data example PVI data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pvi_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fake data as an example of PVI data — pvi_example","text":"","code":"pvi_example"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/pvi_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fake data as an example of PVI data — pvi_example","text":"pvi data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/quantal_dat_nested.html","id":null,"dir":"Reference","previous_headings":"","what":"Data from Acute Studies — quantal_dat_nested","title":"Data from Acute Studies — quantal_dat_nested","text":"Data study response daphnids. 6 treatment groups 6 replicates treatment group, 5 individuals replicates.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/quantal_dat_nested.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data from Acute Studies — quantal_dat_nested","text":"","code":"quantal_dat_nested"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/quantal_dat_nested.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data from Acute Studies — quantal_dat_nested","text":"object class grouped_df (inherits tbl_df, tbl, data.frame) 2 rows 2 columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/rankTransform.html","id":null,"dir":"Reference","previous_headings":"","what":"Rank Transform Data Using Blom's Method — rankTransform","title":"Rank Transform Data Using Blom's Method — rankTransform","text":"function performs rank transformation data using Blom's method, equivalent SAS PROC RANK NORMAL=BLOM TIES=MEAN options. transformation applies formula (r-3/8)/(n+1/4) r rank n sample size.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/rankTransform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rank Transform Data Using Blom's Method — rankTransform","text":"","code":"rankTransform(Data, VecName)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/rankTransform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rank Transform Data Using Blom's Method — rankTransform","text":"Data data frame containing variable transformed VecName name variable data frame transformed","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/rankTransform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rank Transform Data Using Blom's Method — rankTransform","text":"data frame additional column 'TransformedResponse' containing rank-transformed values","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/rankTransform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rank Transform Data Using Blom's Method — rankTransform","text":"","code":"test_data <- data.frame(Value = c(5, 2, 7, 2, 9, 3)) transformed_data <- rankTransform(test_data, \"Value\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/reshape_drcData.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape the wide data to long data — reshape_drcData","title":"Reshape the wide data to long data — reshape_drcData","text":"Reshape wide data long data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/reshape_drcData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape the wide data to long data — reshape_drcData","text":"","code":"reshape_drcData(dat, replicate_col = \"Replicates\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/reshape_drcData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape the wide data to long data — reshape_drcData","text":"dat data table Replicate columns dose groups replicate_col name replicate column columns need retained identifier columns.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/reshape_drcData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape the wide data to long data — reshape_drcData","text":"long format dat","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/reshape_drcData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape the wide data to long data — reshape_drcData","text":"","code":"reshape_drcData(collembola_juveniles) ## note collembola_juveniles is fake data. #> # A tibble: 40 × 4 #>    Replicates Treatment Response  Dose #>         <int> <chr>        <dbl> <dbl> #>  1          1 Control        248     0 #>  2          1 18             146    18 #>  3          1 32             116    32 #>  4          1 56             255    56 #>  5          1 100            291   100 #>  6          1 178            244   178 #>  7          1 316            122   316 #>  8          1 562            125   562 #>  9          1 1000           271  1000 #> 10          2 Control        388     0 #> # ℹ 30 more rows"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Run RSCABS test (DEPRECATED) — runRSCABS","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"DEPRECATED: Please use step_down_RSCABS() instead new code. Runs Rao-Scott adjusted Cochran-Armitage trend test slices (RSCABS) analysis.function adapted archived version RSCABS developed Joe Swintek et al CC0 license. updated anymore included validation purpose. modern replacement step_down_RSCABS().","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"","code":"runRSCABS(Data, Treatment, Replicate = \"\", Effects = \"\", test.type = \"RS\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"Data standard data set tall format.  Every row indicates organism. data set must contain columns treatment level every tested histological endpoint. Treatment name column contains information treatment level. Increasing values indicate higher treatments. Replicate name column contains information replicate structure.  replicate specified default running \"CA\" test type. Effects endpoint tested.  Defaults columns integers less 20. analysis assumes higher scores indicate worse outcome. test.type Indicate type analysis performed.  Use \"RS\" select Rao-Scott adjustment Cochran-Armitage test \"CA\" ignore adjustment.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"table test results treatment injury score.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"function deprecated. new analyses, please use modern implementation step_down_RSCABS() provides: Better error handling input validation flexible data input formats Improved statistical methodology Better documentation examples","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"Green, John W. Springer, Timothy . Saulnier, Amy N. Swintek, Joe, (2014) Statistical analysis histopathological endpoints. Environmental Toxicology Chemistry, 33(5), 1108-1116","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"Joe Swintek","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/runRSCABS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run RSCABS test (DEPRECATED) — runRSCABS","text":"","code":"if (FALSE) { # \\dontrun{ ## Not run: #Take the subset corresponding to F0-females of 16 weeks of age data(exampleHistData) exampleHistData.sub<-exampleHistData[which(exampleHistData$Generation=='F2' &              exampleHistData$Genotypic_Sex=='Female' & exampleHistData$Age=='16_wk' ),  ]  #Run RSCABS  eampleResults<-runRSCABS(exampleHistData.sub,'Treatment',                           'Replicate',test.type='RS') } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_RSCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","text":"function wrapper performs Rao-Scott adjusted Cochran-Armitage trend test clustered binary data.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_RSCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","text":"","code":"run_RSCA(group, replicate, affected, total, correction = 0)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_RSCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","text":"group Vector treatment group identifiers replicate Vector replicate/tank identifiers within treatment groups affected Vector counts affected subjects (fish injuries) replicate total Vector total subjects (fish) replicate correction continuity correction 1, default 0, can changed 0.5.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_RSCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","text":"list containing: interm_values tibble intermediate values Rao-Scott adjustment Z Z-statistic Cochran-Armitage trend test","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_RSCA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","text":"function combines Rao-Scott adjustment Cochran-Armitage trend test analyze dose-response relationships clustered data. first calculates adjusted values accounting clustering, uses values perform trend test. p-value can calculated using: 2 * (1 - pnorm(abs(Z)))","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_RSCA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","text":"Originally Allen Olmstead","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_RSCA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test — run_RSCA","text":"","code":"# Test for trend in injury rates across treatment groups # Considering S1, S2, and S3 as \"affected\" result <- run_RSCA(   dat_bcs1$tmt,   dat_bcs1$tank,   dat_bcs1$S1 + dat_bcs1$S2 + dat_bcs1$S3,   dat_bcs1$total )  # View intermediate values print(result$interm_values) #> # A tibble: 5 × 10 #>   grp       x     n     m p_hat       b       v     D n_tilde x_tilde #>   <chr> <dbl> <dbl> <int> <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl> #> 1 C         6    16     4 0.375 0.0146  0.00521  1       16      6    #> 2 SC       10    16     4 0.625 0.0146  0.0156   1.07    15      9.38 #> 3 T1        3    16     4 0.188 0.00952 0.0143   1.50    10.6    1.99 #> 4 T2        7    16     4 0.438 0.0154  0.0143   1       16      7    #> 5 T3        8    16     4 0.5   0.0156  0.0312   2        8      4     # View Z-statistic print(result$Z) #> [1] 0.01966517  # Calculate p-value p_value <- 2 * (1 - pnorm(abs(result$Z))) print(paste(\"p-value:\", p_value)) #> [1] \"p-value: 0.984310478271696\""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_all_threshold_tests.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Rao-Scott Adjusted Cochran-Armitage Trend Tests for All Thresholds — run_all_threshold_tests","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Tests for All Thresholds — run_all_threshold_tests","text":"function performs Rao-Scott adjusted Cochran-Armitage trend test multiple injury thresholds, providing comprehensive analysis dose-response relationships different severity levels.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_all_threshold_tests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Tests for All Thresholds — run_all_threshold_tests","text":"","code":"run_all_threshold_tests(   data,   max_score = NULL,   min_score = 1,   score_cols = NULL,   treatment_col = \"tmt\",   replicate_col = \"tank\",   total_col = \"total\",   direction = \"greater\",   alternative = \"two.sided\",   include_fisher = TRUE )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_all_threshold_tests.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Tests for All Thresholds — run_all_threshold_tests","text":"data data frame containing fish injury data max_score Maximum score value consider (default: NULL, auto-detected) min_score Minimum score value consider (default: 1) score_cols Character vector column names containing injury scores (default: NULL, auto-detected) treatment_col Name column containing treatment groups (default: \"tmt\") replicate_col Name column containing tank/replicate IDs (default: \"tank\") total_col Name column containing total counts (default: \"total\") direction Character string indicating threshold direction: \"greater\" \\ge threshold, \"less\" \\le threshold (default: \"greater\") alternative Character string specifying alternative hypothesis: \"two.sided\" (default), \"greater\" (proportion increases treatment level), \"less\" (proportion decreases treatment level) include_fisher Logical indicating whether use Fisher's exact test RSCA fails (default: TRUE)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_all_threshold_tests.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Tests for All Thresholds — run_all_threshold_tests","text":"list containing: results Data frame test results threshold proportions Data frame proportions affected fish treatment threshold detailed_results List detailed results threshold","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_all_threshold_tests.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Tests for All Thresholds — run_all_threshold_tests","text":"","code":"# Example data fish_data <- data.frame(   tmt = rep(c(\"Control\", \"Low\", \"Medium\", \"High\"), each = 3),   tank = paste0(rep(c(\"Control\", \"Low\", \"Medium\", \"High\"), each = 3),                 rep(1:3, times = 4)),   S0 = c(8,7,9, 6,5,7, 4,5,3, 2,3,1),   S1 = c(2,2,1, 3,4,2, 4,3,5, 4,3,5),   S2 = c(0,1,0, 1,1,1, 2,2,1, 3,3,3),   S3 = c(0,0,0, 0,0,0, 0,0,1, 1,1,1),   S4 = c(0,0,0, 0,0,0, 0,0,0, 0,0,0),   total = rep(10, 12) )  # Run two-sided tests for all thresholds all_results <- run_all_threshold_tests(fish_data) #> Warning: Some treatment groups have zero affected individuals at threshold S3+. RSCA test may not be valid. #> Warning: Some treatment groups have zero affected individuals at threshold S4+. RSCA test may not be valid.  # Run one-sided tests (proportion increases with treatment level) all_results_greater <- run_all_threshold_tests(   fish_data,   alternative = \"greater\" ) #> Warning: Some treatment groups have zero affected individuals at threshold S3+. RSCA test may not be valid. #> Warning: Some treatment groups have zero affected individuals at threshold S4+. RSCA test may not be valid.  # View results table print(all_results$results) #>   Threshold Z_statistic    P_value Has_zero_counts Alternative #> 1       S1+   1.9595918 0.05004352           FALSE   two.sided #> 2       S2+   0.5880787 0.55647949           FALSE   two.sided #> 3       S3+          NA 0.19127234            TRUE   two.sided #> 4       S4+          NA 1.00000000            TRUE   two.sided #>                            Method #> 1                RSCA (two.sided) #> 2                RSCA (two.sided) #> 3 Fisher's Exact Test (two.sided) #> 4 Fisher's Exact Test (two.sided) print(all_results_greater$results) #>   Threshold Z_statistic    P_value Has_zero_counts Alternative #> 1       S1+   1.9595918 0.02502176           FALSE     greater #> 2       S2+   0.5880787 0.27823974           FALSE     greater #> 3       S3+          NA 0.19127234            TRUE     greater #> 4       S4+          NA 1.00000000            TRUE     greater #>                          Method #> 1                RSCA (greater) #> 2                RSCA (greater) #> 3 Fisher's Exact Test (greater) #> 4 Fisher's Exact Test (greater)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_threshold_RSCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test for a Specific Injury Threshold — run_threshold_RSCA","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test for a Specific Injury Threshold — run_threshold_RSCA","text":"function performs Rao-Scott adjusted Cochran-Armitage trend test specific injury threshold, counting fish injuries threshold \"affected\".","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_threshold_RSCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test for a Specific Injury Threshold — run_threshold_RSCA","text":"","code":"run_threshold_RSCA(   data,   threshold,   score_cols = NULL,   treatment_col = \"tmt\",   replicate_col = \"tank\",   total_col = \"total\",   direction = \"greater\",   alternative = \"two.sided\" )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_threshold_RSCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test for a Specific Injury Threshold — run_threshold_RSCA","text":"data data frame containing fish injury data threshold Numeric value indicating injury threshold (e.g., 1 S1+) score_cols Character vector column names containing injury scores (default: NULL, auto-detected) treatment_col Name column containing treatment groups (default: \"tmt\") replicate_col Name column containing tank/replicate IDs (default: \"tank\") total_col Name column containing total counts (default: \"total\") direction Character string indicating threshold direction: \"greater\" \\ge threshold, \"less\" \\le threshold (default: \"greater\") alternative Character string specifying alternative hypothesis: \"two.sided\" (default), \"greater\" (proportion increases treatment level), \"less\" (proportion decreases treatment level)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_threshold_RSCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test for a Specific Injury Threshold — run_threshold_RSCA","text":"list containing: threshold numeric threshold value threshold_label Character label threshold (e.g., \"S1+\") Z Z-statistic RSCA test p_value P-value based specified alternative hypothesis alternative alternative hypothesis used interm_values Intermediate values Rao-Scott adjustment has_zero_counts Logical indicating treatment group zero affected individuals affected_counts Data frame showing affected counts treatment group","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/run_threshold_RSCA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Rao-Scott Adjusted Cochran-Armitage Trend Test for a Specific Injury Threshold — run_threshold_RSCA","text":"","code":"# Example data fish_data <- data.frame(   tmt = rep(c(\"Control\", \"Low\", \"Medium\", \"High\"), each = 3),   tank = paste0(rep(c(\"Control\", \"Low\", \"Medium\", \"High\"), each = 3),                 rep(1:3, times = 4)),   S0 = c(8,7,9, 6,5,7, 4,5,3, 2,3,1),   S1 = c(2,2,1, 3,4,2, 4,3,5, 4,3,5),   S2 = c(0,1,0, 1,1,1, 2,2,1, 3,3,3),   S3 = c(0,0,0, 0,0,0, 0,0,1, 1,1,1),   S4 = c(0,0,0, 0,0,0, 0,0,0, 0,0,0),   total = rep(10, 12) )  # Two-sided test for trend in S2+ injuries result_two_sided <- run_threshold_RSCA(fish_data, threshold = 2)  # One-sided test (proportion increases with treatment level) result_greater <- run_threshold_RSCA(fish_data, threshold = 2,                                     alternative = \"greater\")  # One-sided test (proportion decreases with treatment level) result_less <- run_threshold_RSCA(fish_data, threshold = 2,                                  alternative = \"less\")"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simDRdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper around rdrm — simDRdata","title":"Wrapper around rdrm — simDRdata","text":"Wrapper around rdrm generate data frame tibble object instead list two matrices","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simDRdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper around rdrm — simDRdata","text":"","code":"simDRdata(   nosim,   fct,   mpar,   xerror,   xpar = 1,   yerror = \"rnorm\",   ypar = c(0, 1),   onlyY = FALSE )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simDRdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper around rdrm — simDRdata","text":"nosim numeric. number simulated curves returned. fct list. built-function package drc list similar components. mpar numeric. model parameters supplied fct. xerror numeric character. distribution dose values. xpar numeric vector supplying parameter values defining distribution dose values. xerror distribution remember number dose values also part argument (first argument). yerror numeric character. error distribution response values. ypar numeric vector supplying parameter values defining error distribution response values. onlyY logical. TRUE response values returned (useful simulations). Otherwise dose values response values (binomial data also weights) returned.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simDRdata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper around rdrm — simDRdata","text":"data frame","code":""},{"path":[]},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simDRdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper around rdrm — simDRdata","text":"","code":"if (FALSE) { # \\dontrun{ dat <- rdrm(1, LL.3(), c(`b:(Intercept)` = 3, `d:(Intercept)` = 8, `e:(Intercept)` = 3), xerror=c(0, 0, 0, 0, 0, 0, 0.94, 0.94, 0.94, 1.88, 1.88, 1.88, 3.75,          3.75, 3.75, 7.5, 7.5, 7.5, 15, 15, 15, 30, 30, 30), yerror = \"rnorm\", ypar = c(0, 0.6)) dat <- data.frame(Dose = dat$x[1,], Response = dat$y[1,]) simDRdata(10, LL.3(), c(`b:(Intercept)` = 3, `d:(Intercept)` = 8, `e:(Intercept)` = 3), xerror=c(0, 0, 0, 0, 0, 0, 0.94, 0.94, 0.94, 1.88, 1.88, 1.88, 3.75,          3.75, 3.75, 7.5, 7.5, 7.5, 15, 15, 15, 30, 30, 30), yerror = \"rnorm\", ypar = c(0, 0.6)) } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simplifyTreatment.html","id":null,"dir":"Reference","previous_headings":"","what":"Resolve the excel datasheet number issues — simplifyTreatment","title":"Resolve the excel datasheet number issues — simplifyTreatment","text":"simplifyTreatment function designed handle simplify treatment vector, can either factor character vector. primary goal function resolve issues numeric precision often arise Excel datasheets, numbers represented excessive decimal places, like 12.300000000000001 8.3579999999999.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simplifyTreatment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resolve the excel datasheet number issues — simplifyTreatment","text":"","code":"simplifyTreatment(trt)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simplifyTreatment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resolve the excel datasheet number issues — simplifyTreatment","text":"trt treatment vector, either factor character","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simplifyTreatment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resolve the excel datasheet number issues — simplifyTreatment","text":"simplified vector, either factor character vector, depending x","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simplifyTreatment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resolve the excel datasheet number issues — simplifyTreatment","text":"","code":"x <- structure(c(   1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,   3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 1L, 1L, 1L,   1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,   5L, 5L, 5L, 6L, 6L, 6L, 6L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,   2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L,   6L ), levels = c(   \"Control\", \"1\", \"3.51\", \"12.300000000000001\",   \"42.9\", \"150\" ), class = \"factor\") simplifyTreatment(x) #>  [1] Control Control Control Control Control Control 1       1       1       #> [10] 1       3.51    3.51    3.51    3.51    12.3    12.3    12.3    12.3    #> [19] 42.9    42.9    42.9    42.9    150     150     150     150     Control #> [28] Control Control Control Control Control 1       1       1       1       #> [37] 3.51    3.51    3.51    3.51    12.3    12.3    12.3    12.3    42.9    #> [46] 42.9    42.9    42.9    150     150     150     150     Control Control #> [55] Control Control Control Control 1       1       1       1       3.51    #> [64] 3.51    3.51    3.51    12.3    12.3    12.3    12.3    42.9    42.9    #> [73] 42.9    42.9    150     150     150     150     #> Levels: Control 1 3.51 12.3 42.9 150"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simulate_dose_response.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Hierarchical Dose-Response Data with Inhomogeneous Variance — simulate_dose_response","title":"Simulate Hierarchical Dose-Response Data with Inhomogeneous Variance — simulate_dose_response","text":"function simulates dose-response data hierarchical structure: n doses, m tanks per dose, optionally k individuals per tank, variance components can vary dose level.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simulate_dose_response.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Hierarchical Dose-Response Data with Inhomogeneous Variance — simulate_dose_response","text":"","code":"simulate_dose_response(   n_doses,   dose_range = c(0, 20),   m_tanks = 3,   k_individuals = 10,   var_tank = 4,   var_individual = 2,   include_individuals = TRUE,   response_function = NULL,   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simulate_dose_response.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Hierarchical Dose-Response Data with Inhomogeneous Variance — simulate_dose_response","text":"n_doses Number dose levels dose_range Vector length 2 specifying min max dose values m_tanks Number tanks per dose k_individuals Number individuals per tank (used include_individuals = TRUE) var_tank Variance tank level. Can single value vector length n_doses. var_individual Variance individual level. Can single value vector length n_doses. include_individuals Logical, whether simulate individual-level data (TRUE) tank-level data (FALSE) response_function Function calculates response given dose ... Additional parameters pass response_function","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/simulate_dose_response.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Hierarchical Dose-Response Data with Inhomogeneous Variance — simulate_dose_response","text":"data frame containing simulated dose-response data","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownRSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs the step down aspect of RSCABS — stepDownRSCABS","title":"Performs the step down aspect of RSCABS — stepDownRSCABS","text":"Performs step aspect RSCABS","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownRSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs the step down aspect of RSCABS — stepDownRSCABS","text":"","code":"stepDownRSCABS(TestK, x.i.j, n.i.j, m.i, Effect, test.type)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownRSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs the step down aspect of RSCABS — stepDownRSCABS","text":"TestK severity score tested x..j Matrix containing number observed \"successes\" replicate treatment j. n..j Matrix containing number observations replicate treatment j. m.Matrix number units treatment/replicate combination. Effect end point tested. test.type Indicate type  analysis performed. Use \"RS\" select Rao-Scott adjustment Cochran-Armitage test \"CA\" ignore adjustment","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownRSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs the step down aspect of RSCABS — stepDownRSCABS","text":"Result.K intermediary result.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownRSCABS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Performs the step down aspect of RSCABS — stepDownRSCABS","text":"Joe Swintek","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownTrendTestBinom.html","id":null,"dir":"Reference","previous_headings":"","what":"Step-down Cochran-Armitage trend test with consistent scoring — stepDownTrendTestBinom","title":"Step-down Cochran-Armitage trend test with consistent scoring — stepDownTrendTestBinom","text":"Step-Cochran-Armitage trend test consistent scoring","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownTrendTestBinom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step-down Cochran-Armitage trend test with consistent scoring — stepDownTrendTestBinom","text":"","code":"stepDownTrendTestBinom(   successes,   totals,   doses,   scoring = c(\"doses\", \"ranks\", \"log_doses\", \"equal_spaced\"),   alternative = c(\"two.sided\", \"greater\", \"less\"),   rao_scott = FALSE,   phi = NULL,   phi_method = c(\"simple\", \"trend_adjusted\"),   tarone_results = NULL )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownTrendTestBinom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step-down Cochran-Armitage trend test with consistent scoring — stepDownTrendTestBinom","text":"successes Vector success counts totals Vector total trials doses Vector dose levels scoring Method defining trend: \"doses\", \"ranks\", \"log_doses\", \"equal_spaced\" alternative Direction test rao_scott Whether apply Rao-Scott correction phi Overdispersion parameter (NULL, estimated Tarone test) phi_method simple trend_adjusted description tarone_results Optional results Tarone.trend.test phi estimation","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownTrendTestBinom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Step-down Cochran-Armitage trend test with consistent scoring — stepDownTrendTestBinom","text":"stepDownTrendBinom object consistent scoring list class \"stepDownTrendBinom\" containing: method Description test performed data.name Description data p.value Matrix p-values step statistic Matrix test statistics step alternative alternative hypothesis doses dose levels used noec Observed Effect Concentration (highest dose significant effect) loec Lowest Observed Effect Concentration (lowest dose significant effect)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownTrendTestBinom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Step-down Cochran-Armitage trend test with consistent scoring — stepDownTrendTestBinom","text":"step-procedure starts dose groups sequentially removes highest dose significant trend detected two groups remain. helps identify lowest dose significant effect occurs. Cochran-Armitage test appropriate detecting trends binomial proportions across ordered groups. Rao-Scott correction adjusts potential overdispersion binomial data, common toxicological studies.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepDownTrendTestBinom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Step-down Cochran-Armitage trend test with consistent scoring — stepDownTrendTestBinom","text":"","code":"# Example with simulated data successes <- c(20, 18, 15, 10, 5) totals <- rep(20, 5) doses <- c(0, 1, 2, 5, 10)  # Run step-down test with Cochran-Armitage result <- stepDownTrendTestBinom(successes, totals, doses) print(result) #>  #> Step-down Cochran-Armitage test for trend (doses scoring) (doses scoring)  #>  #> data: successes out of totals at doses 0, 1, 2, 5, 10 with doses scoring  #>  #> Step-down results: #>        Doses_Included Statistic      P_Value #> Step 1 0, 1, 2, 5, 10 -5.746549 9.108323e-09 #> Step 2     0, 1, 2, 5 -4.090480 4.304814e-05 #> Step 3        0, 1, 2 -2.462659 1.379110e-02 #> Step 4           0, 1 -1.450953 1.467931e-01 #>  #> Alternative hypothesis: two.sided  #> NOEC: 1  #> LOEC: 2   # Run with Rao-Scott correction result_rs <- stepDownTrendTestBinom(successes, totals, doses, rao_scott = TRUE) #> Estimated phi = 8.571 using simple method with doses scoring print(result_rs) #>  #> Step-down Rao-Scott corrected Cochran-Armitage test for trend (doses scoring) (doses scoring)  #>  #> data: successes out of totals at doses 0, 1, 2, 5, 10 with doses scoring  #>  #> Step-down results: #>        Doses_Included  Statistic    P_Value #> Step 1 0, 1, 2, 5, 10 -1.9628953 0.04965834 #> Step 2     0, 1, 2, 5 -1.3972184 0.16234791 #> Step 3        0, 1, 2 -0.8411904 0.40024125 #> Step 4           0, 1 -0.4956136 0.62016705 #>  #> Alternative hypothesis: two.sided  #> NOEC: 5  #> LOEC: 10"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepKRSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"plotRSCABS — stepKRSCABS","title":"plotRSCABS — stepKRSCABS","text":"Steps severity score given effect","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepKRSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plotRSCABS — stepKRSCABS","text":"","code":"stepKRSCABS(Effect, Data.Prep, Treatment, Replicate, test.type)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepKRSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plotRSCABS — stepKRSCABS","text":"Effect Endpoint tested. Data.Prep Data prepared prepDataRSCABS. Treatment Name treatment variable. Replicate Name replicate variable. test.type Indicate type analysis performed.  Use \"RS\" select Rao-Scott adjustment Cochran-Armitage test \"CA\" ignore adjustment.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepKRSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plotRSCABS — stepKRSCABS","text":"Results.Effect Results.Effect intermediary step results.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepKRSCABS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"plotRSCABS — stepKRSCABS","text":"internal function stepping severity score endpoint.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/stepKRSCABS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"plotRSCABS — stepKRSCABS","text":"Joe Swintek","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/step_down_RSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Step-Down Rao-Scott Adjusted Cochran-Armitage Trend Test Procedure — step_down_RSCABS","title":"Perform Step-Down Rao-Scott Adjusted Cochran-Armitage Trend Test Procedure — step_down_RSCABS","text":"function performs step-procedure using Rao-Scott adjusted Cochran-Armitage trend tests (RSCABS). procedure systematically excludes highest treatment groups identify treatment level dose-response relationship becomes significant.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/step_down_RSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Step-Down Rao-Scott Adjusted Cochran-Armitage Trend Test Procedure — step_down_RSCABS","text":"","code":"step_down_RSCABS(   data,   treatment_col = \"tmt\",   treatment_order = NULL,   max_score = NULL,   min_score = 1,   score_cols = NULL,   replicate_col = \"tank\",   total_col = \"total\",   direction = \"greater\",   alternative = \"greater\",   include_fisher = TRUE )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/step_down_RSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Step-Down Rao-Scott Adjusted Cochran-Armitage Trend Test Procedure — step_down_RSCABS","text":"data data frame containing fish injury data treatment_col Name column containing treatment groups (default: \"tmt\") treatment_order Optional vector specifying order treatment groups lowest highest dose. NULL, alphabetical order used (default: NULL) max_score Maximum score value consider (default: NULL, auto-detected) min_score Minimum score value consider (default: 1) score_cols Character vector column names containing injury scores (default: NULL, auto-detected) replicate_col Name column containing tank/replicate IDs (default: \"tank\") total_col Name column containing total counts (default: \"total\") direction Character string indicating threshold direction: \"greater\" \\ge threshold, \"less\" \\le threshold (default: \"greater\") alternative Character string specifying alternative hypothesis: \"two.sided\", \"greater\" (proportion increases treatment level), \"less\" (proportion decreases treatment level) (default: \"greater\") include_fisher Logical indicating whether use Fisher's exact test RSCA fails (default: TRUE)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/step_down_RSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Step-Down Rao-Scott Adjusted Cochran-Armitage Trend Test Procedure — step_down_RSCABS","text":"list class \"StepDownRSCABS\" containing: combined_results Data frame test results steps thresholds step_results List RSCABS objects step summary Summary significant findings step lowest_significant Information lowest significant treatment level parameters List parameters used analysis","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/step_down_RSCABS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Step-Down Rao-Scott Adjusted Cochran-Armitage Trend Test Procedure — step_down_RSCABS","text":"","code":"# Example data fish_data <- data.frame(   tmt = c(rep(\"Control\", 8), rep(\"Low\", 4), rep(\"Medium\", 4), rep(\"High\", 4)),   tank = c(paste0(\"C\", 1:8), paste0(\"L\", 1:4), paste0(\"M\", 1:4), paste0(\"H\", 1:4)),   S0 = c(3, 2, 3, 2, 2, 1, 2, 3, 3, 3, 4, 2, 2, 3, 2, 2, 2, 3, 1, 2),   S1 = c(1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0),   S2 = c(0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1),   S3 = c(0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1),   total = c(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4) )  # Run step-down procedure with default parameters result <- step_down_RSCABS(fish_data, treatment_col = \"tmt\",                           treatment_order = c(\"Control\", \"Low\", \"Medium\", \"High\")) #> Warning: Some treatment groups have zero affected individuals at threshold S3+. RSCA test may not be valid. #> Warning: Some treatment groups have zero affected individuals at threshold S3+. RSCA test may not be valid. #> Warning: Some treatment groups have zero affected individuals at threshold S3+. RSCA test may not be valid.  # Print results print(result) #> Step-Down RSCABS Analysis #> ======================== #>  #> Parameters: #>   Direction: greater  #>   Alternative hypothesis: greater  #>   Treatment levels: Control, Low, Medium, High  #>  #> Summary of findings: #> Step 1 : Included treatments: Control, Low, Medium, High  #>   No significant findings #> Step 2 : Included treatments: Control, Low, Medium  #>   No significant findings #> Step 3 : Included treatments: Control, Low  #>   No significant findings  # Plot results plot(result)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summary.StepDownRSCABS.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for StepDownRSCABS objects — summary.StepDownRSCABS","title":"Summary method for StepDownRSCABS objects — summary.StepDownRSCABS","text":"Summary method StepDownRSCABS objects","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summary.StepDownRSCABS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for StepDownRSCABS objects — summary.StepDownRSCABS","text":"","code":"# S3 method for class 'StepDownRSCABS' summary(object, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summary.StepDownRSCABS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for StepDownRSCABS objects — summary.StepDownRSCABS","text":"object StepDownRSCABS object ... Additional arguments (used)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summary.StepDownRSCABS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for StepDownRSCABS objects — summary.StepDownRSCABS","text":"list summary information","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summaryZG.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Williams Test results. — summaryZG","title":"Summary Williams Test results. — summaryZG","text":"Summary Williams Test results.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summaryZG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Williams Test results. — summaryZG","text":"","code":"summaryZG(object, verbose = F, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summaryZG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Williams Test results. — summaryZG","text":"object William test result object verbose whether print intermediate results. ... additional parameters passed function, placeholder","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summaryZG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Williams Test results. — summaryZG","text":"William test results","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/summaryZG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Williams Test results. — summaryZG","text":"","code":"## Example from Sachs (1997, p. 402) x <- c(106, 114, 116, 127, 145,        110, 125, 143, 148, 151,        136, 139, 149, 160, 174) g <- gl(3,5) levels(g) <- c(\"0\", \"I\", \"II\")  ## Williams Test res <- PMCMRplus::williamsTest(x ~ g) summaryZG(res) ## return a data frame instead of a list. #>                t'-value df t'-crit decision alpha #> mu1 - ctr <= 0    1.357 12   1.782   accept  0.05 #> mu2 - ctr <= 0    2.950 12   1.873   reject  0.05"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tarone_with_trend_removal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to perform Tarone test with trend removal and calculate phi — tarone_with_trend_removal","title":"Internal function to perform Tarone test with trend removal and calculate phi — tarone_with_trend_removal","text":"Internal function perform Tarone test trend removal calculate phi","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tarone_with_trend_removal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to perform Tarone test with trend removal and calculate phi — tarone_with_trend_removal","text":"","code":"tarone_with_trend_removal(successes, totals, scores)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tarone_with_trend_removal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to perform Tarone test with trend removal and calculate phi — tarone_with_trend_removal","text":"successes Vector success counts (summarized dose) totals Vector total trials (summarized dose) scores Vector scores defining trend","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/test_overdispersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to test for overdispersion in binomial data using glm approach — test_overdispersion","title":"Function to test for overdispersion in binomial data using glm approach — test_overdispersion","text":"Function test overdispersion binomial data using glm approach","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/test_overdispersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to test for overdispersion in binomial data using glm approach — test_overdispersion","text":"","code":"test_overdispersion(successes, totals, model = NULL)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/test_overdispersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to test for overdispersion in binomial data using glm approach — test_overdispersion","text":"successes Numeric vector successes (e.g., number survivors). totals Numeric vector total observations (e.g., total organisms). model fitted binomial GLM predictors accounted . (default NULL)","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/test_overdispersion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to test for overdispersion in binomial data using glm approach — test_overdispersion","text":"list dispersion test results","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/treatment2dose.html","id":null,"dir":"Reference","previous_headings":"","what":"Change Treatment groups to numerical dose — treatment2dose","title":"Change Treatment groups to numerical dose — treatment2dose","text":"Change Treatment groups numerical dose","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/treatment2dose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change Treatment groups to numerical dose — treatment2dose","text":"","code":"treatment2dose(x)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/treatment2dose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change Treatment groups to numerical dose — treatment2dose","text":"x treatment groups numbers \"Control\"","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/treatment2dose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change Treatment groups to numerical dose — treatment2dose","text":"numeric vector dose","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/treatment2dose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change Treatment groups to numerical dose — treatment2dose","text":"","code":"treatment2dose(c(\"Control\",\"0.1\",\"1\",\"10\")) #> [1]  0.0  0.1  1.0 10.0"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.data.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"TSK Analysis for Data Frame Input — tsk.data.frame","title":"TSK Analysis for Data Frame Input — tsk.data.frame","text":"function performs TSK analysis data frame input.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.data.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TSK Analysis for Data Frame Input — tsk.data.frame","text":"","code":"# S3 method for class 'data.frame' tsk(input, control = 0, trim = 0, conf.level = 0.95, use.log.doses = TRUE, ...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.data.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TSK Analysis for Data Frame Input — tsk.data.frame","text":"input data frame containing columns x (doses), n (total counts), r (response counts). control numeric value indicating control dose (default 0). trim numeric value indicating trim level (default 0). conf.level numeric value indicating confidence level (default 0.95). use.log.doses logical value indicating whether use log-transformed doses (default TRUE). ... Additional arguments passed function.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.data.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TSK Analysis for Data Frame Input — tsk.data.frame","text":"result TSK analysis.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.html","id":null,"dir":"Reference","previous_headings":"","what":"Trimmed Spearman-Karber Method by brsr — tsk","title":"Trimmed Spearman-Karber Method by brsr — tsk","text":"function adapted single function package tsk developed GPL3 license. included validation purpose.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trimmed Spearman-Karber Method by brsr — tsk","text":"","code":"tsk(...)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trimmed Spearman-Karber Method by brsr — tsk","text":"... inputs","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trimmed Spearman-Karber Method by brsr — tsk","text":"tsk estimations","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Trimmed Spearman-Karber Method by brsr — tsk","text":"https://github.com/brsr/tsk","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"TSK Analysis for Numeric Input — tsk.numeric","title":"TSK Analysis for Numeric Input — tsk.numeric","text":"function performs TSK analysis numeric input.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TSK Analysis for Numeric Input — tsk.numeric","text":"","code":"# S3 method for class 'numeric' tsk(   x,   n,   r,   control = 0,   trim = 0,   conf.level = 0.95,   use.log.doses = TRUE,   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TSK Analysis for Numeric Input — tsk.numeric","text":"x numeric vector doses. n numeric vector total counts. r numeric vector response counts. control numeric value indicating control dose (default 0). trim numeric value indicating trim level (default 0). conf.level numeric value indicating confidence level (default 0.95). use.log.doses logical value indicating whether use log-transformed doses (default TRUE). ... Additional arguments passed function.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk.numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TSK Analysis for Numeric Input — tsk.numeric","text":"result TSK analysis.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk_auto.html","id":null,"dir":"Reference","previous_headings":"","what":"Auto-trimmed TSK Analysis — tsk_auto","title":"Auto-trimmed TSK Analysis — tsk_auto","text":"function automatically determines appropriate trim level TSK analysis applies . first tries trimming, fails due responses spanning required range, automatically calculates applies minimum required trim level based data characteristics.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk_auto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Auto-trimmed TSK Analysis — tsk_auto","text":"","code":"tsk_auto(x, ...)  # S3 method for class 'numeric' tsk_auto(   x,   n,   r,   control = 0,   conf.level = 0.95,   use.log.doses = TRUE,   max.trim = 0.45,   ... )  # S3 method for class 'data.frame' tsk_auto(   x,   control = 0,   conf.level = 0.95,   use.log.doses = TRUE,   max.trim = 0.45,   ... )"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk_auto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Auto-trimmed TSK Analysis — tsk_auto","text":"x numeric vector doses (numeric method) data frame containing columns 'x', 'n', 'r' (data.frame method). ... Additional arguments passed tsk function. n numeric vector total counts (numeric method ). r numeric vector response counts (numeric method ). control numeric value indicating control dose (default 0). conf.level numeric value indicating confidence level (default 0.95). use.log.doses logical value indicating whether use log-transformed doses (default TRUE). max.trim numeric value indicating maximum allowed trim level (default 0.45, must < 0.5).","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk_auto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Auto-trimmed TSK Analysis — tsk_auto","text":"result TSK analysis automatic trimming applied.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk_auto.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Auto-trimmed TSK Analysis — tsk_auto","text":"automatic trimming triggered response proportions increase trim level 1-trim level, typically occurs responses close 0% 100% extreme doses.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/tsk_auto.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Auto-trimmed TSK Analysis — tsk_auto","text":"","code":"if (FALSE) { # \\dontrun{ # With numeric vectors - data that needs trimming doses <- c(0, 1, 2, 3, 4, 5) total <- rep(20, 6) responses <- c(0, 2, 8, 14, 18, 20)  # Goes from 0 to 100% result <- tsk_auto(doses, total, responses)  # With data frame - moderate responses that may not need trimming data <- data.frame(   x = c(0.1, 0.5, 1, 2, 4, 8),   n = rep(20, 6),   r = c(2, 5, 8, 12, 15, 17) ) result <- tsk_auto(data)  # Using hamilton dataset (if available) if (exists(\"hamilton\")) {   # Try with one of the hamilton datasets   result <- tsk_auto(hamilton$dr1a) } } # }"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/wide2long.html","id":null,"dir":"Reference","previous_headings":"","what":"Change from an expected wide format to long format — wide2long","title":"Change from an expected wide format to long format — wide2long","text":"Change expected wide format long format","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/wide2long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change from an expected wide format to long format — wide2long","text":"","code":"wide2long(widedat, cnames = 1, repnames = 1)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/wide2long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change from an expected wide format to long format — wide2long","text":"widedat data wide format cnames logical,1 0, whether use 1st row column names, 1 means 1st row need converted headers repnames whether 1st column Replicates column","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/wide2long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change from an expected wide format to long format — wide2long","text":"dataframe long format","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/wide2long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change from an expected wide format to long format — wide2long","text":"","code":"# Create a sample wide dataset widedat <- data.frame(   Replicates = c(\"Rep1\", \"Rep2\", \"Rep3\"),   Treatment1 = c(1.1, 2.2, 3.3),   Treatment2 = c(4.4, 5.5, 6.6) ) drcHelper:::wide2long(widedat, cnames = FALSE) #> # A tibble: 6 × 3 #>   Replicates Treatment  Response #>   <chr>      <chr>         <dbl> #> 1 Rep1       Treatment1      1.1 #> 2 Rep1       Treatment2      4.4 #> 3 Rep2       Treatment1      2.2 #> 4 Rep2       Treatment2      5.5 #> 5 Rep3       Treatment1      3.3 #> 6 Rep3       Treatment2      6.6"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/williamsTest_JG.html","id":null,"dir":"Reference","previous_headings":"","what":"Williams Test from the StatCharrms Package — williamsTest_JG","title":"Williams Test from the StatCharrms Package — williamsTest_JG","text":"function adapted archived version StatCharrms developed Joe Swintek et al CC0 license. updated anymore included validation purpose. recommend use williamsTest PMCMRplus package instead.","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/williamsTest_JG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Williams Test from the StatCharrms Package — williamsTest_JG","text":"","code":"williamsTest_JG(df, resp, trt, direction = \"decreasing\", SeIn = NULL)"},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/williamsTest_JG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Williams Test from the StatCharrms Package — williamsTest_JG","text":"df data frame resp name response string trt name response string direction direction test 'decreasing' 'increasing' SeIn standard error, default program selected. WilliamsTest can take different value case repeated measures","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/williamsTest_JG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Williams Test from the StatCharrms Package — williamsTest_JG","text":"Williams' test result","code":""},{"path":"https://bayer-group.github.io/drcHelper/index.html/reference/williamsTest_JG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Williams Test from the StatCharrms Package — williamsTest_JG","text":"","code":"## Williams Test x <- c(106, 114, 116, 127, 145,110, 125, 143, 148, 151, 136, 139, 149, 160, 174) g <- gl(3,5) levels(g) <- c(\"0\", \"I\", \"II\") PMCMRplus::williamsTest(x ~ g) #>  #> \t Williams trend test  #>  #> data:  x by g  #> alternative hypothesis:  greater  #>  #> H0 #>                t'-value df t'-crit decision alpha #> mu1 - ctr <= 0    1.357 12   1.782   accept  0.05 #> mu2 - ctr <= 0    2.950 12   1.873   reject  0.05 #> --- williamsTest_JG(data.frame(treatment_var = g,response_var=x), \"response_var\",\"treatment_var\",direction=\"increasing\") #>   treatment_var Y.Tilde    Y0 Se.Diff DF  Will TCrit Signif #> 2            II   151.6 121.6   10.17 12 2.950 1.873      * #> 1             I   135.4 121.6   10.17 12 1.357 1.782      ."}]
