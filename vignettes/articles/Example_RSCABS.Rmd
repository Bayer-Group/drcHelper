---
title: "RSCABS"
author: "Zhenglei Gao"
date: '2023-04-11'
output: html_document
---







## RSCABS

RSCABS (Rao-Scott Cochran-Armitage by slice) is designed to analyze histopathological results from standard toxicology experiments, for example the MEOGRT.

Steps in the testing procedure:

1.The Cochran-Armitage (CA) trend test was used to test a set of organisms for an increase in the presences (score $>$ 0) or absence (score = 0) of an effect with an increase in the dose concentration of the treatments.
2. The Rao-Scott (RS) adjustment controls for the similarity in each experiment unit / apparatus (*e.g.*, fish tank) by calculating an adjustment to the CA test statistic from correlation of organisms within each apparatuses.
3. The by slices (BS) part allows for testing at each severity score (*e.g.*, from 1 to 5) instead of just presences or absence. By slices works by splitting the severity scores associated with an endpoint into **two** groups based on the severity score being tested.  The RSCA test statistic is calculated based on these two groups.
4. Carry out a step-down procedure by excluding the highest treatment level in the analysis and recalculate the RSCA test statistic until the test stats is not significant or there is only control group left.

Current implementation used Rao-Scott correction always, potential inflated type-I error in slices with very low occurences. High resolution of scoring system (many categories) could be less powerful due to the violation of monotonicity.



```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE
)
```

```{r setup}
library(drcHelper)
library(tidyverse)
```


### Some Backgrounds

The Rao-Scott adjustment is a method to account for clustering in binary data. Using a fish injury dataset as an example, fish are clustered within tanks (replicates), which means observations within the same tank may be correlated. Standard statistical tests assume independent observations, which could lead to incorrect inference if clustering is ignored.

The adjustment works by:

1. Calculating the observed variance within treatment groups, accounting for clustering
2. Comparing this to the expected variance under a simple binomial model
3. Computing a design effect (D) as the ratio of these variances
4. Adjusting the sample sizes and counts by dividing by D

**What is the Cochran-Armitage Trend Test?**

The Cochran-Armitage trend test examines whether there is a linear trend in proportions across ordered categories. In this context, it tests whether the proportion of injured fish increases (or decreases) systematically with treatment level.

The test assigns scores to treatment groups (typically 1, 2, 3, ...) and calculates a Z-statistic that measures the strength of the linear trend.

## Example 1: synthetic dataset

I'll create a simulated dataset with Control and 3 treatment groups (T1, T2, T3), each with 4 tanks, and 6 fish per tank. The data will show a trend where higher treatment groups have more severe injuries (higher scores). Injury scores from S0 (no injury) to S4 (severe injury).

Treatment effects: 
- Control group has mostly healthy fish (S0)
- As treatment level increases, the proportion of higher injury scores increases
- T3 (highest treatment) has the most severe injuries

Variability:

- Small random variations in the probabilities for each tank
- This simulates natural tank-to-tank variability within treatment groups



```{r}
# Set seed for reproducibility
set.seed(123)

# Define parameters
treatments <- c("Control", "T1", "T2", "T3")
tanks_per_treatment <- 4
fish_per_tank <- 6
tank_labels <- paste0(rep(1:tanks_per_treatment, length(treatments)), 
                     rep(LETTERS[1:length(treatments)], each = tanks_per_treatment))

# Create base data frame
sim_data <- data.frame(
  tmt = rep(treatments, each = tanks_per_treatment),
  tank = tank_labels,
  total = fish_per_tank
)

# Define probability distributions for each treatment
# Format: list of vectors, where each vector contains probabilities for [S0, S1, S2, S3, S4]
# Trend: Control has mostly S0, T3 has more severe injuries
prob_distributions <- list(
  Control = c(0.80, 0.15, 0.03, 0.02, 0.00),  # Mostly healthy fish
  T1 = c(0.60, 0.25, 0.10, 0.04, 0.01),       # Slight increase in injuries
  T2 = c(0.40, 0.30, 0.15, 0.10, 0.05),       # Moderate increase in injuries
  T3 = c(0.20, 0.25, 0.25, 0.20, 0.10)        # Substantial increase in injuries
)

# Function to generate counts based on multinomial distribution
generate_counts <- function(n, probs) {
  # Add small random variation to probabilities (within tanks)
  varied_probs <- pmax(0, probs + rnorm(length(probs), 0, 0.03))
  varied_probs <- varied_probs / sum(varied_probs)  # Normalize to sum to 1
  
  # Generate counts using multinomial distribution
  counts <- rmultinom(1, n, varied_probs)
  return(counts)
}

# Generate injury counts for each tank
for (i in 1:nrow(sim_data)) {
  treatment <- sim_data$tmt[i]
  probs <- prob_distributions[[treatment]]
  
  counts <- generate_counts(fish_per_tank, probs)
  
  sim_data$S0[i] <- counts[1]
  sim_data$S1[i] <- counts[2]
  sim_data$S2[i] <- counts[3]
  sim_data$S3[i] <- counts[4]
  sim_data$S4[i] <- counts[5]
}

# Verify that the total counts match
sim_data$check_sum <- sim_data$S0 + sim_data$S1 + sim_data$S2 + sim_data$S3 + sim_data$S4
all(sim_data$check_sum == sim_data$total)  # Should be TRUE

# Remove the check column
sim_data$check_sum <- NULL

# Display the simulated data
print(sim_data)

# Calculate the average proportion of each score by treatment group
summary_by_treatment <- aggregate(
  cbind(S0, S1, S2, S3, S4) ~ tmt, 
  data = sim_data, 
  FUN = function(x) round(mean(x/fish_per_tank), 2)
)

print("Average proportion of each score by treatment:")
print(summary_by_treatment)

# Calculate the average severity score by treatment
sim_data$severity_score <- with(sim_data, 
                               (0*S0 + 1*S1 + 2*S2 + 3*S3 + 4*S4) / total)

avg_severity <- aggregate(severity_score ~ tmt, data = sim_data, FUN = mean)
print("Average severity score by treatment:")
print(avg_severity)

# Visualize the trend
if (requireNamespace("ggplot2", quietly = TRUE)) {
  library(ggplot2)
  
  # Convert to long format for plotting
  sim_data_long <- reshape2::melt(
    sim_data, 
    id.vars = c("tmt", "tank", "total"), 
    measure.vars = c("S0", "S1", "S2", "S3", "S4"),
    variable.name = "score",
    value.name = "count"
  )
  
  # Calculate proportions
  sim_data_long$proportion <- sim_data_long$count / sim_data_long$total
  
  # Plot
  ggplot(sim_data_long, aes(x = tmt, y = proportion, fill = score)) +
    geom_bar(stat = "identity", position = "stack") +
    labs(title = "Distribution of Injury Scores by Treatment",
         x = "Treatment Group",
         y = "Proportion of Fish",
         fill = "Injury Score") +
    theme_minimal() +
    scale_fill_brewer(palette = "YlOrRd")
  
  # Plot severity score
  ggplot(sim_data, aes(x = tmt, y = severity_score)) +
    geom_boxplot() +
    geom_jitter(width = 0.2, alpha = 0.5) +
    labs(title = "Average Injury Severity by Treatment",
         x = "Treatment Group",
         y = "Severity Score (weighted average)") +
    theme_minimal()
}
```


The dataset shows a clear trend of increasing injury severity across treatment groups. This can be seen in both the distribution of scores and the average severity score.



```{r}
# Define affected fish as those with any injury (S1-S4)
affected <- sim_data$S1 + sim_data$S2 + sim_data$S3 + sim_data$S4

# Run the Rao-Scott adjusted Cochran-Armitage test
result <- run_RSCA(
  group = sim_data$tmt,
  replicate = sim_data$tank,
  affected = affected,
  total = sim_data$total
)

# View results
print(result$interm_values)
print(paste("Z-statistic:", round(result$Z, 3)))
p_value <- 2 * (1 - pnorm(abs(result$Z)))
print(paste("p-value:", round(p_value, 4)))

# You can also test for a trend in more severe injuries only (S2-S4)
severe_affected <- sim_data$S2 + sim_data$S3 + sim_data$S4
result_severe <- run_RSCA(
  group = sim_data$tmt,
  replicate = sim_data$tank,
  affected = severe_affected,
  total = sim_data$total
)

print(paste("Z-statistic (severe injuries):", round(result_severe$Z, 3)))
p_value_severe <- 2 * (1 - pnorm(abs(result_severe$Z)))
print(paste("p-value (severe injuries):", round(p_value_severe, 4)))
```


```{r}
# Test data
test_data <- data.frame(
  tmt = c("C", "SC"),
  tank = c("5A", "4A"),
  S0 = c(2, 1),
  S1 = c(1, 3),
  S2 = c(0, 0),
  S3 = c(1, 0),
  total = c(4, 4)
)

# Test the simplified expansion function
individual_data <- expand_to_individual(test_data)
print(individual_data)

# Test the simplified aggregation function
aggregated_data <- aggregate_from_individual(individual_data)
print(aggregated_data)

# Verify that the conversion is lossless
all.equal(test_data[order(test_data$tmt, test_data$tank), c("tmt", "tank", "S0", "S1", "S2", "S3", "total")], 
          aggregated_data[order(aggregated_data$tmt, aggregated_data$tank), c("tmt", "tank", "S0", "S1", "S2", "S3", "total")])
```

## Example 2:


- Take the subset of F2-females with 16 weeks of age, run RSCABS. 

```{r}
data("exampleHistData")
exampleHistData <- exampleHistData %>% as_tibble %>% mutate(across(where(is.integer),as.numeric)) %>% as.data.frame(.)
#Take the subset corresponding to F0-females of 16 weeks of age

subIndex<-which(exampleHistData$Generation=='F2' &
                  exampleHistData$Genotypic_Sex=='Female' &
                  exampleHistData$Age=='16_wk' )
exampleHistData.Sub<-exampleHistData[subIndex, ]
#Run RSCABS
exampleResults<-runRSCABS(exampleHistData.Sub,'Treatment',
                          'Replicate',test.type='RS')
```

```{r}
exampleResults %>% knitr::kable(.,digits=3)
```
Note that the R.score in the table only shows the scores occured in the respective treatment groups. 


```{r}
ggplot(exampleHistData.Sub,aes(x=Treatment,fill=factor(Gon_Asynch_Dev)))+geom_bar()+scale_fill_viridis_d()+labs(title="Example Data: Gon_Asynch_Dev",subtitle = "subset: F2 generation, 16 week age and female")

cids <-which(apply(exampleHistData.Sub[,-(1:5)],2,max)>0)
responses <- names(cids)



ggplot(exampleHistData.Sub[,c(1:5,5+cids)]%>%tidyr::pivot_longer(-(1:5),values_to = "Response",names_to = "Endpoint"),aes(x=Treatment,fill=factor(Response)))+geom_bar()+scale_fill_viridis_d()+labs(title="Example Histopath Data",subtitle = "subset: F2 generation, 15 week age and female")+facet_wrap(~Endpoint)


library(scales)
dat1 <- exampleHistData.Sub[,c(1:5,5+cids)]%>%tidyr::pivot_longer(-(1:5),values_to = "Response",names_to = "Endpoint") %>% group_by(Endpoint,Treatment,Response) %>% summarise(counts=n())%>% group_by(Endpoint,Treatment) %>% mutate(total=sum(counts))

ggplot(dat1,aes(x=Treatment,fill=factor(Response)))+geom_bar(aes(y=counts/total),stat = "identity")+scale_fill_viridis_d()+labs(title="Example Histopath Data",subtitle = "subset: F2 generation, 15 week age and female")+facet_wrap(~Endpoint,drop = T)+ scale_y_continuous(labels = percent)
```
## Using R's prop.test instead



## Alternative Nonparametric Tests

The example below is taken from Hothorn's paper. `independence_test` function from the `coin` package can be used to test the independence of two sets of variables measured on arbitrary scales. Transformations can be done via `trafo` so that various test statsitcs can be calculated, including Pearson $\chi^2$ test, the generalized Cochran-Mantel-Haenszel test, the Spearman correlation test, the Fisher-Pitman permutation test, the Wilcoxon-Mann-Whitney test, the Kruskal-Wallis test and the family of weighted logrank tests for censored data.

However, the Williams' contrast is not the same as Williams' test, just like in multcomp package. 

```{r inlcude=FALSE}
ifcoin <- require(coin)
```


```{r eval=ifcoin}
data(exampleHistData)
subIndex<-which(exampleHistData$Generation=="F1" &
exampleHistData$Genotypic_Sex=="Male" &
exampleHistData$Age=="8_wk")
LH<-exampleHistData[subIndex, ]
lh<-LH[, c(2,6)]
lh$Gon<-as.numeric(lh$Gon_Phenotype)
lh$EP1<-ifelse(lh$Gon >1,1,0)
lh$EP2<-ifelse(lh$Gon >2,1,0)
lh$EP3<-ifelse(lh$Gon >3,1,0)
lh$treat<-as.factor(lh$Treatment)
lhh<-droplevels(lh[lh$treat!=6, ])
Lhh<-droplevels(lhh[lhh$treat!=3, ])
library("coin")
library("multcomp")
Co1 <- function(data) trafo(data, factor_trafo = function(x)
model.matrix(~x - 1) %*% t(contrMat(table(x), "Dunnett")))
Codu <-independence_test(EP1 +EP2+EP3~ treat, data = Lhh, teststat = "maximum",
distribution = "approximate", xtrafo=Co1, alternative="greater")
pvalCODU <-pvalue(Codu, method="single-step")
pvalCODU
```

```{r eval=ifcoin}
CoW <- function(data) trafo(data, factor_trafo = function(x)
model.matrix(~x - 1) %*% t(contrMat(table(x), "Williams")))
Cowi <-independence_test(EP1 +EP2+EP3~ treat, data = Lhh, teststat = "maximum",
distribution = "approximate", xtrafo=CoW, alternative="greater")
pvalCOWI <-pvalue(Cowi, method="single-step")
pvalCOWI
```



## Multi-quantile JT

From: John Green, personal communication.





## Function Notes

```{r eval=FALSE}
library(DependenciesGraphs)
dep <- funDependencies("package:drcHelper", "runRSCABS")

# visualization
plot(dep)

```

### Notes on RSCABS functions

1. Select responses maximum value should be > 0 and smaller than 20 (limited ranks in response). 
2. for each to be tested response/endpoints, *convert2score*
3. for each to be tested response/endpoints, *prepDataRSCABS*, prepare the data into matrix/table format, treatment as column, replicate as row
4. for each to be tested response/endpoints, *stepKRSCABS*.

The results look like below:

```
$Gon_Asynch_Dev
           Effect Treatment R.Score Statistic     P.Value Signif
1 Gon_Asynch_Dev1         5       1  2.622022 0.004370488     **
2 Gon_Asynch_Dev1         4       1       NaN 1.000000000      .
3 Gon_Asynch_Dev1         4       1       NaN 1.000000000      .
4 Gon_Asynch_Dev2         5       2  2.622022 0.004370488     **
5 Gon_Asynch_Dev2         4       2       NaN 1.000000000      .
6 Gon_Asynch_Dev2         4       2       NaN 1.000000000      .
```

5. combine the results into a big matrix.



## Validation by SAS

The RSCABS code in R written by  is validated in SAS by Chen Meng and also against the RSCABS procedure in the archived statCharrms package.


## References

- Green, John W. and Springer, Timothy A. and Saulnier, Amy N. and Swintek, Joe, (2014) Statistical analysis of histopathological endpoints. Environmental Toxicology and Chemistry, 33(5), 1108-1116

- Hothorn, T., Hornik, K., van de Wiel, M. A. and Zeileis, A. (2008). Implementing a class of permutation tests: The coin package. Journal of Statistical Software 28(8), 1–23. doi: 10.18637/jss.v028.i08
